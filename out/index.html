<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0" class="jsx-834064900"/><link rel="icon" href="/blog/favicon.ico" class="jsx-834064900"/><title class="jsx-86124067">RedLaboratory</title><meta name="next-head-count" content="4"/><link rel="preload" href="/blog/_next/static/D0XTK0MEKRJDXLhC_InxX/pages/_app.js" as="script"/><link rel="preload" href="/blog/_next/static/D0XTK0MEKRJDXLhC_InxX/pages/index.js" as="script"/><link rel="preload" href="/blog/_next/static/runtime/webpack-c212667a5f965e81e004.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/framework.619a4f70c1d4d3a29cbc.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/commons.020a96d8a8e71e9e3362.js" as="script"/><link rel="preload" href="/blog/_next/static/runtime/main-d76a4f4aadf0225115f4.js" as="script"/><link rel="preload" href="/blog/_next/static/chunks/e6dc419047dac61ef10415aaccc4c72c1149af9c.5637e4aab0992574c455.js" as="script"/><style id="__jsx-86124067">.top.jsx-86124067{margin:0;background-color:#ff6565;box-shadow:0 0 5px black;color:white;}.fixed-width.jsx-86124067{max-width:600px;padding:0 20px;margin:0 auto;}.header.jsx-86124067{padding-top:40px;padding-bottom:40px;}.header.jsx-86124067 .title.jsx-86124067{font-size:50px;font-weight:bold;}.header.jsx-86124067 .subtitle.jsx-86124067{font-weight:bold;}.tag.jsx-86124067{padding:2px 4px;font-size:9px;border-radius:3px;background-color:#0000007a;}.content-wrapper.jsx-86124067{margin:40px 0;}</style><style id="__jsx-834064900">@import url(https://fonts.googleapis.com/earlyaccess/notosanskr.css);html,body{margin:0;padding:0;font-family:'Noto Sans KR',sans-serif;}a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}*{box-sizing:border-box;}</style></head><body><div id="__next"><div class="jsx-834064900 container"><div class="jsx-86124067 top"><div class="jsx-86124067 header fixed-width"><div class="jsx-86124067 date">2020-06-07</div><div class="jsx-86124067 title">Untitled</div><div class="jsx-86124067 subtitle">subtitle</div><div class="jsx-86124067 tags"></div></div></div><main class="jsx-86124067 content-wrapper"><div class="jsx-86124067 content fixed-width"><h1 class="jsx-86124067">Title</h1><p class="jsx-86124067">Test</p><h2 class="jsx-86124067">Title</h2><p class="jsx-86124067">Test</p><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-06-27-putoutafire-diary-1">2014-06-27-putoutafire-diary-1<!-- -->게임 개발 일지 - 1.메인 메뉴와 맵 렌더링</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-06-30-putoutafire-diary-2">2014-06-30-putoutafire-diary-2<!-- -->게임 개발 일지 - 2.맵 렌더링 알고리즘 변경 및 엔티티 추가 및 단위 통일</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-07-02-putoutafire-diary-3">2014-07-02-putoutafire-diary-3<!-- -->게임 개발 일지 - 3.플레이어 입력 받기 및 이동!!</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-07-05-putoutafire-diary-4">2014-07-05-putoutafire-diary-4<!-- -->게임 개발 일지 - 4.렌더링 방법 전환...</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-07-07-putoutafire-diary-5">2014-07-07-putoutafire-diary-5<!-- -->게임 개발 일지 - 5.엔티티와 벽 충돌!</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-07-11-putoutafire-diary-6-1">2014-07-11-putoutafire-diary-6-1<!-- -->게임 개발 일지 - 6-1.시야 가시 또는 빛 그림자 렌더링</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-07-14-putoutafire-diary-6-2">2014-07-14-putoutafire-diary-6-2<!-- -->게임 개발 일지 - 6-2.시야 가시 또는 빛 그림자 렌더링 (완성)</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-07-15-putoutafire-diary-7">2014-07-15-putoutafire-diary-7<!-- -->게임 개발 일지 - 7.움직이는 이미지와 렌더링 메소드 변경</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-11-02-putoutafire-diary-8">2014-11-02-putoutafire-diary-8<!-- -->Put out a fire 제작 현황 - 2014/11/2</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2014-11-18-putoutafire-diary-9">2014-11-18-putoutafire-diary-9<!-- -->Put out a fire 제작 현황 - 2014/11/18</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2016-08-03-chinese-five-stroke-input-method-complete">2016-08-03-chinese-five-stroke-input-method-complete<!-- -->한자 오필 입력기 개발 - 완성</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2016-08-10-chinese-five-stroke-input-add-functions">2016-08-10-chinese-five-stroke-input-add-functions<!-- -->한자 오필 입력기 기능 추가</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2016-12-28-ETSDIYController-diary-1">2016-12-28-ETSDIYController-diary-1<!-- -->유로 트럭 시뮬레이터 DIY 컨트롤러 일지 1</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-01-04-ETSDIYController-diary-2">2017-01-04-ETSDIYController-diary-2<!-- -->유로 트럭 시뮬레이터 DIY 컨트롤러 일지 2 - 5:18 스퍼기어 출력</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-01-25-ETSDIYController-diary-3">2017-01-25-ETSDIYController-diary-3<!-- -->유로 트럭 시뮬레이터 DIY 컨트롤러 일지 3</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-01-30-ETSDIYController-diary-4">2017-01-30-ETSDIYController-diary-4<!-- -->유로 트럭 시뮬레이터 DIY 컨트롤러 일지 4</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-02-01-ETSDIYController-diary-5">2017-02-01-ETSDIYController-diary-5<!-- -->유로 트럭 시뮬레이터 DIY 컨트롤러 일지 5</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-08-neural-network-and-deep-learning">2017-04-08-neural-network-and-deep-learning<!-- -->뉴런 네트워크와 딥 러닝</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-08-neuralnet-chap1-using-neural-nets-to-recognize-handwritten-digits">2017-04-08-neuralnet-chap1-using-neural-nets-to-recognize-handwritten-digits<!-- -->제 1장 - 손으로 쓴 숫자를 인식하는 뉴런 네트워크 사용하기</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-08-perceptrons">2017-04-08-perceptrons<!-- -->퍼셉트론</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-08-sigmoid-neurons">2017-04-08-sigmoid-neurons<!-- -->시그모이드 뉴런</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-08-what-this-book-is-about">2017-04-08-what-this-book-is-about<!-- -->이 책이 다루고 있는 것</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-09-a-simple-network-to-classify-handwritten-digits">2017-04-09-a-simple-network-to-classify-handwritten-digits<!-- -->손으로 쓴 숫자를 구분하기 위한 간단한 네트워크</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-09-the-architecture-of-neural-networks">2017-04-09-the-architecture-of-neural-networks<!-- -->뉴런 네트워크의 구조</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-11-learning-with-gradient-descent">2017-04-11-learning-with-gradient-descent<!-- -->기울기 하강 알고리즘으로 학습</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-15-implementing-our-network-to-classify-digits">2017-04-15-implementing-our-network-to-classify-digits<!-- -->숫자들을 판별하기 위한 네트워크 구현하기(작성중)</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-18-neuralnet-chap2-how-the-backpropagation-algorithm-works">2017-04-18-neuralnet-chap2-how-the-backpropagation-algorithm-works<!-- -->제 2장 - 역전파 알고리즘이 어떻게 작동하는가</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-18-the-four-fundamental-equations-behind-backpropagation">2017-04-18-the-four-fundamental-equations-behind-backpropagation<!-- -->역전파에 대한 네가지 중요한 공식(작성중)</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-18-the-hadamard-product">2017-04-18-the-hadamard-product<!-- -->하다마드 곱</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-18-the-two-assumptions-we-need-about-the-cost-function">2017-04-18-the-two-assumptions-we-need-about-the-cost-function<!-- -->비용함수에 대해 필요한 두가지 추정(작성중)</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-18-toward-deep-learning">2017-04-18-toward-deep-learning<!-- -->딥러닝을 향해</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-04-18-warm-up-a-fast-matrix-based-approach-to-computing-the-output-from-a-neural-network">2017-04-18-warm-up-a-fast-matrix-based-approach-to-computing-the-output-from-a-neural-network<!-- -->준비운동 뉴런 네트워크로 부터의 결과를 계산하기 위한 빠른 행렬 기반 접근방법</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-05-14-neuralnet-chap3-improving-the-way-neural-networks-learn">2017-05-14-neuralnet-chap3-improving-the-way-neural-networks-learn<!-- -->제 3장 - 뉴런 네트워크가 학습하는 방법 향상하기(작성중)</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2017-08-27-google-web-fonts">2017-08-27-google-web-fonts<!-- -->구글 웹 폰트 목록</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2019-08-07-afa-quick-shifter">2019-08-07-afa-quick-shifter<!-- -->A-FA 퀵 시프터 제작</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2019-08-30-minecraft-hangulinput-mod-1.0.0-release">2019-08-30-minecraft-hangulinput-mod-1.0.0-release<!-- -->마인크래프트 한글 입력 모드 1.0.0 릴리즈 - 자바 에디션 1.14.4</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/2020-06-07-test">2020-06-07-test<!-- -->Test post</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/testA/2020-06-07-testA">testA/2020-06-07-testA<!-- -->untitled</a></div><div class="jsx-86124067"><a class="jsx-86124067" href="/blog/blog/testA/testAA/2020-06-07-testA">testA/testAA/2020-06-07-testA<!-- -->untitled</a></div></div></main><style>
            .container {
            }
            </style></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 1.메인 메뉴와 맵 렌더링\",\"tags\":\"PutOutAFire\",\"date\":\"2014-06-27 20:09:00 +0900\"}","markdownbody":"\n이번에 자바로 게임 만들기를 해보려고 합니다.(시험이 다음주인데 포스팅 하고 있다니!!!!)\n며칠동안 프로젝트 생성후 게임 구동에 필요한 쓰레드, 프레임등을 세팅하고 나서 기본적인 게임 관련 클래스들과 렌더링을 위한 코드 알고리즘 짰습니다. 알고리즘은 100% 제가 짰습니다.\n\n먼저, 이미지를 화면 크기에 맞게 렌더링 하도록 하는 알고리즘이 있고 다음으로는 맵 렌더링 입니다.\n이미지를 화면 크기에 맞게 렌더링 하는것은 어렵지 않았지만 맵 렌더링은 고난, 그 자체였습니다. ㅋㅋㅋ\n엄청난 오류와(ArrayIndexOutOfBoundsException!!!!!!!!!!!) 이상한 결과까지!!!!! 그 과정도 찍어뒀으면 좋았을텐데...\n\n여튼 지금까지 만든 게임 영상을 올려보도록 하겠습니다.\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 1.메인 메뉴와 맵 렌더링\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/59821106?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2014-06-27-putoutafire-diary-1"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 2.맵 렌더링 알고리즘 변경 및 엔티티 추가 및 단위 통일\",\"date\":\"2014-06-30 17:54:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n이전에는 블럭 이미지의 크기를 8 * 8 로만 맟춰놓고 렌더링 해서 나중에 고해상도 이미지 변경시 코드 자체를 수정해야 하는 일이 생기므로 블럭이 가지고 있는 이미지를 화면 크기에 맞게 렌더링 하도록 하였고, 게임 내에서 단위를 통일하였습니다.\n\n블럭과 블럭 사이의 간격을 1로 두고, 엔티티의 위치과 엔티티의 크기를 이에 맞춰 렌더링 하도록 하였습니다.\n이전에는 단위 자체를 생각 안해서 엔티티 렌더링시 그냥 픽셀 크기에 맞춰 렌더링 했습니다.\n\n엔티티 추가는 정말 재밌습니다 :) 다만, 엔티티의 위치는 엔티티의 가장 왼쪽 위가 기준이므로 나중에 이것이 문제가 될지는 모르겠습니다. 단위 통일했으니 별 문제는 없으려냐? ... 여튼 동영상!\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 2.맵 렌더링 알고리즘 변경 및 엔티티 추가 및 단위 통일\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/59897857?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n\n※ 개발 일지 마다 악뮤 노래가 들어가 있는데, 제가 동영상 촬영할때 맨날 악뮤 노래 틀어놓고 찍는지라~ ㅋㅋㅋ ※\n※ 그러니까 제가 임의로 삽입한게 아니라 제가 듣고있었다는점~ 이해해 주세요~ ※","slug":["2014-06-30-putoutafire-diary-2"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 3.플레이어 입력 받기 및 이동!!\",\"date\":\"2014-07-02 16:13:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n오늘은 플레이어를 움직여 보겠습니다!!!!!\nInputHandler 라는 클래스에서 입력에 대한 모든 정보를 받고, 그 정보를 가지고 플레이어의 움직임을 결정합니다!!!!!\n\n여기서 감속도라는 변수가 있는데, 속도가 점점 줄어들도록 하는 코드에 쓰이는 변수임돠.\n감속도가 1.0 이라면, 마찰이 아에 없는 상태가 되버립니다.\n0.98 ~ 0.99 정도는 얼음처럼 미끄러워 보입니다 ㅋ\n0.92 ~ 0.95 정도가 적당한 것 같습니다.\n\n( 오 오 점점 발전하고 있따 )\n( fps 를 타이틀바 쪽에 표시되도록 바꿈 )\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 3.플레이어 입력 받기 및 이동!!\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/59951256?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2014-07-02-putoutafire-diary-3"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 4.렌더링 방법 전환...\",\"date\":\"2014-07-05 14:39:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n오늘 맵 크기를 10 * 10 으로 해놓고 보니 너무 렉이 심하더라.... 왜그런가 생각해 봤는데 아무래도 매 렌더링 마다 맵을 새로 그려서 렉이 심해지는것 같았다.\n\n그래서! 미리 맵 전체를 렌더링 해놓고 필요한 맵 부분만 그리고 엔티티만 매번 새로 그리는 방법을 생각했다.\n\n그 결과, 엄청난 속도의 차이가!!!!!\n\n최대 fps 를 120 로 설정해 놓고 그 차이를 비교해 보았다.( 오늘또한 악뮤 노래가... )\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 4.렌더링 방법 전환...\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/60026035?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2014-07-05-putoutafire-diary-4"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 5.엔티티와 벽 충돌!\",\"date\":\"2014-07-07 21:46:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n드디어 오늘 엔티티와 블럭의 충돌을 구현했습니다!\n전 의도치 않았지만 벽과 부딧칠 시 약간의 튕김 효과까지....ㅋㅋ\n이제 좀더 게임같은 모습이 된것같아 기분이 좋네요.\n\u003cimg src=\"https://i1.daumcdn.net/mimg/mypeople/sticker/edit/sticker_374.png\" alt=\"신나2\" style=\"font-size: 9pt; line-height: 1.5;\"\u003e\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 5.엔티티와 벽 충돌!\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/60094099?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2014-07-07-putoutafire-diary-5"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 6-1.시야 가시 또는 빛 그림자 렌더링\",\"date\":\"2014-07-11 19:48:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n이번에는 시야 가시 또는 빛 그림자 렌더링을 해보려고 합니다.\n사실 이 과정을 포기해야 할지 모르겠습니다.\n일단 왜냐하면 아래 영상에서 두가지 방법이 나와있는데 하나는 360 도 회전하면서 빛이 최종적으로 닿는 부분을 찾는 방법이 있고, 블럭의 꼭짓점을 기준으로 빛의 최종 지점을 찾는 방법 두가지가 있는데, 전자는 3000번 이상 해야(1도 2도 가 아닌 1.1도 1.2 도 이렇게 세세하게...) 완벽한 그림자 또는 시야를 찾을 수 있고 계속 반복문을 돌리므로 무식한 방법이라고 할 수 있고, 후자는 가장 완성적이었으나 찾아낸 점들을 삼각형으로 매꿔야 하는데 이 부분이 제일 어려웠습니다. 아래 영상에서 조금 어느정도 매워지는것 같으나, 불완전하고 제가 쓸때 없이 쓴 코드들 때문인지 렉이 먹습니다.\n\n이 글을 보시는 분중 해결방법 아시는 분좀 꼭 댓글로..ㅠ.ㅠ\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 6-1.시야 가시 또는 빛 그림자 렌더링\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/60202340?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2014-07-11-putoutafire-diary-6-1"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 6-2.시야 가시 또는 빛 그림자 렌더링 (완성)\",\"date\":\"2014-07-14 17:46:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n오늘 드디어 시야 가시 즉, 볼 수 없는 구역을 까맣게 하는 렌더링 코드를 완성했습니다! (와아아앙!!!!\u003cimg src=\"https://i1.daumcdn.net/mimg/mypeople/sticker/edit/sticker_372.png\" alt=\"홧팅2\" height=\"42\" width=\"42\"\u003e)\n대신에 렉이 아주 먹는군요. 이 부분을 렌더링 안할때는 300 fps 나오는데 렌더링 하면 25 fps 로 확 내려간다는 사실...ㅠㅠ\n알아보니, 볼 수 없는 구역을 찾은 후 그곳을 까만색으로 칠하는 메소드가 시간을 좀 잡아 먹더라구요. 그 메소드를 실행하는 부분만 빼면 한 100 fps 정도? 나오는것 같네요. 목표 fps 는 120 fps 정도인데 그정도면...그래도 렉이 걸리는 편이군요\n여튼 이 렌더링 코드는 게임 만들면서 일단 보류 하고 더 효율성 있게 계산 가능한 알고리즘이 나오면 그때 해보도록 해야겠습니다.\n\n여튼 완성해 놓으니 기분이 좋군요!!!!!!!\u003cimg src=\"https://i1.daumcdn.net/mimg/mypeople/sticker/edit/sticker_330.png\" alt=\"굿보이\"\u003e\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 6-2.시야 가시 또는 빛 그림자 렌더링 (완성)\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/60282993?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2014-07-14-putoutafire-diary-6-2"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"게임 개발 일지 - 7.움직이는 이미지와 렌더링 메소드 변경\",\"date\":\"2014-07-15 18:27:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n제가 그동안 너무 \"직접 혼자서\" 개발하는것에만 열중했나 봅니다. 자바의 Graphics 객체가 있음에도 불구하고 이용하지 않았습니다.... 삼각형이나 이미지를 그리는 메소드를 Graphics 에 있는 메소드로 바꾸어 렌더링 하니 그 속도가 엄청나게 빨라졌습니다...\n\n또한 불 엔티티를 위한 움직이는 이미지 또한 만들었습니다. 사실 메소드 바꾸기 전에(방금 얘기한 메소드!) 이 움직이는 이미지를 렌더링 해봤는데 속도가 24fps 가 나오더라구요....\n\n여튼 앞으로는 Graphics 를 자주 이용해야 겠습니다 :)\n\n\u003ccenter\u003e\u003ciframe title=\"게임 개발 일지 - 7.움직이는 이미지와 렌더링 메소드 변경\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/60313171?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e","slug":["2014-07-15-putoutafire-diary-7"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"Put out a fire 제작 현황 - 2014/11/2\",\"date\":\"2014-11-02 17:11:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n*불* 구현\n\n*파티클* 구현(물리 포함)\n\n*아이템* 구현(소화기)\n\n*불* 소화 구현\n\n\u003ccenter\u003e\u003ciframe title=\"Put out a fire 제작 현황 - 2014/11/2\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/63148444?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e","slug":["2014-11-02-putoutafire-diary-8"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"Put out a fire 제작 현황 - 2014/11/18\",\"date\":\"2014-11-18 18:04:00 +0900\",\"categories\":null,\"tags\":\"PutOutAFire\"}","markdownbody":"\n*맵렌더링* 최적화\n\n*글자 렌더링 코드* 작성\n\n들고있는 아이템 *표시*\n\n*체력 수치값*도 표시\n\n\u003ccenter\u003e\u003ciframe title=\"Put out a fire 제작 현황 - 2014/11/18\" width=\"640\" height=\"360\" src=\"https://kakaotv.daum.net/embed/player/cliplink/63560926?service=daum_tistory\" allowfullscreen frameborder=\"0\" scrolling=\"no\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n\n*글자 렌더링*이 짜세 ㅋ(문자열을 for 문으로 char 하나하나 불러와 비교 후 렌더링 ㅋ핰핰하)\n","slug":["2014-11-18-putoutafire-diary-9"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"한자 오필 입력기 개발 - 완성\",\"categories\":\"programming\",\"tags\":\"한자오필입력기\",\"date\":\"2016-08-03 01:49:00 +0900\"}","markdownbody":"\n# 한자 오필 입력기\n\n## 개발하게 된 동기\n학교에서 중국어를 배우는데, 왜이렇게 중국어가 재밌는지, 휴대폰으로 한자를 입력할 방법을 찾다가 획만으로 모든 한자를 입력하는 입력기를 알게되어 설치하게 되었다.\n\n이 방법을 컴퓨터 에서도 쓰고 싶어서 PC판 오필입력기를 찾는데, 도통 나오질 않고 겨우 찾은 프로그램은 이미 휴대폰 자판에 익숙해진 나에게 너무 불편했다. 획 자판이 일렬로 나열되어 있었고 검색 결과 밑에 우리나라 한자 음이 표기 되면 좋겠다라는 생각에 그럴바에 직접 만들어 버리지 뭐, 하면서 시작하게 된것이 C언어를 배워야 하는 대 프로젝트로 커지고 말았다.\n\n## 오필입력이란?\n간단히 말해, 한자의 획을 *다섯가지로 구분*하여 획 수 대로 입력하는 방법.\n예를 들어, \"열 십 十\"같은 한자의 경우 가로획, 세로획 두가지 획이 있으므로 해당하는 획 버튼을 순서대로 누른다.\n\n\u003c!-- more --\u003e\n\n여기서 중요한 점은 *획순*을 지켜야 한다는 것이다.\n자세한 사항은 필자가 위키백과에 정리해 두었다.\n\n위키백과 \"오필화수입법\": [https://ko.wikipedia.org/wiki/오필화수입법](https://ko.wikipedia.org/wiki/%EC%98%A4%ED%95%84%ED%99%94%EC%88%98%EC%9E%85%EB%B2%95)\n\n위키에도 나와있듯이, 이 입력법의 장점은 한자의 모양만 알고 있으면 입력할 수 있다는 것 이지만, 한자 획순의 규칙을 알아야 하고, 규칙을 알고 있다 하더라도 대부분의 한자들은 규칙대로 입력하기 힘들다. 특히 \"벚 우 友\"와 \"반할 반 反\"자는 이 입력법으로 입력하려고 하면 처음쓰는 사람에게는 혼란을 야기하기 쉽다. 맨 첫번째 획만 다르고 나머지는 다 똑같다.\n\n그럼에도 불구하고 난 이 입력법이 너무 좋다. 너무 매력적이기 때문이다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/screenshot.png\" width=\"400px\" /\u003e\u003c/center\u003e\n\n# 프로그램으로 구현하기 까지\n\n이를 프로그램으로 구현하기 위해서는, 어떤 한자에 대한 획 정보를 담고있는 표가 필요한데, 직접 만들기는 뭐하고 인터넷을 검색하던 도중에 아니나 다를까, 이미 누군가 파싱하기 쉽도록 만들어 두었다.\n\n획 테이블: [https://code.google.com/archive/p/ibus-t9/issues/3](https://code.google.com/archive/p/ibus-t9/issues/3)\n\n이 개발자는 이미 한참전에 개발을 멈춘것 같다. 완성이 된것인지는 자세히 알아보지 않아서 모르지만 좋은 자료다!\n\n이제 이 테이블을 가지고 해야하는 일은 테이블 검색이다. 세상에나. 이 테이블에는 20000개는 넘는 한자데이터들이 있다. 지금까지 이렇게 많은 데이터는 다뤄 본적이 없어서 막막했지만 사전처럼 일정한 규칙이 있었기에 적당한 알고리즘이 있을거라고 생각했다. 찾은 알고리즘은 바로 \"이분법적 검색(binary search)\" 이다. 정렬되어있는 데이터셋에서 매우 강력한 힘을 발휘한다. 한번 루프를 돌 때 마다 검색의 범위가 반으로 줄기 때문에 속도가 미친듯이 빠르다.\n\n물론 정렬이 되어있어야 하고, 어떤 방식으로 정렬이 되어있는지 알아야 한다는 문제가 있다.\n\n그래서 두 가지의 데이터 베이스를 만들었다.\n첫번째 데이터 베이스는 획수의 길이를 고려하여, 짧은것이 우선순위가 높은 정렬이고, 두번째 데이터 베이스는 길이는 고려치 않고 획의 종류로만 정렬한 데이터 이다.\n\n첫번째와 두번째 테이블을 가지고 검색했을때, 다른 이점이 있는데 획수를 고려했을때의 결과는 획수를 고려했기 때문에 획수대로 검색할 수 있다는 것이고, 그 때문에 획수는 같은데 비슷한 한자들을 나열할 수 있다.\n두번째 테이블 같은 경우는 같은 부수를 가지는 한자들을 많이 찾을 수 있다. 예를 들어 삼수변을 검색했다면 삼수변을 부수로 두는 한자들이 나올것이다. 만약, 첫번째 테이블에서 삼수변을 찾으면 3획짜리 한자들이 나올것이다.\n\n둘중 하나를 골라 하나만 쓰기에는 좀 그래서 각 테이블에서 5개씩 검색하여 둘다 보여주기로 결정했다.\n\n그 다음 GUI를 만들고 모바일 입력기 처럼 버튼을 만들어 획을 입력하도록 하고 검색한 결과를 열개의 버튼에 순서대로 표시하여 해당 버튼을 누르면 그 한자가 커서에 나오도록 했다.\n\n그 다음에 검색결과에 우리나라 한자 음이 나오면 좋겠다 싶어서 이번에는 그에 대한 데이터베이스를 찾다가 Unihan이라는 것을 알게 되었다.\n\nUnihan: [https://unicode.org/charts/unihan.html](https://unicode.org/charts/unihan.html)\n\n이 프로젝트는 한중일 한자의 대한 데이터를 수집하여 현재 zip파일 형태로 데이터 베이스를 제공하고 있다. 한중일의 한자들중 같은 한자이나, 모양이 다른 한자들에 대해서도 모두 정리해 두었고 일본어 발음, 중국어 발음, 한국어 발음, 광둥어 발음등 발음에 대한 정보도 모두 들어있고 영어로 뜻 또한 들어있다.\n데이터 베이스 중에서도 Unihan_Readings.txt 라는 파일에 kHangul이라는 속성에 한국어 한자 발음에 대한 정보가 들어있다. 이 데이타 베이스도 용량이 방대하기 때문에 이분법적 검색 알고리즘을 사용했다.(거의 만능)\n\n이제 기본적인 틀은 모두 갖추었으나, 사용하는데 너무 불편하다. 그 이유는 마우스로 일일이 눌러야 하기 때문이다. 그래서 키보드 입력을 지원해 보기로 했으나, 자바로 개발했기에 컴퓨터 자체의 키보드 입력을 받는데 문제가 있다. 그래서 전역 키보드 후킹을 해야하는데 네이티브 라이브러리를 이용해야 한다.\n\n물론 오픈소스로 네이티브 키보드 후킹 라이브러리가 존재하나, 진짜 내가 원하는 기능이 없었다. 바로 키보드 입력을 '취소'시켜버리는 것이다. 이거 하나때문에 내가 직접 키보드 후킹을 만들어야지, 라고 생각했다. 사실 엄청 좋은 기능이지만, 이를 구현하려면 배울게 하나둘이 아니었다.\n\n일단 가장 기본중의 기본 언어인 C를 선택하였고 dll을 만들어야 했다.\n키보드 후킹을 하기위해서는, 프로세스마다 dll을 inject하여 jvm에 알려주어야 하는데 처음에는 다 무슨 \u003cs\u003e개\u003c/s\u003e소린지 알아듯질 못했다.\n\n프로세스간 메모리 공간이 불리되어 thread-safe한 객체일 지라도 한 프로세스 내에서만 유효하다는 것, 핸들은 한 쓰레드 내에서만 유효 하다는것, 포인터와 이중 포인터의 개념, 이름있는 파이프, 구조체, jni의 사용 등 배우고 이해해야 하는것이 많았고 두 세번 갈아 엎어서 완성했다.\n\n실제로 사용하면서도 문제가 있었는데, 키보드 입력 취소가 목적이었던 터라 자바에서 함수를 빨리 return 해주지 않으면 dll에서 계속 기다리고 있는 탓에(그것도 KeyboardProc에서) 시스템의 입력 전체가 맛이 가는 부작용이 있었다. 물론 이 문제는 프로그래밍 하면서 게속 유념해야 할 것이다. 그래서 딜레이가 생기는 일 이라면 자바에서 쓰레드를 생성해서 이벤트 함수는 빨리 리턴해 주고 후에 작업을 해 주어야 한다.\n\n# 완성\n\n\u003ccenter\u003e\u003ciframe width=\"560\" height=\"315\" src=\"//sendvid.com/embed/qgp3760s\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2016-08-03-chinese-five-stroke-input-method-complete"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"한자 오필 입력기 기능 추가\",\"categories\":\"programming\",\"tags\":\"한자오필입력기\",\"date\":\"2016-08-10 21:50:00 +0900\"}","markdownbody":"\n저번에 작성한 한자 오필 입력기 아래에 텍스트 창과 네개의 버튼을 넣어 기능을 추가하였다!\n\n*텍스트 창 안의 한자들을 변환*할 수 있는 기능.\n\n- pinyin: 한자들을 해당하는 한어병음으로 치환한다.\n- hangul: 한자들을 해당하는 한글로 치환한다.\n- simplefy: 한자들을 해당하는 간체자로 치환한다.\n- tradition: 한자들을 해당하는 번체자로 치환한다.\n\n\u003ccenter\u003e\u003ciframe width=\"560\" height=\"315\" src=\"//sendvid.com/embed/ibhtv6zj\" frameborder=\"0\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/center\u003e\n","slug":["2016-08-10-chinese-five-stroke-input-add-functions"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"유로 트럭 시뮬레이터 DIY 컨트롤러 일지 1\",\"categories\":null,\"tags\":\"유로트럭시뮬레이터\",\"date\":\"2016-12-28 11:10:00 +0900\"}","markdownbody":"\n유로 트럭을 하면서 키보드로 조종 하는것이 어렵고 불편하기도 해서 핸들로 조종하고 싶다는 마음이 들었다.\n그렇지만 핸들을 사기도 뭐해서 직접 만들기로 했다.\n\n센서 =\u003e 아두이노 =\u003e JVM =\u003e vJoy =\u003e Euro Truck Simulator 2\n\n센서로 부터 값을 아두이노가 받아들이고 이를 시리얼 통신으로 JVM으로 보낸다.\nJVM에서 vJoy 인터페이스에 조이스틱 값을 변환해 전달하고 vJoy가 유로 트럭 시뮬레이터에 최종적으로 값을 보낸다.\n\nvJoy는 Virture Joystick 의 약자로, 운영체제 상에서 인식되는 가상의 조이스틱 디바이스이다.\nvJoy feeder를 작성해서 가짜로 조이스틱의 값을 만들어 주면, 예를 들어 X 버튼이 눌렸다 라는 신호를 만들어 주면, 운영체제 에서는 실제 컨트롤러 기기에서 X 버튼이 눌렸다고 인식 하도록 할 수 있는것이다.\n\n그런데 vJoy 인터페이스는 C언어로 작성되어 dll 로 제공되어 있어서 JNI를 이용해서 자바에서 접근할 수 있었다.\n그냥 C로 개발하면 되지만 그냥 자바로 하고싶었다.\n그래서 [JvJoyInterface 라이브러리][JvJoyInterface-github]를 직접 만들었다. vJoy와 관련된 내용은 [공식 홈페이지][vJoy-site]를 참조.\n\n\u003c!-- more --\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-18 23.50.54.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n가변저항과 아두이노를 사용해서 스티어링이 인식됨을 확인하고 핸들을 만들기로 했다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-19 20.31.05.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-19 20.31.11.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-19 20.41.20.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n블랜더로 대충 어떤 모양으로 만들지 구상하였다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-19 21.19.13.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-19 21.43.23.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-19 22.16.38.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-19 22.20.37.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n집에 남아도는 전선으로 끈을 대신하였다. (철사라서 그런지 매우 단단하다.)\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-25 13.13.53.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n핸들을 만들기 위해 아크릴 판에 구멍을 뚫어 가변저항을 넣고 고정시킨 모습이다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-25 13.22.29.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n가변저항은 300도 밖에 움지이지 못하는데, 핸들은 좌 우 각각 한바퀴 반씩, 총 1080도를 돈다.\n그래서 기어를 이용하여 핸들이 1080도를 돌때 가변저항은 300도를 돌도록 할 예정이다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2016-12-25 13.22.35.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n가변저항 핀에 전선을 땜질하였다.\n\n[JvJoyInterface-github]:          https://github.com/rlj1202/JvJoyInterface\n[vJoy-site]:                      https://vjoystick.sourceforge.net/site/\n","slug":["2016-12-28-ETSDIYController-diary-1"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"유로 트럭 시뮬레이터 DIY 컨트롤러 일지 2 - 5:18 스퍼기어 출력\",\"categories\":null,\"tags\":\"유로트럭시뮬레이터\",\"date\":\"2017-01-04 00:50:00 +0900\"}","markdownbody":"\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017_01_04_00_52_51_967.png\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003ca href=\"https://geargenerator.com/\" target=\"_blank\" class=\"tx-link\"\u003ehttps://geargenerator.com/\u003c/a\u003e\n\n해당 홈페이지에서 기어 이빨의 수가 5:18의 비율을 다르도록 하여 백터 이미지 파일로 저장하였다.\n원래는 블랜더에서 작업 후 obj로 만들려고 했지만, 블랜더에서 출력한 obj 파일의 사이즈 정보가 제대로 나오지 않는지 3D 큐브 프로그램에서 사이즈를 인식하지 못한다.\n\n그래서 FreeCad 프로그램을 사용하여 작업하기로 했다.\n\n\u003c!-- more --\u003e\n\n\u003ca href=\"https://www.freecadweb.org/\" target=\"_blank\" class=\"tx-link\"\u003ehttps://www.freecadweb.org/\u003c/a\u003e\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017_01_03_23_50_04_901.png\" width=\"400px\"\u003e\u003c/center\u003e\n\n백터 이미지를 불러온 뒤 2D 오브젝트를 늘려서 3D로 만들고 6mm 구멍을 낸 결과다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017_01_04_00_03_09_704.png\" width=\"400px\"\u003e\u003c/center\u003e\n\n가변저항의 손잡이가 지름이 6mm이다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-02 13.31.55.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n인쇄가 시작되었다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-02 13.32.05.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n5시간 반정도 걸린다. 평소보다 밀도도 높이고 레이어 두께도 얇아 졌다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-02 13.43.21.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n사이드 워크 인쇄가 모두\u0026nbsp;끝났다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-02 14.41.07.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n다른때랑 다르게 내부 층이 육각형 구조로 채워진다. 더 단단하다고 한다.\n아직 네시간이나 남았으므로 다음날 확인한다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-03 09.56.47.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n다음날 확인해 보니 이상없이 잘 뽑혀있다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-03 09.57.15.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n잘 보이지 않지만 멀리서 보면 층이 거의 보이지 않을 정도로 조밀조밀 하다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-03 10.11.03.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n사이드 워크를 모두 제거한 상태이다. 사포질까지 마치면 사용 가능하다.\n\n기어 허브의 지름이 6mm인건 맞지만 6.1mm정도로 인쇄하면 가변저항 손잡이에 바로 끼울 수 있을것 같다.\n손잡이에 끼우기 위해 사포로 허브 안쪽을 갈아야 했기 때문이다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-04 00.55.31.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n사포질을 해서 딱 들어간다!\n인쇄 전에 수평맞춤을 하지 않아서 그런지 약간 휘어지거나 기운 부분이 있지만 사용하는데 지장은 없어 보인다.\n","slug":["2017-01-04-ETSDIYController-diary-2"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"유로 트럭 시뮬레이터 DIY 컨트롤러 일지 3\",\"categories\":null,\"tags\":\"유로트럭시뮬레이터\",\"date\":\"2017-01-25 18:58:00 +0900\"}","markdownbody":"\n어제인가 그제인가 아크릴 판과 아크릴 접착제를 주문해서 오늘 도착했다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 16.11.58.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003c!-- more --\u003e\n\n동호수는 그냥 뭐...안지워도 되겠지?\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 16.13.18.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 16.14.38.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n짠! 3T 짜리 20x20 아크릴판 네 장이다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 16.15.20.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n원래 가지고 있던 아크릴판은 4T 정도 되서 조금 더 얇다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 16.26.53.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n이제 20x20 짜리를 15x20으로 만들 차례다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 16.28.39.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n(사진이 굉장히 역동적이다.) 빠르게 움직여야 마찰열이 나면서 잘 잘리는것 같은데 계속 톱 날이 걸린다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 16.52.56.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n하... 톱 페인트가 벗겨졌다. 아크릴 판 자르기 정말 힘들다. 포멕스로 할 걸 그랬다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 17.23.38.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n새 아크릴 판에 두개의 구멍을 뚫고 원래 있던 아크릴판에 한번 갖다 올려 보았다.\n\n잘 맞는다!\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 17.25.12.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n아크릴 판도 소개가 각각 다른지 모르겠지만 이 아크릴 판은 원래 아크릴 판과 조금 달랐다.\n원래 있던 아크릴 판은 갈리면서 뚫리는게 느껴지는데 반해 새로 산 아크릴 판은 녹으면서 뚫리는 것 같다. 그래서 그런지 사진처럼 끝에 녹은 아크릴이 드릴 사이에 끼어버렸다. 라이터로 불을 지진 다음에서야 떼어낼 수 있었다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 18.02.23.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n아크릴 접착제도 샀다. 냄새는 휘발성이라 그런지 알코올 냄새가 난다. 초강력 접착제보다 훨씬 견고히 붙는 것 같다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 18.02.34.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n30ml 짜린데 적은 양으로도 강하게 붙어서 충분히 오랬동안 쓸 수 있을 것 같다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-25 18.02.41.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n주사기도 동봉되어 왔는데 적은 양을 주입할 때 굉장히 편한 것 같다. 다만, 출구 자체가 너무 좁다보니 저기서 접착제가 조금이라도 굳게 되면 주사기를 누를 때 접착제가 확 나와버려서 접착제가 여기저기 튄다. 몸에 좋지 않다고 하니 빨리 씻어 내자.\n\n이제 다음에 할 일은 6파이 샤프트를 본체에서 빠지지 않도록 하고 샤프트가 흔들리지 않도록 새로 산 아크릴 판을 덧댄다음 핸들을 붙이면 완성이다!","slug":["2017-01-25-ETSDIYController-diary-3"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"유로 트럭 시뮬레이터 DIY 컨트롤러 일지 4\",\"categories\":null,\"tags\":\"유로트럭시뮬레이터\",\"date\":\"2017-01-30 23:53:00 +0900\"}","markdownbody":"\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-29 14.14.53.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n오늘은 핸들을 조립했다. 생각했던것 보다 굉장히 부드럽게 잘 돌아간다. 본체에 추 같은걸 달아서 무게를 준다면 실제로 게임하는데 굉장히 편할 것 같다. (저 핸들에다가 커버를 사서 하나 끼워볼까...?)\n\n\u003c!-- more --\u003e\n\n\u003ccenter\u003e\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/S3UnWIlso8E\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/center\u003e\n\n사실 실제 게임 운전까지 해볼 수 있었는데 인두로 포텐션미터를 땜질하다가 뭘 잘못 건드렸는지 가지고있던 포텐션 미터 두개 모두 고장나 버렸다. 사실 고장났다고 해야될지 잘 모르겠지만 원인을 설명하자면,\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-01-30 23.37.16.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n사진에서 빨갛게 동그라미 친 부분이 pc핀과 pbc판이 접합되어있는 부분인데, 이 부분이 허술해서 제대로 연결되지 않아 전류가 불규칙적으로 흘러 센서값이 정확히 측정되지 않았다. 그래서 플라이어 등의 공구를 이용해서 저 접합부를 강하게 눌러준 다음에는 일시적으로 센서값이 정확히 측정되다가 다시 불규칙적인 값을 보인다. 납땜을 할때 인두를 pc핀에 너무 오래 대고 있어서 그런지도 모르겠다. 아니면 땜납에서 나오는 플럭스 또는 인두팁에 묻힌 솔더링 페이스트가 두 접합부 사이에 끼어서 그런지도 모르겠다. 다음에 납땜질을 할때에는 밖으로 삐져나온 pc핀에다가 땜질을 해야겠다. 사실 저 핀들은 납땜하기 어려워 보여서 저 구멍을 택했는데 잘못된 선택인것 같다. 뭐 어쨌든 그래서 납땜으로 pbc판과 pc핀 을 이어보려 했으나 저 pcb판에는 납이 붙지 않는다. 또 알루미늄 포일로 둘 사이에 끼어보려고 했으나 그러기에는 또 너무 틈이 좁다... 현재 4개의 새 포텐션미터를 주문한 상태이다.\n\n또 인두 팁 관리를 하지 않아 인두 팁이 다 산화되어버렸다. 사포로 긁어도 보고 철 수세미로 닦아도 보았다. 인두 팁에 납을 녹여놓으라길래 다시 전원을 키면 납이 녹기도 전에 먼저 산화되어 버려서 뭘 어떻게 해야할지 모르겠다.\n\n※ 구글링 결과 ※\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/alphapot16x15.jpg\" width=\"400px\"\u003e\u003c/center\u003e\n\n사진 출처 - https://www.diystompboxes.com/smfforum/index.php?topic=114228.0\n\n저 구멍에는 납땜을 하지 말란다. 납땜위치가 잘못된것이었다. 사진을 구한 쓰레드에서는 그냥 포텐션미터에 데미지를 줄 수 있으니 하지 말라고만 이야기 하고 있다.\n\n","slug":["2017-01-30-ETSDIYController-diary-4"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"유로 트럭 시뮬레이터 DIY 컨트롤러 일지 5\",\"categories\":null,\"tags\":\"유로트럭시뮬레이터\",\"date\":\"2017-02-01 20:50:00 +0900\"}","markdownbody":"\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-02-01 14.16.02.jpg\" width=\"400\"\u003e\u003c/center\u003e\n\n이틀 전 주문했던 포텐셔미터가 도착했다.\n\n\u003c!-- more --\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-02-01 14.48.54.jpg\" width=\"400\"\u003e\u003c/center\u003e\n\n이번에는 기판 안으로 납땜중에 발생하는 이물질이 들어가지 않도록 핀에다가 땜질을 하였다.\n인두가 상태가 안좋아서 이쁘게 되지는 않았지만...\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-02-01 14.49.04.jpg\" width=\"400\"\u003e\u003c/center\u003e\n\n드디어 시범운전을 할 수 있게 되었다. 엑셀과 브레이크가 없는관계로 오른손으로는 핸들을, 왼손으로는 키보드를 조작해서 운전을 하려고 한다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-02-01 17.29.23.jpg\" width=\"400\"\u003e\u003c/center\u003e\n\n핸들 본체가 너무 가볍다 보니 계속 움직여서 핸들을 제대로 잡고 있을수가 없었다.\n그래서 뒤에 안쓰는 CD롬을 올려두었다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/photo/2017-02-01 20.36.39.jpg\" width=\"400\"\u003e\u003c/center\u003e\n\nㅎㅎㅎㅎ 드디어 시범 운전이다.\n\n\u003ccenter\u003e\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HjnKdOh23q8\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/center\u003e\n\n동영상은 용량이 약 1G여서 유튜브에 미등록 영상으로 업로드 하였다.\n운전 미숙으로 중간중간 부딧히지만 역시 키보드로 할때 보다는 훨씬 재미있다.\n컴퓨터 성능상에 문제인지 아두이노의 속도 문제인지 모르겠지만 핸들의 반응속도가 약간 느리다. 그렇지만 조작에는 문제가 없어 보인다.\n\n이제 원래 목표인 스티어링 핸들을 완료했다. 다음에 시간이 되면 엑셀과 브레이크를 만들어 보면 좋겠다.\n기어를 만들게 된다면 수동 기어는 만들기 어려우니 오토에 필요한 기어를 만들어 봐야겠다.(후진, 전진, 중립의 세단계만 가능하면 될것 같다.)\n사이드 브레이크인지 주차 브레이크인지도 한번 해보면 좋겠지만....불필요한것 같다.\n","slug":["2017-02-01-ETSDIYController-diary-5"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"뉴런 네트워크와 딥 러닝\",\"date\":\"2017-04-08 20:44:00 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n이 글의 원문은 [https://neuralnetworksanddeeplearning.com](https://neuralnetworksanddeeplearning.com) 입니다. 이 번역 글은 이 책의 저작자표시-비영리 라이센스를 따릅니다. 또한 이 글 또한 같은 라이센스를 따릅니다.\n\n개인적인 공부(인공지능과 영어)와 정보 공유를 위해 번역을 시작하게 되었으며, 번역과 영어에 미숙하기 때문에 여러 오역등이 있을 수 있으며 오역, 오타 등알 발견했을 때 댓글로 알려주시면 수정하도록 하겠습니다.\n\n\u003c!-- more --\u003e\n\n* [이 책이 다루고 있는 것][book_about]\n* [제 1장 - 손으로 쓴 숫자를 인식하는 뉴런 네트워크 사용하기][chap1]\n  * [퍼셉트론][perceptrons]\n  * [시그모이드 뉴런][sigmoid]\n  * [뉴런 네트워크의 구조][architecture]\n  * [손으로 쓴 숫자를 구분하기 위한 간단한 네트워크][simple_network]\n  * [기울기 하강 알고리즘으로 학습][gradient_descent]\n  * [숫자들을 판별하기 위한 네트워크 구현하기][implementing_network]\n  * [딥러닝을 향해][toward_deep_learning]\n* [제 2장 - 역전파 알고리즘이 어떻게 작동하는가][chap2]\n  * [준비운동: 뉴런 네트워크로 부터의 결과를 계산하기 위한 빠른 행렬 기반 접근 방법][warm_up]\n  * [비용함수에 대해 필요한 두 가지 추정][two_assumptions]\n  * [하다마드 곱][hadamard]\n  * [역전파에 대한 네 가지 중요한 공식][four_equations]\n* [제 3장 - 뉴런 네트워크가 학습하는 방법 향상하기][chap3]\n  * 교차 엔트로피 비용 함수\n  * 과적합과 일반화\n  * 가중치 초기화\n  * 손글씨 인식문제 다시보기: 코드\n  * 뉴런 네트워크의 hyper-parameter를 어떻게 선택하는가?\n  * 다른 기술들\n* 제 4장 - 뉴런 네트워크가 어떤 함수라도 계산 가능하다는 시각적 증명\n  * Two caveats\n  * Univerality with one input and one output\n  * Many input variables\n  * Extension beyond sigmoid neurons\n  * Fixing up the step functions\n  * Conclusion\n* 제 5장 - 왜 딥 뉴런 네트워크는 학습하기 어려운가?\n  * The vanising gradient problem\n  * What's causing the vanishing gradient problem? Unstable gradients in deep neural nets\n  * Unstable gradients in more complex networks\n  * Other obstacles to deep learning\n* 제 6장 - 딥 러닝\n  * Introducing convolutional networks\n  * Convolutional neural networks in practice\n  * The code for our convolutional networks\n  * Recent progress in image recognition\n  * Other approaches to deep neural nets\n  * On the future of neural networks\n* Appendix: Is there a simple algorithm for intelligence?\n* Acknowledgements\n* Frequently Asdked Questions\n\n아래서 부터는 해당 온라인 책의 내용입니다.\n\n------\n\n뉴런 네트워크와 딥 러닝은 온라인으로 읽을 수 있는 무료 책 입니다. 이 책에서는 다음과 같은것을 배울 수 있습니다.\n\n* 뉴런 네트워크, 관측 가능한 데이터로 부터 학습하는 컴퓨터를 가능하게 하는 아름다운 생물학적 프로그래밍 패러다임\n* 딥 러닝, 뉴런 네트워크의 학습을 위한 강력한 기술\n\n뉴런 네트워크와 딥 러닝은 현재 이미지 인식, 음성 인식, 자연어 처리 등의 많은 문제들의 가장 좋은 해결책을 제공하고 있습니다. 이 책은 뉴런 네트워크와 딥 러닝에 있어서 가장 핵심적인 개념들을 여러분에게 알려줄 것입니다.\n\n이 책에서 사용되는 접근법에 대해서 더 자세히 알고싶다면, [여기][book_about]를 참고하세요. 또는 바로 [제 1장][chap1]으로 건너가 시작할 수 있습니다.\n\n[book_about]: {{ site.baseurl }}{% post_url 2017-04-08-what-this-book-is-about %}\n[chap1]:      {{ site.baseurl }}{% post_url 2017-04-08-neuralnet-chap1-using-neural-nets-to-recognize-handwritten-digits %}\n[perceptrons]: {{ site.baseurl }}{% post_url 2017-04-08-perceptrons %}\n[sigmoid]: {{ site.baseurl }}{% post_url 2017-04-08-sigmoid-neurons %}\n[architecture]: {{ site.baseurl }}{% post_url 2017-04-09-the-architecture-of-neural-networks %}\n[simple_network]: {{ site.baseurl }}{% post_url 2017-04-09-a-simple-network-to-classify-handwritten-digits %}\n[gradient_descent]: {{ site.baseurl }}{% post_url 2017-04-11-learning-with-gradient-descent %}\n[implementing_network]: {{ site.baseurl }}{% post_url 2017-04-15-implementing-our-network-to-classify-digits %}\n[toward_deep_learning]: {{ site.baseurl }}{% post_url 2017-04-18-toward-deep-learning %}\n[chap2]: {{ site.baseurl }}{% post_url 2017-04-18-neuralnet-chap2-how-the-backpropagation-algorithm-works %}\n[warm_up]: {{ site.baseurl }}{% post_url 2017-04-18-warm-up-a-fast-matrix-based-approach-to-computing-the-output-from-a-neural-network %}\n[two_assumptions]: {{ site.baseurl }}{% post_url 2017-04-18-the-two-assumptions-we-need-about-the-cost-function %}\n[hadamard]: {{ site.baseurl }}{% post_url 2017-04-18-the-hadamard-product %}\n[four_equations]: {{ site.baseurl }}{% post_url 2017-04-18-the-four-fundamental-equations-behind-backpropagation %}\n[chap3]: {{ site.baseurl }}{% post_url 2017-05-14-neuralnet-chap3-improving-the-way-neural-networks-learn %}\n","slug":["2017-04-08-neural-network-and-deep-learning"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"제 1장 - 손으로 쓴 숫자를 인식하는 뉴런 네트워크 사용하기\",\"date\":\"2017-04-08 21:35:00 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n인간의 시각 체계는 세계에서 불가사의한 것들 중 하나입니다. 다음과 같은 손으로 쓴 숫자들을 한번 보세요.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/digits.png\" width=\"300px\"\u003e\u003c/center\u003e\n\n대부분의 사람들은 큰 노력없이 이 숫자들을 504192라고 읽을 수 있습니다. 우리 뇌의 각 좌뇌 우뇌에서, 인간은 $V1$이라고 알려진 첫번째 시각피질을 가지고 있고 이는 1억 4천만개의 뉴런들과 그것들 사이의 100억개 이상의 연결을 가지고 있습니다. 또한 $V1$ 뿐만 아니라 $V2$, $V3$, $V4$, $V5$의 여러개의 시각피질들을 통해 더욱 복잡한 이미지 처리를 합니다. 우린 시각적 세계를 이해하기 위해 수십억년동안 진화한 슈퍼컴퓨터를 머리에 이고 다니는 셈이죠. 손으로 쓴 숫자를 인식하는 것은 쉽지 않습니다. 그러나 우리 인간은 매우 놀랍게도 우리 눈이 우리에게 보여주는 것에 대한 감각을 잘 만듭니다. 하지만 이 과정은 무의식적으로 이루어집니다. 그래서 우리는 우리의 시각치계가 해결하는 문제가 얼마나 어려운 일인지 알지 못하죠.\n\n\u003c!-- more --\u003e\n\n시각 패턴 인식의 어려움은 위와 같은 숫자들을 인식하는 컴퓨터 프로그램을 작성하려고 할 때 잘 드러납니다. 우리가 스스로 할 때는 굉장히 쉬워보였던 것이 순식간에 어려워 집니다. 우리가 어떻게 모양을 인식하는지에 대한 간단한 직관, \"숫자 9는 위에 동그라미가 있고 오른쪽 아래로 수직하는 획이 하나 있다\"와 같은 것은 알고리즘으로 표현하기 결코 쉽지 않습니다. 만약 이런 규칙을 명확하게 하고자 한다면, 여러분은 아마 예외와 오류들 그리고 특별한 경우들의 늪에 빠지게 될 것 입니다. 희망이 없어 보이는군요.\n\n하지만 뉴런 네트워크는 이 문제에 대해 다르게 접근합니다. 이 방법은 학습 예시라고 알려진 많은 양의 손으로 쓴 글씨 이미지들을 취하여 이 학습 예시들로 부터 배울수 있는 한 체계를 만드는 것 입니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/mnist_100_digits.png\"\u003e\u003c/center\u003e\n\n다른말로 하면, 뉴런 네트워크는 손으로 쓴 숫자들을 인식하기 위한 규칙을 스스로 추론하기 위해 이 예시들을 사용합니다. 또한, 이 예시들의 수를 늘림으로써 손글씨에 대해 더 배우고 정확도를 높일 수 있습니다. 제가 위에 100개의 예시들을 보여드렸지만, 우리는 천개 심지어는 백만 또는 10억개에 달하는 예시들을 이용하여 더 나운 손글씨 인식기를 만들 수 있습니다.\n\n이 장에서는 손글씨들을 인식하기 위해 학습하는 뉴런 네트워크를 구현하는 컴퓨터 프로그램을 작성하게 될 것입니다. 프로그램은 단지 74줄로 이루어져 있고 어떠한 뉴런 네트워크 라이브러리도 사용하지 않습니다. 하지만 이 짧은 프로그램은 어떠한 인간의 개입 없이도 숫자들을 96%이상의 확률로 판정할 수 있는 정확도를 가지고 있습니다. 더 나아가, 이후 장에서는 우리는 이 정확도를 99% 이상 높일 수 있는 개념들에 대해 배우게 될것 입니다. 사실 최고의 상업적 뉴런 네트워크는 너무 정확해서 은행에서 수표를 처리하는데 또는 우체국에서 주소를 인식하는데 사용되고 있습니다.\n\n우리는 일반적으로 뉴런 네트워크를 배우는데 있어서 가장 기본적인 문제이기 때문에 손글씨 인식에 초점을 맞추고 있습니다. 매우 도전적인 일입니다. 손글씨를 인식하는것은 결코 작은 업적이 아닙니다. 그렇지만 매우 복잡한 해결 방법이나 무지막지한 컴퓨팅 파워를 요구하는 만큼 어려운 일도 아닙니다. 더 나아가, 딥 러닝과 같은 고급기술들을 개발하는데에 있어서 좋은 방법입니다. 또한 이 책을 통해 우리는 반복해서 손글씨 인식 문제로 돌아갈 것 입니다. 후에 이 책에서, 우리는 어떻게 이런 개념들이 컴퓨터 이미지 인식, 음성 인식, 자연어 인식, 그리고 다은 환경에서의 다른 문제들에 적용될 수 있는지 논의하게 될 것 입니다.\n\n물론, 이 장에서의 주된 목적이 단지 손글씨 인식을 위한 컴퓨터 프로그램 작성이라면, 이 장은 굉장이 짧아질 것입니다. 하지만 과정을 따라가며 우리는 두개의 중요한 가상 뉴런의 종류를 포함하여 뉴런 네트워크와 확률론적 기울기 하강 알고리즘과 같은 뉴런 네트워크를 위한 기본적 학습 알고리즘에 대한 많은 중요한 개념들을 개발하게 될 것 입니다. 이를 통해, 저는 왜 그것들이 왜 그렇게 되었는지 설명하고, 여러분의 뉴런 네트워크에 대한 직관을 쌓는데 집중할 것 입니다. 이것은 제가 단지 무엇이 일어나고 있는지에 대한 기초적인 고정을 드러낸느것 보다 더 긴 논의를 필요로 합니다. 그러나 여러분이 얻게될 깊은 이해를 위해서는 가치 있는 일입니다. 장의 마지막에서는 우리는 딥 러닝이 무엇인지, 또 왜 이것이 문제가 되는지 이해하기 위한 위치에 도달해 있을 것 입니다.","slug":["2017-04-08-neuralnet-chap1-using-neural-nets-to-recognize-handwritten-digits"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"퍼셉트론\",\"date\":\"2017-04-08 22:55:00 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n뉴런 네트워크란 무엇인가요? 시작하기에 앞서, 저는 퍼셉트론이라고 불리는 가상 뉴런의 한 종류에 대해 설명하고자 합니다. 퍼셉트론은 [워렌 맥클로치](https://en.wikipedia.org/wiki/Warren_McCulloch)와 [월터 피치](https://en.wikipedia.org/wiki/Walter_Pitts)의 [선행 연구](https://scholar.google.ca/scholar?cluster=4035975255085082870)에 영감을 받아 과학자 [프랭크 로젯블랫](https://en.wikipedia.org/wiki/Frank_Rosenblatt)에 의해 1950년과 1960년대 사이에 [개발](https://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ)되었습니다. 오늘날에는 다른 뉴런 모델을 사용하는 것이 일반적입니다. 이 책과 대부분의 현대적 연구에서 사용되는 주된 뉴런 모델은 시그모이드 뉴런 이라고 불리는 뉴런입니다. 곧 시그모이드 뉴런에 대해 다룰것 이지만 왜 시그모이드 뉴런이 왜 그렇게 정의되었는지 알기 위해서는 퍼셉트론을 첫번째로 이해하는 시간을 가지는 것이 좋겠습니다.\n\n그래서, 퍼셉트론 어떻게 작동할까요? 퍼셉트론은 $x_{1}$, $x_{2}$, ...와 같은 몇개의 이진 입력을 받습니다. 그리고 하나의 이진 출력을 내보냅니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz0.png\"\u003e\u003c/center\u003e\n\n\u003c!-- more --\u003e\n\n위의 예시에서는 퍼셉트론이 세개의 입력, $x_{1}$, $x_{2}$, $x_{3}$을 가지고 있습니다. 일반적으로 이보다 더 많거나 적은 입력을 가질 수 있습니다. 로젠블랫은 출력값을 계산하기 위한 하나의 간단한 규칙을 제안하였습니다. 그는 가중치, $w_{1}$, $w_{2}$, $w_{3}$, ...와같은 출력을 위한 각각의 입력들에 대한 중요도를 의미하는 실수 숫자들을 소개했습니다. 뉴런의 출력이 되는 0 또는 1은 $\\sum_{j}w_{j}x_{j}$의 값이 어떤 $threshold$ 값보다 작거나 큰지에 따라 결정됩니다. 가중치과 같이, $threshold$는 뉴런의 변수 중 하나인 실수 숫자입니다. 더 명확한 용어로 표현하자면 다음과 같습니다.\n\n$$\n\\begin{eqnarray}\\mbox{output} \u0026 = \u0026 \\left\\{ \\begin{array}{ll}0 \u0026 \\mbox{if } \\sum_j w_j x_j \\leq \\mbox{ threshold} \\\\1 \u0026 \\mbox{if } \\sum_j w_j x_j \u003e \\mbox{ threshold}\\end{array} \\right.\\tag{1}\\end{eqnarray}\n$$\n\n이것이 어떻게 퍼셉트론이 작동하는지에 대한 전부입니다!\n\n이것이 기초적인 수학적 모델입니다. 여러분이 퍼셉트론에 대해 생각할 수 있는 방법은 여러 요소들의 중요도를 조정함에 따라 결정을 내리는 장치 하나를 생각하는것 입니다. 예시를 하나 들어보겠습니다. 매우 현실적인 예시는 아니지만 이해하기 쉬운 예시입니다. 그리고 우리는 후에 더 현실적인 예시를 들것입니다. 주말이 오고 있고 여러분은 여러분의 도시에 치즈 페스티벌이 있을 예정이라고 들었다고 합시다. 여러분은 치즈를 좋아합니다. 그리고 페스티벌에 갈지 가지 않을지 결정하고 있습니다. 여러분은 아마 다음 세 요소의 중요도를 조정하며 결정을 내리게 될 것 입니다.\n\n1. 날씨가 좋은가?\n2. 남자친구 혹은 여자친구가 함께 갈 것인가?\n3. 페스티벌이 열리는 곳에 대중교통이 잘 되어 있는가? (여러분은 차가 없습니다)\n\n우리는 이 세개의 요소를 각각의 대응하는 변수 $x_{1}$, $x_{2}$, $x_{3}$에 대입하여 표현할 수 있습니다. 예를 들어, $x_{1}=1$라면 날씨가 좋은것이고 $x_{1}=0$이면 날씨가 좋지 않은 것 입니다. 비슷하게, $x_{2}=2$라면 여러분의 남자친구 혹은 여자친구가 함께 갈 것이라는 뜻이고 $x_{2}=0$ 이라면 그렇지 않은 것 입니다. 또 비슷하게 $x_{3}$ 에 대해서는 대중교통의 유무를 의미합니다.\n\n이제, 여러분이 정말 치즈를 좋아하고 남자친구 혹은 여자친구과 관심이 없더라도 심지어 페스티벌이 가기 힘든곳에 있더라고 정말 그곳에 가고싶다고 가정해 봅시다. 하지만 여러분이 나쁜 날씨를 정말 싫어하고 날씨가 나쁘다면 그곳에 갈 수 있는 방법이 없다고 해봅시다. 여러분은 이러한 의사결정 모델을 퍼셉트론을 이용하여 만들수 있습니다. 이 모델을 만드는 방법은 날씨에 대해 $w_{1}=6$ 으로 설정하고 다른 조건들에 대해 $w_{2}=2$, $w_{3}=2$로 설정하는 것 입니다. $w_{1}$ 의 큰 값은 남자친구 또는 여자친구가 여러분과 함께 갈 것인지 보다, 대중교통이 잘 되어있는지 보다 훨씬 더 날씨가 여러분의 의사 결정에 많은 영향을 준다는 뜻 입니다. 마지막으로, 퍼셉트론에게 $5$라는 $threshold$값을 선택했다고 합시다. 이 선택들에 따라, 날씨가 좋으면 1을 출력하고 날씨가 좋지 않으면 0을 내놓는 우리가 원하는 의사 결정 모델을 만들게 되었습니다. 남자친구 또는 여자친구의 동행 여부 또는 대중교통의 유무는 의사결정에 영향을 주지 않습니다.\n\n이러한 가중치과 $threshold$값들을 다양하게 함으로써 우리는 다른 의사결정 모델을 얻을 수 있습니다. 예를 들어, $threshold$값으로 3을 선택했다고 합시다. 그러면 퍼셉트론은 여러분이 날씨가 좋거나 혹은 남자친구 또는 여자친구가 동행하면서 대충교통이 근처에 있다면 페스티벌에 가야한다고 결정할 것 입니다. 다른 말로, 이는 또 다른 의사결정 모델이 된다는 것 입니다. $threshold$값을 떨어뜨린다는 것은 여러분이 페스티벌에 갈 의사가 더 강하다는 뜻입니다.\n\n당연히, 퍼셉트론은 완벽한 인간의 의사결정 모델이 아닙니다! 하지만 위의 예시가 보여주는 것은 어떻게 퍼셉트론이 결정을 내리기 위해 서로 다른 종류의 요소들의 중요도를 조정하는지 입니다. 그리고 퍼셉트론의 복잡한 네트워크는 꽤 복잡한 의사결정이 가능하다는 것이 당연해 보입니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz1.png\"\u003e\u003c/center\u003e\n\n이 네트워크에서, (우리가 첫번째 층이라고 부르는) 퍼셉트론의 첫번째 열은 입력 요소들의 중요도를 조정함에 따라 세개의 간단한 결정을 내립니다. 두번째 층은 어떤가요? 각각의 퍼셉트론은 첫번째 층의 의사결정에 의한 결과들의 중요도를 조정함에 따라 또 다른 의사결정을 합니다. 이를 통해 두번째 층에 있는 퍼셉트론은 첫번째 층의 퍼셉트론 보다 더 복잡하고 추상적인 수준의 의사결정을 할 수 있게 됩니다. 그리고 심지어 더 복잡한 의사결정이 세번 째 층에서 만들어 질 수 있습니다. 이렇게, 퍼셉트론의 다층 네트워크는 자세한 의사결정을 이끌어 낼 수 있습니다.\n\n그러나, 제가 퍼셉트론을 정의했을때에 저는 퍼셉트론이 하나의 출력만을 가진다고 이야기 했습니다. 위의 네트워크에서는 퍼셉트론이 여러개의 출력을 가지고 있는 것 처럼 보입니다. 사실, 저것들은 여전히 하나의 출려입니다. 여러개의 출력을 화살표들은 단지 퍼셉트론의 출력이 몇개의 다른 퍼셉트론의 입력으로서 사용될 수 있음을 나타내는데 유용한 방법일 뿐입니다. 이는 갈라지는 하나의 출력선 보다는 훨씬 보기 좋습니다.\n\n우리가 퍼셉트론을 설명하는 방법을 간단하게 해 봅시다. $\\sum_{j}w_{j}x_{j}\u003ethreshold$이라는 조건은 길고 복잡합니다. 그리고 우리는 이것을 간단하게 두개의 기호를 이용해 변화시킬 수 있습니다. 첫번째 변화는 $\\sum_{j}w_{j}x_{j}$를 내적으로 표현하여 $w\\cdot x\\equiv \\sum_{j}w_{j}x_{j}$ 와 같이 바꿀 수 있고 $w$와 $x$가 있는 자리에는 가중치와 입력값들을 성분으로 하는 백터가 들어갑니다. 두번째 변화는 $threshold$를 부등식의 다른 변에 이항하고 이를 퍼셉트론의 $bias$를 의미하는 $b\\equiv -threshold$로 바꾼것 입니다. $threshold$ 대신 $bias$를 씀으로써 퍼셉트론 규칙은 다음과 같이 다시 쓰여질 수 있습니다.\n\n$$\n\\begin{eqnarray}\\mbox{output} = \\left\\{ \\begin{array}{ll} 0 \u0026 \\mbox{if } w\\cdot x + b \\leq 0 \\\\1 \u0026 \\mbox{if } w\\cdot x + b \u003e 0\\end{array}\\right.\\tag{2}\\end{eqnarray}\n$$\n\n여러분은 $bias$에 대해 얼마나 퍼셉트론이 1을 출력값으로 가지기 쉬운지에 대한 척도라고 생각할 수 있습니다. 또는 좀 더 생물학적인 용어로, $bias$는 얼마나 퍼셉트론이 잘 흥분하는지에 대한 척도라고 할 수 있습니다. 큰 $bias$를 가진 퍼셉트론은 1을 출력값으로 가지기 매우 쉽습니다. 하지만 $bias$가 음수의 값을 가지면 1을 출력으로 가지기 매우 어려워 집니다. 당연히 $bias$를 소개한것은 어떻게 우리가 퍼셉트론을 설명하는지에 대한 단지 작은 변화일 뿐입니다. 그러나 우리는 나중에 이것이 기호를 이용한 표기에서 편의성을 가져옴을 보게될 것 입니다. 이러한 이유로, 우리는 $threshold$를 사용하지 않고 계속해서 $bias$를 사용할 것입니다.\n\n저는 퍼셉트론을 의사결정을 위해 요소들의 가중치를 조정하는 한 방법으로 설명하였습니다. 퍼셉트론이 사용될 수 있는 또 다른 방법은 AND, OR 그리고 NAND와 같은 논리 연산을 하는 것 입니다. 예를 들어 우리가 -2를 가중치고 가지는 두개의 입력과 $bias$가 3인 퍼셉트론이 있다고 하면 다음과 같이 그릴 수 있습니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz2.png\"\u003e\u003c/center\u003e\n\n우리는 입력이 $(0, 0)$ 이라면 1을 출력으로 가진다는것을 알 수 있습니다. 왜냐하면 $(-2) * 0 + (-2) * 0 + 3 = 3$은 양수이기 때문입니다. 여기에 저는 곱셈 연산을 명확히 하기위해 $ * $이라는 기호를 사용하였습니다. (역주: 내적 또는 외적 연산자와 확실히 구별하기 위함으로 추정.) 비슷한 연산으로 입력이 $(0, 1)$일 때와 $(1, 0)$일 때는 출력으로 1을 갖습니다. 그러나 입력이 $(1, 1)$이 되면 0을 출력으로 내놓습니다. 왜냐하면 $(-2) * 1 + (-2) * 1 + 3 = -1$은 음수이기 때문입니다. 그렇기 때문에 이 퍼셉트론은 NAND 함수를 구현한 것 입니다!\n\nNAND 함수의 예시는 우리가 간단한 논리함수를 연산하는데 퍼셉트론을 사용할 수 있음을 보여줍니다. 사실, 우리는 퍼셉트론의 네트워크로 어떠한 논리 연산도 할 수 있습니다. 그 이유는 우리는 NAND 함수로는 어떠한 연산도 가능하기 때문입니다. 예를 들어, 우리는 NAND 함수를 이용하여 $x_{1}$, $x_{2}$ 두개의 비트를 더하는 회로를 구현할 수 있습니다. 이는 비트연산, $x_{1}\\oplus x_{2}$와 $x_{1}$, $x_{2}$의 값이 모두 1일때 1의 값을 가지는 올림자리 비트(carry bit)를 필요로 합니다. carry 비트는 비트곱셈 $x_{1}x_{2}$으로 구할 수 있습니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz3.png\"\u003e\u003c/center\u003e\n\n퍼셉트론으로 이루어진 동등한 네트워크를 얻기 위해서는 우리는 모든 NAND 함수를 가중치가 -2인 두개의 입력과 $bias$가 3인 퍼셉트론으로 바꾸어야 합니다. 여기 그 결과물이 있습니다. 제가 오른쪽 아래의 NAND 회로에 해당하는 퍼셉트론을 화살표를 그리기 쉽도록 조금 이동하여 그렸습니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz4.png\"\u003e\u003c/center\u003e\n\n이 퍼셉트론 네트워크의 기억할 만한 부분은 왼쪽에 있는 퍼셉트론의 출력이 오른쪽 아래에 있는 퍼셉트론의 입력으로써 두번 사용되었다는 것 입니다. 제가 퍼셉트론의 모델의 정의할때 이러한 같은곳으로의 이중 출력이 가능한지 아닌지 이야기 하지 않았습니다. 사실, 이는 그리 문제되지 않습니다. 이러한 것을 원하지 않는다면, 간단히 두 입력을 하나의 입력으로 만들어 가중치가 -4가 되도록 하면 됩니다. (만약 이것이 당연하다고 생각하지 않는다면, 여러분은 여기서 잠시 멈추고 두 경우 모두 같은 결과가 나옴을 스스로 증명해 보아야 합니다. 이러한 변화를 거치고 나면 네트워크는 다음과 같이 보여질 것 입니다. 특별히 명시되지 않은 가중치는 -2의 값을 가지고 $bias$는 모두 3이며 하나의 가중치에만 -4의 값을 가집니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz5.png\"\u003e\u003c/center\u003e\n\n지금까지 저는 $x_{1}$과 $x_{2}$와 같은 입력들을 네트워크의 왼쪽에 떠다니는 변수로 그려놓았으나, 사실 이는 퍼셉트론의 추가적인 레이어로 그릴 수 있습니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz6.png\"\u003e\u003c/center\u003e\n\n이러한 입력이 없고 출력만 존재하는 퍼셉트론에 대한 표기는\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz7.png\"\u003e\u003c/center\u003e\n\n위와 같이 짧게 표기할 수 있습니다. 이것이 퍼셉트론이 입력이 존재하지 않는다는 의미는 아닙니다. 이것을 이해하기 위해, 우리가 입력이 없는 퍼셉트론을 가지고 있다고 가정해 봅시다. 그렇게 된다면 $\\sum_{j}w_{j}x_{j}$의 값은 0이 될것이고, $b\u003e0$이라면 출력은 1이 될것이고 $b\\leq 0$이라면 출력값은 0이 될것입니다. 이 말은, 퍼셉트론은 고정된 값만을 내놓는다는 것 입니다. 입력 퍼셉트론을 하나의 퍼셉트론 보다는 원하는 값인 $x_{1}$, $x_{2}$, ...을 내놓도록 정의된 특별한 단위로써 보는것이 더 낫습니다.\n\n위 가산회로 예시는 어떻게 퍼셉트론 네트워크가 수많은 NAND 회로들을 가지고 있는 회로를 시물레이션 할 수 있는지 입증해 줍니다. 그리고 NAND 회로가 모든 연산에 대해 사용될 수 있기에 퍼셉트론 또한 모든 연산에 사용 가능하다는 결론을 이끌어 낼 수 있습니다.\n\n퍼셉트론의 이러한 범용성은 만족스럽기도 하지만 한편으로 실망스럽기도 합니다. 이것이 만족스러운 이유는 퍼셉트론의 네트워크가 그 어떤 연산장치만큼 강력할 수 있기 때문입니다. 또한 이것이 실망스러운 이유는 퍼셉트론이 단지 NAND회로의 새로운 한 종류에 불과하기 때문입니다. 그것 참 인정하기 힘들군요!\n\n그러나, 이런 시작에서 보여지는 것 보다 실제 상황은 훨씬 더 좋습니다. 이는 우리가 가상 뉴런의 네트워크의 가중치와 $bias$들을 자동으로 조정해 주는 학습 알고리즘을 창안할 수 있다는 것을 보여줍니다. 이러한 조정은 프로그래머의 의한 직접적인 개입 없이도 외부 시물레이션에서 이루어 질 수 있습니다. 이러한 학습 알고리즘은 동일한 논리회로와는 근본적으로 다른 방법으로 가상 뉴런들을 사용할 수 있도록 해줍니다. NAND 회로와 다른 논리 화로로 이루어진 회로를 정확히 배열하는것 대신에 우리의 뉴런 네트워크는 직접 회로를 디자인 하기 어려운 문제더라도 학습하여 문제를 해결할 수 있습니다.\n","slug":["2017-04-08-perceptrons"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"시그모이드 뉴런\",\"date\":\"2017-04-08 23:02:27 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n학습 알고리즘은 매우 획기적으로 들립니다. 하지만 어떻게 우리가 뉴런 네트워크를 위한 그런 알고리즘을 창안할 수 있을까요? 우리가 어떤 문제를 풀기위해 학습을 할 퍼셉트론의 네트워크를 가지고 있다고 가정해 봅시다. 예를 들어, 네트워크의 입력값은 손으로 쓴 숫자 이미지를 스캔한 픽셀 데이터 일 것입니다. 그리고 우리는 가중치와 $bias$값들을 조정하여 정확한 숫자의 결과를 내놓는 네트워크를 원할 것 입니다. 어떻게 학습이 이뤄지는지 보기 위하여 우리가 네트워크에서 가중치 또는 $bias$에서 작은 변화를 주었다고 가정해 봅시다. 우리가 원하는 결과는 우리가 가중치 또는 $bias$에 준 작은 변화가 오직 네트워크의 출력값에 원하는 작은 변화가 일어나는 것 입니다. 이런 특징이 학습이 가능토록 하는 부분입니다. 도식으로 우리가 원하는 결과를 그려보았습니다. (당연히 이 네트워크는 손글씨를 인식하기에는 너무 간단합니다!)\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz8.png\" style=\"max-width:100%;height:auto\"  height=\"270\" width=\"487\"/\u003e\u003c/center\u003e\n\n만약 우리가 준 작은 변화가 작은 변화만을 준것이 사실이라면, 우리는 이 사실을 우리가 원하는 방향으로 행동하도록 네트워크의 가중치와 bias를 조정하는데 적용할\u0026nbsp;수 있을것입니다. 예를 들어, 우리의 네트워크가 8이 그려진 이미지를 9라고 인식했다고 잘못 학습됬다고 가정하여 봅시다. 우리는 네트워크가 이 이미지가 9라고 더 가깝게 판정하도록 어떻게 가중치와 $bias$에 작은 변화를 줄것인지 알아낼 수 있을것입니다. 이것을 반복하다 보면 결과는 점점 더 좋아질 것 입니다. 이 네트워크는 계속 배우고 있는 것 입니다.\n\n\u003c!-- more --\u003e\n\n문제는 우리의 네트워크가 퍼셉트론을 포함하고 있을때는 이것이 일어나지 않는다는 것 입니다. 사실, 네트워크에 있는 어떠한 퍼셉트론의 가중치와 $bias$에 대한 작은 변화는 퍼셉트론의 출력이 완전히 반대가 되도록 할 수 있습니다. 이러한 변화는 매우 복잡한 과정을 거쳐 나머지 네트워크의 행동이 완전히 바뀌도록 할 수 있습니다. 그래서 여러분의 9 이미지가 이제는 완벽히 판별될 수 있을지라도, 다른 모든 이미지에 대한 네트워크의 행동은 건드릴 수 없을만큼 다르게 바뀌어 있을 수 있습니다. 이것이 가중치와 $bias$를 조정하여 네트워크가 원하는 결과를 만들어 내도록 하는것이 얼마나 어려운 일인지 보여줍니다. 아마 이 문제를 해결하는 더 현명한 방법이 있을 수 있습니다. 그러나, 학습 가능한 퍼셉트론 네트워크를 얻을 수 있음이 한순간에 당연해 지지는 않을것입니다.\n\n우리는 시그모이드 뉴런이라고 불리는 새로운 종류의 가상 뉴런을 소개함으로써 이 문제에 접근할 수 있습니다. 시그모이드 뉴런은 페셉트론과 비슷하지만, 그들의 가중치와 $bias$에 작은 변화를 주는것이 그들의 출력의 작은 변화만을 가져옵니다. 이 결정적인 사실이 시그모이드 뉴런으로 이루어진 네트워크가 학습을 가능토록 합니다.\n\n좋습니다, 시그모이드 뉴런이 무엇인지 설명하도록 하지요. 우리는 퍼셉트론을 묘사했던 것 처럼 시그모이드 뉴런을 묘사 하고자 합니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz9.png\" style=\"max-width:100%;height:auto\"  height=\"138\" width=\"280\"/\u003e\u003c/center\u003e\n\n퍼셉트론 처럼, 시그모이드 뉴런은 $x_{1}$, $x_{2}$...와 같은 입력을 가지고 있습니다. 하지만 단지 0과 1뿐만이 아닌 0과 1 사이의 그 어떤 실수값이라도 받아들일 수 있습니다. 그래서, 예를 들면, 0.638...과 같은 값도 이 시그모이드 뉴런에서는 유효한 값입니다. 또한 퍼셉트론 처럼, 시그모이드 뉴런 또한 각 입력마다 $w_{1}$, $w_{2}$...와 같은 가중치와 $b$라고 표기하는 $bias$를 가지고 있습니다. 하지만 출력값은 0 이거나 1이 아닙니다. 대신 시그모이드 함수라고 불리는 $\\sigma (w\\cdot x+b)$의 값을 가집니다. 시그모이드 함수는 다음과 같습니다.\n\n$$\\begin{eqnarray} \\sigma(z) \\equiv \\frac{1}{1+e^{-z}}.\\tag{3}\\end{eqnarray}$$\n\n\u003cspan style=\"color: rgb(189, 189, 189);\"\u003e*가끔, $\\sigma$ 기호는 로그함수를 부를때도 사용되고, 로그함수는 로그 뉴런이라고 불리는 새로운 종류의 뉴런에 사용됩니다. 이 기호는 뉴런 네트워크에서 활동하는 사람들이 많이 사용하기 때문에 기억하기 쉽습니다. 그러나, 우리는 이 기호를 시그모이드에서의 용어로써만 다룰것입니다.\u003c/span\u003e\n\n더 정확히 표현하자면, 시그모이드 뉴런의 입력들과 가중치, $bias$에 대해 표현하면\n\n$$\\begin{eqnarray} \\frac{1}{1+\\exp(-\\sum_j w_j x_j-b)}.\\tag{4}\\end{eqnarray}$$\n\n첫 인상은 시그모이드 뉴런이 퍼셉트론과는 매우 달라보입니다. 시그모이드 함수의 수학적 형태는 여러분이 익숙하지 않다면 이해하기 힘들고 무서워 보입니다. 사실, 퍼셉트론과 시그모이드 뉴런 사이에는 매우 많은 공통점이 있고, 시그모이드 함수의 수학적 형태는 이해를 위한 장애물 보다는 더 많은 기술적 디테일을 담고있습니다.\n\n이것과 퍼셉트론 모델과의 비슷한 점을 이해하기 위해서는, $z\\equiv w\\cdot x+b$의 값이 큰 양수라고 가정해 봅시다. 그러면 $e^{-z}\\approx 0$이고 $\\sigma (z) \\approx 1$ 입니다. 다시 말하면, $z\\equiv w\\cdot x+b$의 값이 큰 양수라면 시그모이드 뉴런의 출력값은 퍼셉트론이 그랬던것 처럼 1에 가까워 진다는 뜻 입니다. 이젠 $z\\equiv w\\cdot x+b$의 값이 음수라고 가정해 봅시다. 그렇다면 $e^{-z} \\rightarrow \\infty$ 이고 $\\sigma (z) \\approx 0$ 입니다. 그래서 $z\\equiv w\\cdot x+b$의 값이 음수라면 시그모이드 뉴런은 퍼셉트론처럼 행동하게 됩니다. 이는 $w\\cdot x+b$의 값이 적당한 크기였을때만의 이야기 이며, 실제로는 퍼셉트론 모델과는 많은 편차가 존재합니다.\n\n그렇다면 시그모이드 함수의 수학적 형태는 어떻게 생겼을까요? 어떻게 우리가 그것을 이해할 수 있을까요? 사실, 시그모이드 함수의 수학 식은 중요치 않습니다. 정말 중요한 것은 함수의 그래프 입니다. 여기 아래 바로 그 그래프가 있습니다.\n\n\n\u003cdiv id=\"sigmoid_graph\"\u003e\u003c/div\u003e\u003cscript src=\"https://d3js.org/d3.v3.min.js\"\u003e\u003c/script\u003e\u003cscript\u003e\nfunction s(x) {return 1/(1+Math.exp(-x));}\nvar m = [40, 120, 50, 120];\nvar height = 290 - m[0] - m[2];\nvar width = 600 - m[1] - m[3];\nvar xmin = -5;\nvar xmax = 5;\nvar sample = 400;\nvar x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);\nvar data = d3.range(sample).map(function(d){ return {\n        x: x1(d), \n        y: s(x1(d))}; \n    });\nvar x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);\nvar y = d3.scale.linear()\n                .domain([0, 1])\n                .range([height, 0]);\nvar line = d3.svg.line()\n    .x(function(d) { return x(d.x); })\n    .y(function(d) { return y(d.y); })\nvar graph = d3.select(\"#sigmoid_graph\")\n    .append(\"center\")\n    .append(\"svg\")\n    .attr(\"width\", width + m[1] + m[3])\n    .attr(\"height\", height + m[0] + m[2])\n    .append(\"g\")\n    .attr(\"transform\", \"translate(\" + m[3] + \",\" + m[0] + \")\");\nvar xAxis = d3.svg.axis()\n                  .scale(x)\n                  .tickValues(d3.range(-4, 5, 1))\n                  .orient(\"bottom\")\n                  .outerTickSize(1)\ngraph.append(\"g\")\n    .attr(\"class\", \"x axis\")\n    .attr(\"transform\", \"translate(0, \" + height + \")\")\n    .call(xAxis);\nvar yAxis = d3.svg.axis()\n                  .scale(y)\n                  .tickValues(d3.range(0, 1.01, 0.2))\n                  .orient(\"left\")\n                  .ticks(5)\n                  .outerTickSize(1)\ngraph.append(\"g\")\n    .attr(\"class\", \"y axis\")\n    .call(yAxis);\ngraph.append(\"path\")\n    .attr(\"d\", line(data))\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke-width\", 1)\n    .attr(\"stroke\", \"rgb(42, 110, 166)\");\ngraph.append(\"text\")\n     .attr(\"class\", \"x label\")\n     .attr(\"text-anchor\", \"end\")\n     .attr(\"x\", width/2)\n     .attr(\"y\", height+35)\n     .text(\"z\");\ngraph.append(\"text\")\n        .attr(\"x\", (width / 2))             \n        .attr(\"y\", -10)\n        .attr(\"text-anchor\", \"middle\")  \n        .style(\"font-size\", \"16px\") \n        .text(\"sigmoid function\");\n\u003c/script\u003e\n\n이 그래프는 step 함수를 부드럽게 만들었을 때의 그래프와 같습니다.\n\n\n\u003cdiv id=\"step_graph\"\u003e\u003cscript\u003e\nfunction s(x) {return x \u003c 0 ? 0 : 1;}\nvar m = [40, 120, 50, 120];\nvar height = 290 - m[0] - m[2];\nvar width = 600 - m[1] - m[3];\nvar xmin = -5;\nvar xmax = 5;\nvar sample = 400;\nvar x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);\nvar data = d3.range(sample).map(function(d){ return {\n        x: x1(d), \n        y: s(x1(d))}; \n    });\nvar x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);\nvar y = d3.scale.linear()\n                .domain([0,1])\n                .range([height, 0]);\nvar line = d3.svg.line()\n    .x(function(d) { return x(d.x); })\n    .y(function(d) { return y(d.y); })\nvar graph = d3.select(\"#step_graph\")\n    .append(\"center\")\n    .append(\"svg\")\n    .attr(\"width\", width + m[1] + m[3])\n    .attr(\"height\", height + m[0] + m[2])\n    .append(\"g\")\n    .attr(\"transform\", \"translate(\" + m[3] + \",\" + m[0] + \")\");\nvar xAxis = d3.svg.axis()\n                  .scale(x)\n                  .tickValues(d3.range(-4, 5, 1))\n                  .orient(\"bottom\")\n                  .outerTickSize(1)\ngraph.append(\"g\")\n    .attr(\"class\", \"x axis\")\n    .attr(\"transform\", \"translate(0, \" + height + \")\")\n    .call(xAxis);\nvar yAxis = d3.svg.axis()\n                  .scale(y)\n                  .tickValues(d3.range(0, 1.01, 0.2))\n                  .orient(\"left\")\n                  .ticks(5)\n                  .outerTickSize(1)\ngraph.append(\"g\")\n    .attr(\"class\", \"y axis\")\n    .call(yAxis);\ngraph.append(\"path\")\n    .attr(\"d\", line(data))\n    .attr(\"fill\", \"none\")\n    .attr(\"stroke-width\", 1)\n    .attr(\"stroke\", \"rgb(42, 110, 166)\");\ngraph.append(\"text\")\n     .attr(\"class\", \"x label\")\n     .attr(\"text-anchor\", \"end\")\n     .attr(\"x\", width/2)\n     .attr(\"y\", height+35)\n     .text(\"z\");\ngraph.append(\"text\")\n        .attr(\"x\", (width / 2))             \n        .attr(\"y\", -10)\n        .attr(\"text-anchor\", \"middle\")  \n        .style(\"font-size\", \"16px\") \n        .text(\"step function\");\n\u003c/script\u003e\u003c/div\u003e\n\n만약 시그모이드 함수가 step 함수와 그래프가 같아면, 시그모이드 뉴런은 $w\\cdot x+b$의 값이 양수인지 음수인지에 따라 1 또는 0의 값만을 가질 것 이기 때문에 퍼셉트론과 같아질겁니다. 우리가 얻는 이 시그모이드 함수를 사용함에 따라, 이미 위에서 언급한 것 처럼, 굉장히 부드럽고 연속적인 출력을 내보내는 뉴런을 얻게 될 것입니다. 따라서 시그모이드 함수의 자세한 수학적 형태 보다는 이러한 부드러운 그래프가 우리가 주목해야할 부분입니다. 이 함수의 부드러운 그래프는 가중치와 $bias$의 작은 변화가 작은 출력의 변화만을 만들어 낸다는것을 의미합니다. 다음과 같은 계산식은 뉴런의 출력값이\n\n$$\\begin{eqnarray} \\Delta \\mbox{output} \\approx \\sum_j \\frac{\\partial \\, \\mbox{output}}{\\partial w_j} \u0026nbsp;\\Delta w_j + \\frac{\\partial \\, \\mbox{output}}{\\partial b} \\Delta b,\\tag{5}\\end{eqnarray}$$\n\n와 근접한다는 것을 알려줍니다. 시그마는 모든 가중치 값, $w_{j}$에 대한 것이고 $\\partial output/\\partial w_{j}$와 $\\partial output/\\partial b$는 $output$의 $w_{j}$와 $b$에 대한 각각의 편미분을 의미합니다. 편미분에 대해 잘 알지 못하더라도 걱정하지 마세요! 위의 식이 복잡해 보일지 몰라도, 사실 굉장히 쉬운 이야기를 하고 있는 것 이랍니다.(좋은 소식이군요!): $\\Delta\u0026nbsp;output$은 가중치와 $bias$의 $\\Delta w_{j}$와 $\\Delta b$의 변화량에 대한 일차 함수 입니다. 이러한 직선성은 $output$에서의 우리가 원하는 작은 어떠한 변화도 이룰 수 있게 하는 가중치와 $bias$에서의 변화량을 선택하기 쉽게 해 줍니다. 그래서 시그모이드 뉴런이 퍼셉트론 처럼 굉장히 비슷한 점을 가지고 있음에도, 시그모이드 뉴런은 어떻게 가중치와 $bias$의 변화가 $output$을 어떻게 변화시킬지 알아내는것을 쉽게 해줍니다.\n\n시그모이드 함수의 그래프가 정확히 어떤 모양인지, 수학공식이 어떤지가 중요한 부분이 아니라면, 왜 우리는 (3)번식 처럼 특정한 형태의 식을 사용할까요? 사실, 이 책의 뒤에서 우리는 때때로 활성화 함수 $f$에 대한 출력이 $f(w\\cdot x+b)$인 뉴런을 다뤄야 합니다. 우리가 다른 활성화 함수를 사용할 때 변하는 가장 큰 것은 (5)번 식에서 편미분을 위한 특정한 값이 변한다는 것 입니다. 우리가 나중에 저 편미분을 계산 할 때, 시그모이드 함수를 사용하면 자연 상수는 미분할 때 굉장히 좋은 점을 가지고 있기 때문에(역주: $e^{x}$는 미분해도 $e^{x}$가 나온다) 식이 간단해 집니다. 어떤 상황에서든, 시그모이드 함수는 뉴런 네트워크에서 굉장히 자주 사용되고 또한 우리가 이 책에서 가장 많이 사용하는 활성화 함수 입니다.\n\n어떻게 우리가 시그모이드 뉴런으로 부터 $output$을 바로 얻어낼 수 있을까요? 당연히, 퍼셉트론과 시그모이드 함수의 가장 큰 차이점은 시그모이드 뉴런은 $output$이 단지 0 또는 1이 아니라는 겁니다. 이 뉴런은 0과 1 사이의 그 어떤 실수값이라도 가질 수 있습니다. 0.173... 그리고 0.689... 와 같은 값은 출력값으로써 적합한 값입니다. 이런점은 굉장히 유용히 쓰일 수 있습니다. 이를테면 우리가 출력값을 뉴런 네트워크로 들어가는 이미지의 픽셀들의 명도의 평균값을 표현하는데 쓰일 수 있습니다. 하지만 가끔 이는 귀찮은 점이 될 수도 있습니다. 우리가 \"입력된 이미지는 9야\" 또는 \"입력 이미지는 9가 아니야\"라고 판단하기 위한 네트워크로 부터 출력값을 얻어내고 싶다고 해 봅시다. 당연히, 출력값이 퍼셉트론 0과 1 이라면 굉장히 쉬울것 입니다. 하지만 실제로는 우리는 최소한 0.5의 값을 가지는 출력값을 \"9\"라고 하고 또 0.5보단 작은 값을 가지는 출력값을 \"9가 아님\"이라고 나타내기로 정해야 합니다. 제가 어떤 규칙을 만들고자 하면 반드시 그 규칙을 명확히 알려드릴테니, 지금 너무 혼란해 하지 않으셔도 됩니다.\n\n### 연습\n* 시그모이드 뉴런으로 퍼셉트론 시물레이션 하기, 첫번째\n우리가 퍼셉트론 네트워크에 있는 모든 가중치와 $bias$들을 취하여 양수 $c$ 를 곱했다고 가정해 봅시다. 이 네트워크의 결과가 전혀 변하지 않음을 증명해 보세요.\n* 시그모이드 뉴런으로 퍼셉트론 시물레이션 하기, 두번째\n우리가 아까 가져왔던 퍼셉트론 네트워크를 가지고 있다고 가정해 봅시다. 또한 그 네트워크에 입력될 값들을 선택해 두었다고 가정해 봅시다. 실제 값을 가져올 필요는 없습니다. 그냥 아무 고정된 값을 사용하세요. 모든 가중치와 $bias$들이 네트워크의 모든 퍼셉트론에서 입력값 $x$에 대해 $w\\cdot x+b \\neq 0$이라고 가정합시다. 이제 네트워크의 모든 퍼셉트론을 시그모이드 뉴런으로 교체하고 모든 가중치와 $bias$에 양수 $c$를 곱하세요. 만약 $c\\rightarrow \\infty$일때 시그모이드 네트워크의 결과가 퍼셉트론 네트워크와 일치함을 보이세요. 만약 한 퍼셉트론이라도 $w\\cdot x+b=0$이라면 결과가 어떻게 될까요?\n\n","slug":["2017-04-08-sigmoid-neurons"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"이 책이 다루고 있는 것\",\"date\":\"2017-04-08 21:08:00 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n뉴런 네트워크는 이제까지 발명된 프로그래밍 패러다임중 가장 아름다운 것중 하나입니다. 일반적인 프로그래밍 방법에서, 우리는 컴퓨터에게 무슨 일을 해야하는지, 큰 문제들을 작은 단위로 쪼개면서, 컴퓨터가 수행하기 쉽도록 일들을 명확히 명시하였습니다. 반면에 뉴런 네트워크에서는 우리는 컴퓨터에게 어떻게 문제를 해결해야 하는지 알려주지 않습니다. 대신, 관측 가능한 데이터로 부터 배우고, 스스로의 해결책을 만들어 내놓습니다.\n\n데이터로 부터 스스로 배운다는 사실이 매우 흥미로워 보입니다. 그러나 2006년 까지는 몇몇의 특정한 문제들을 제외하고서는 기존에 사용하던 해결책 보다 좋은 결과를 얻기 위한 학습 방법을 알지 못했습니다. 2006에 바뀐것은 딥 뉴런 네트워크라고 불리는 학습 기술입니다. 이 기술은 우리가 현재 딥 러닝 이라고 알고 있는 기술입니다. 이는 계속해서 개발되어 오늘날 딥 뉴런 네트워크와 딥 러닝은 컴퓨터 비젼, 음성 인식, 자연어 인식과 같은 매우 많은 중요한 문제들에 대한 이루 말할 수 없는 매우 놀라운 성과를 이루어 냈습니다. 이 기술은 구글, 마이크로 소프트 그리고 페이스북과 같은 회사들에 의해 넓은 영역에서 적용되고 사용되고 있습니다.\n\n이 책의 목표는 딥 러닝을 위한 현대적인 기술들을 포함하여 뉴런 네트워크의 핵심 개념들을 모두 습득할 수 있도록 여러분들을 돕는것 입니다. 이 책을 끝낸 뒤에는 여러분은 복잡한 패턴 인식 문제들을 풀 수 있는 뉴런 네트워크와 딥 러닝을 사용하는 코드를 작성할 수 있을 것 입니다. 또한 여러분은 여러분만의 문제들을 해결하기 위한 뉴런 네트워크와 딥 러닝을 사용할 수 있는 기반을 가지게 될 것 입니다.\n\n\u003c!-- more --\u003e\n\n# 원리 중심 접근\n\n이 책의 기초를 이루는 한 확신은 많고 많은 개념들의 얕은 이해 보다는 뉴런 네트워크와 딥 러닝의 핵심 원리들의 단단한 이해를 얻는 것이 훨씬 낫다는 것 입니다. 여러분이 핵심 개념들을 잘 이해 했다면, 여러분은 다른 새 내용들도 잘 이해할 수 있을것입니다. 컴퓨터 프로그래밍의 면에서, 새 언어에 대한 문법, 라이브러리와 데이터 구조를 습득하는것 이라고 생각해 보세요. 여러분은 아마 전체 언어들 중 극히 일부만을 알고있을 것 입니다. (많은 언어들은 방대한 기본 라이브러리를 가지고 있습니다) 그러나 새로운 라이브러리와 데이터 구조는 매우 쉽고 빠르게 배울 수 있습니다.\n\n이 말인 즉슨, 이 책은 결코 어떤 특정한 뉴런 네트워크 라이브러리를 사용하는 방법에 대한 강의가 아니라는 것 입니다. 만약 여러분이 라이브러리를 배우고자 이 책을 읽으려고 한다면, 이 책을 읽지 마세요! 배우고 싶은 라이브러리를 찾고, 강좌와 문서들을 통해 배우십시오. 그러나 명심하세요. 지금 당장의 문제를 해결할 수 있을지 몰라도 정말로 뉴런 네트워크에서 무엇이 일어나고 있는지 알고싶다면, 지금으로 부터 몇 년이 지나서도 여러분의 식견이 유지 되길 원한다면, 단지 어떤 라이브러리를 배우는것 만으로는 충분치 않습니다. 여러분은 어떻게 뉴런 네트워크가 움직이는지에 대한 오래가고 지속 가능한 식견을 배울 필요가 있습니다. 기술은 우리에게 오기도, 또 사라지기도 합니다. 그러나 우리의 식견은 영원합니다.\n\n# 실습 중심 접근\n\n우리는 실질적인 문제를 해결함으로써 뉴런 네트워크와 딥 러닝의 핵심 원리들을 배울 것 입니다. 바로 컴퓨터에게 손으로 쓴 숫자들을 인식하게 하는 문제입니다. 이 문제는 일반적인 프로그래밍 방법으로는 매우 해결하기 어려운 문제입니다. 하지만 곧, 앞으로 보겠지만, 이 문제는 간단한 뉴런 네트워크를 사용하면 아주 쉽게 해결할 수 있습니다. 단지 몇십줄의 코드만으도 말이죠. 또 어떠한 라이브러리를 사용하지 않고서도 말이죠. 한 술 더 떠서, 우리는 많은 반복을 통해 뉴런 네트워크와 딥 러닝에 대한 핵심 개념들을 서서히 더 많이 결합시키면서 프로그램을 개선해 나갈 것입니다.\n\n이러한 실습 중심 접근은 이 책을 읽기 위해 프로그래밍 경험이 필요하다는 것을 의미합니다. 하지만 여러분이 전문적인 프로그래머가 될 필요는 없습니다. 저는 파이썬 2.7 으로 코드를 작성해 두었습니다. 파이썬은 여러분이 파이썬으로 프로그래밍을 하지 않더라도 적은 노력으로도 이해하기 쉬울것이기 때문입니다. 이 책의 과정을 따라가면서 우리는 작은 뉴런 네트워크 라이브러리를 개발할 것 입니다. 여러분의 실험에 사용하고 이해를 돕기위한 것이지요. 모든 코드는 여기서 다운로드 할 수 있습니다. 한번 책을 다 읽고 나면, 실제 생산적인 사용을 위한 많은 기능을 포함한 뉴런 네트워크 라이브러리 중 하나를 골라 쉽게 사용할 수 있습니다.\n\n비슷한 맥락으로, 이 책을 읽기 위해 필요한 수학적 지식들 또한 대단할 필요가 없습니다. 대부분의 장에서는 몇몇 수학 공식들이 등장하지만, 이는 단지 초등 수학이거나 함수들의 그래프에 불과합니다. 많은 독자들이 아마 이해하는데 무리가 없을 것 입니다. 때때로 저는 고급 수학 공식들을 사용하지만 중요한 내용들을 정리해 두어 여러분은 몇 수학적 세부사항들을 무시할지라도 잘 따라올 수 있을겁니다. 예외적으로 굉장히 어려운 수학 공식들이 등장하는 장은 제 2장입니다. 다항 함수 연산과 선형 수학이 사용됩니다. 저 둘은 비슷하진 않지만, 저는 제 2장에서 어떻게 수학을 다뤄야 하는지 논의와 함께 시작하였습니다. 만약 너무 어렵다고 생각이 든다면, 요약문으로 넘어가 결과만 확인할 수도 있습니다. 어떤 상황이건, 시작부터 이것에 대해 너무 걱정할 필요는 없습니다.\n\n책에서 원리 중심 접근과 실습 중심 접근 둘다 동시에 초점을 맞추어 진행하는 것은 흔지 않습니다만, 저는 뉴런 네트워크의 근본적 개념을 쌓는다면 여러분이 매우 잘 배울 수 있을것이라고 믿습니다. 우리는 단지 추상적인 이론이 아닌 살아있는 코드를 작성하게 될 것입니다. 여러분은 또한 그 코드를 탐색하고, 확장할 수 있습니다. 이를 통해 여러분은 이론과 실습 양쪽 모두에서 궁극적인 것들을 이해하고 여러분의 지식을 넓힐 수 있을것 입니다.","slug":["2017-04-08-what-this-book-is-about"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"손으로 쓴 숫자를 구분하기 위한 간단한 네트워크\",\"date\":\"2017-04-09 14:04:14 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n뉴런 네트워크에 대해 정의하면서, 다시 손으로 쓴 숫자를 인식하기 위한 문제로 돌아와 봅시다. 우리는 이 문제를 크게 두개의 문제로 나누어 생각할 수 있습니다. 첫째로, 많은 숫자가 포함된 이미지를 여러개의 조각난 이미지로 나누는 것입니다. 각각의 조각난 이미지는 하나의 숫자를 가지고 있습니다. 예를 들어, 다음과 같은 이미지는\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/digits.png\" style=\"cursor: pointer;max-width:100%;height:auto\" onclick=\"open_img('https://cfile2.uf.tistory.com/original/227E6F4958E9BE12217489')\"  height=\"64\" style=\"width: 312px; height: 64px;\" width=\"312\" /\u003e\u003c/center\u003e\n\n다음과 같이 여섯 개의 이미지로 나누어 질 수 있습니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/digits_separate.png\" style=\"max-width:100%;height:auto\"  height=\"99\" width=\"630\"/\u003e\u003c/center\u003e\n\n\u003c!-- more --\u003e\n\n우리와 같은 인간들은 이 분리 문제를 쉽게 해결할 수 있으나, 이를 정확히 나누는 컴퓨터 프로그램에게는 꽤 도전적입니다. 일단 한번 이미지가 분리되고 나면, 프로그램은 각 이미지를 판별해야 합니다. 그래서, 예를 들면, 우리는 위에 있는 이미지중 첫번 째 이미지의 숫자를 판별하는 프로그램을 작성하고자 합니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/mnist_first_digit.png\" style=\"max-width:100%;height:auto\"  height=\"35\" width=\"31\"/\u003e\u003c/center\u003e\n\n첫번째 이미지는 위와같이 5가 쓰여진 이미지 입니다.\n\n우리는 각각의 이미지의 숫자를 판별하는것에 대한 두번째 문제를 해결할 프로그램을 작성하는것에 초점을 맞추려고 합니다. 왜냐하면 분리 문제는 한번 숫자 판별 문제를 해결하고 나면 해결하는데 그리 어렵지 않기 때문입니다. 분리 문제를 해결하는데는 많은 접근 방법이 있습니다. 한 접근 방법은 이미지를 분리하는 여러가지 다른 방법들을 시도해 보는 것 입니다. 각각의 숫자를 식별하는 프로그램을 이용해서 분리를 시도한 이미지에 점수를 매기는 것이지요. 분리를 시도한 이미지는 숫자 식별 프로그램에 의해 점수가 매겨집니다. 각 분리된 이미지의 숫자를 식별하는데 어려움을 겪는다면 이미지는 낮은 점수를 받게 되겠지요. 이 아이디어와 다른 다양한 방법들은 이러한 분리 문제를 꽤나 잘 해결할 수 있습니다. 그러니 분리문제에 대해 걱정하는것 보다는 우리는 더 흥미롭고 어려운 문제를 푸는, 각각의 손으로 쓴 숫자를 인식하는 네트워크를 작성하는데 집중하고자 합니다.\n\n각각의 숫자를 인식하기 위해서는, 우리는 3층 뉴런 네트워크를 사용해야 합니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz12.png\" style=\"max-width:100%;height:auto\"  height=\"447\" width=\"537\"/\u003e\u003c/center\u003e\n\n네트워크의 입력 레이어는 입력 픽셀들의 변환된 값들을 가지고 있습니다. 다음 차례에서 이야기 하겠지만, 우리의 네트워크를 위한 학습 자료는 $28\\times 28$크기의 많은 손글씨 이미지들로 이루어져 있습니다. 그러니 입력 레이어는 $784=28\\times 28$크기의 뉴런들을 가지게 될겁니다. 간략하게 나타내기 위해서 저는 위 그림처럼 대부분의 뉴런들을 생략하였습니다. 입력 픽셀들은 흑백값입니다. 0.0은 흰색, 1.0은 검정을 나타냅니다. 0.0 에서 1.0으로 숫자가 증가할 수록 점점 어두워 지는 값을 가지게 됩니다.\n\n네트워크의 두번째 층은 은닉층 입니다. 우리는 은닉층의 뉴런들의 갯수를 n으로 나타내기로 합시다. 그리고 n에 여러 다른 값을 넣어서 실험을 해볼겁니다. 위에 보여드린 예는 단지 15개의 뉴런만을 가진 은닉층을 가지고 있습니다.\n\n위 네트워크의 출력층은 10개의 뉴런을 가지고 있습니다. 첫번째 뉴런이 발화하면, 즉 1에 가까운 값을 가지게 되면, 이는 네트워크가 숫자는 0이다 라고 생각하고 있슴을 나타냅니다. 두번째 뉴런이 발화하면 이는 네트워크가 숫자는 1이다 라고 생각하고 있음을 나타냅니다. 나머지도 마찬가지 입니다. 정확히 말하면, 우리는 출력 뉴런들을 첫번째 뉴런부터 열번째 뉴런까지 차례로 보면서 어떤 뉴런이 가장 크게 발화되었는지를 확인함으로써 숫자를 판별합니다. 만약 그 뉴런이 여섯번째 뉴런이라면, 네트워크는 입력 숫자가 6이라고 추측하는겁니다. 그리고 다른 뉴런들도 마찬가지 입니다.\n\n여러분은 아마 왜 우리가 10개의 뉴런을 사용하는지 궁금해 하실겁니다. 어쨌거나 네트워크로 우리가 하고자 하는것은 입력 이미지에 해당하는 숫자가 어떤것인지 밝혀내는것 입니다. 그냥 겉으로 보면 이 목적을 이루기 위해서는 단지 네개의 뉴런만으로도 가능해 보입니다. \u0026nbsp;뉴런의 출력을 0에 가까운지 1에 가까운지에 따라 각 뉴런을 이진 출력으로 본다면 네개의 뉴런으로는 $2^4=16$만큼의 수를 표현할 수 있습니다. 그렇기 때문에 10까지의 숫자를 표현하는데 충분하고도 남습니다. 그렇다면 우리는 왜 10개의 뉴런을 사용해야 할까요? 비효율적이지 않을까요? 궁극적으로 타당한 이유를 대자면 경험적인 이유 때문입니다: 우리는 두개의 네트워크 디자인을 모두 시도해 볼 수 있습니다. 시도해 보니, 네개의 뉴런을 사용한 네트워크보다는 열개의 뉴런을 사용했을때 학습이 훨씬 더 잘 이루어 졌습니다. 하지만 이러한 결과는 왜 열개의 뉴런을 사용한 네트워크가 네개의 뉴런을 사용한 네트워크보다 훨씬 결과가 좋았는지에 대한 궁금증을 남기는군요. 우리가 네개의 출력 대신에 열개의 출력을 사용해야 한다는 것을 자세히 알려줄 경험적 사례가 있을까요?\n\n왜 우리가 이것을 하는지 이해하기 위해서는, 첫번째 원리로 부터 뉴런 네트워크가 무엇을 하는지에 대해 생각해 보는것이 도움이 됩니다. 우리가 열개의 뉴런을 사용할때의 경우를 생각해 봅시다. 입력된 이미지의 숫자가 0인지 아닌지 결정하는 출력 뉴런들 중 첫번째 뉴런을 한번 봅시다. 이 뉴런은 입력층으로 부터 가져온 정보들에 가중치를 곱하여 의사결정을 내리게 됩니다. 은닉층의 뉴런들의 하는일은 뭔가요? 일단, 그냥 논의를 해보기 위해 은닉층의 첫번째 뉴런이 다음과 같은 이미지가 드러나는지 아닌지 감지한다고 가정해 봅시다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/mnist_top_left_feature.png\" style=\"cursor: pointer;max-width:100%;height:auto\" onclick=\"open_img('https://cfile8.uf.tistory.com/original/233D164B58EB9B0E2B73E4')\"  height=\"200\" original=\"yes\" style=\"width: 194px; height: 200px;\" width=\"194\" /\u003e\u003c/center\u003e\n\n이 이미지와 겹치는 픽셀들에 가중치를 무겁게 두고 나머지는 가볍게 둠으로써 이 이미지가 드러나는지 않는지 감지할 수 있습니다. 비슷한 방법으로 은닉층의 두번째, 세번째, 네번째 뉴런이 다음과 같은 이미지가 드러나는지 아닌지 감지한다고 해봅시다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/mnist_other_features.png\" style=\"max-width:100%;height:auto\"  height=\"203\" width=\"636\"/\u003e\u003c/center\u003e\n\n아마 보이시겠지만, 이 네장의 이미지를 모두 겹치면 \u003ca href=\"https://neuralnetworksanddeeplearning.com/chap1.html#complete_zero\" target=\"_blank\" class=\"tx-link\"\u003e앞에서 본 숫자 0 이미지\u003c/a\u003e가 됩니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/mnist_complete_zero.png\" style=\"cursor: pointer;max-width:100%;height:auto\" onclick=\"open_img('https://cfile22.uf.tistory.com/original/2230F84B58EB9B0F102A5D')\"  height=\"200\" original=\"yes\" style=\"width: 199px; height: 200px;\" width=\"199\" /\u003e\u003c/center\u003e\n\n그러므로 이 네개의 뉴런들이 모두 발화할때 우리는 이 숫자가 0이라고 말 할 수 있습니다. 당연히, 이미지가 0이라고 결정짓기 위해 사용하는 근거는 이것만 있지는 않습니다. 우리는 다른 방법으로도 0이라는 숫자를 얻어낼 수 있습니다. 하지만 최소한 이 상황에서는 우리가 입력 이미지가 0이었다고 잘 판단했다 말할 수 있겠군요.\n\n뉴런 네트워크가 이런 식으로 작동한다고 가정하면, 네개보다 열개의 뉴런을 가지는 것이 왜 좋은지에 대한 그럴듯한 설명할 할 수 있습니다. 만약 우리가 네개의 출력을 가지고 있다면, 첫번째 출력 뉴런은 숫자의 가장 중요한 비트가 무엇인지 결정하려고 할겁니다. 그리고 저 가장 중요한 비트를 위와같은 간단한 도형과 관련짓는 쉬운 방법은 없습니다. 숫자의 부분적인 형태가 출력의 가장 중요한 비트와 큰 관련이 있을거라는 그 어떤 좋은 역사적, 경험적 이유가 있을거라고는 상상하기 힘듭니다.\n\n이제 제가 말한 모든것들은 경험적인 것들 입니다. 그 무엇도 3층 뉴런 네트워크가 제가 설명한 방법대로 작동할 것이라고 말하지 않습니다. (은닉층의 뉴런이 숫자의 부분적 형태를 감지한다는 설명) 아마 현명한 학습 알고리즘은 우리에게 단지 네개의 뉴런만을 사용할 수 있도록 해줄 가중치를 찾을 것 입니다. 하지만 경험적으로는 제가 설명한 방법은 잘 작동합니다. 그리고 좋은 뉴런 네트워크 구조를 설계하는데 시간을 절약해 줄 것입니다.\n\n### 연습\n위의 삼층 네트워크에 새로운 층을 추가함으로써 숫자의 이진수 표현을 결정할 수 있는 방법이 있습니다. 새로운 층은 전에 있던 출력 층으로 부터 나온 숫자를 아래 나온것 처럼 이진수 표현법으로 변환하는 역할을 합니다. 새 출력 층에 알맞는 가중치들과 $bias$들을 찾아보세요. 첫번째 세개의 층이 세번째 층의 올바른 출력이 이루어 졌을때 그 값이 최소한 0.99가 되고 나머지는 0.01이 되는 층이라고 가정하세요.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz13.png\" style=\"max-width:100%;height:auto\"  height=\"304\" width=\"545\"/\u003e\u003c/center\u003e\n","slug":["2017-04-09-a-simple-network-to-classify-handwritten-digits"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"뉴런 네트워크의 구조\",\"date\":\"2017-04-09 13:50:37 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n다음 차례에서는 손글씨를 꽤 잘 인식할 수 있는 뉴런 네트워크를 소개해 드릴겁니다. 그 전에, 네트워크의 각 부분을 부르는 몇 개의 전문 용어들을 설명하는 것이 도움이 되겠군요. 우리가 아래와 같은 네트워크를 가지고 있다고 해봅시다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz10.png\" style=\"max-width:100%;height:auto\"  height=\"211\" style=\"\" width=\"396\"/\u003e\u003c/center\u003e\n\n앞서 언급했듯이, 가장 왼쪽에 위치한 층은 입력 층이라고 불리고, 그 안에 있는 뉴런들은 입력 뉴런이라고 불립니다. 가장 오른쪽에 있는 출력층은 출력 뉴런들을 가지고 있습니다. 위 예시에서는 하나의 뉴런만을 가지고 있군요. 가운데 있는 층은 입력 뉴런 또는 출력 뉴런을 가지고 있지 않으므로 은닉층이라고 불립니다. \"은닉\"이라는 용어는 이상하게 들릴 수 있습니다. (제가 처음 이 단어를 들었을때는 이 은닉층이 꽤 깊은 철학적 의미 또는 수학적 중요성을 가지고 있는줄 알았습니다.) 하지만 은닉층은 정말 \"입력 또는 출력이 아님\" 이라는 의미 그 이상, 그 이하도 아닌 그 자체를 의미합니다. 위에 있는 네트워크는 단 하나의 은닉 레이어만을 가지고 있지만 몇몇 네트워크들은 여러개의 은닉층을 가지고 있습니다. 예를 들면, 다음의 4층 네트워크는 두개의 은닉층을 가지고 있습니다.\n\n\u003c!-- more --\u003e\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz11.png\" style=\"max-width:100%;height:auto\"  height=\"324\" style=\"\" width=\"597\"/\u003e\u003c/center\u003e\n\n혼란스럽게도, 어떤 역사적인 이유로 인해 다층 네트워크들은 시그모이드 뉴런으로 이루어져 있음에도 불구하고 다층 퍼셉트론 또는 MLPs(Multi Layer Percptrons)라고 불립니다. 저는 이 책에서 MLP라는 전문용어를 사용하진 않을테지만, 여러분에게 이런 용어가 있음을 알려드리고 싶었습니다.\n\n네트워크에서 이런 입력과 출력층의 구조는 일반적으로 일방통행적입니다. 예를 들어, 우리가 손글씨 이미지가 \"9\"를 나타내는지 아닌지를 결정하려고 한다고 합시다. 이 네트워크를 디자인 하는 일반적 방법은 입력층에 들어갈 이미지의 픽셀들의 명도를 변환하는것 입니다. 이미지의 크기가 $64\\times 64$ 인 흑백 이미지라면, 우리는 $4096=64\\times 64$개의 입력 뉴런들을 가지게 되고, 명도값들은 0과 1 사이의 값을 가지게 됩니다. 출력층은 단 한개의 출력뉴런만을 가지게 되고 0.5 보다 작은 값은 \"이 이미지는 9가 아닙니다\"를, 0.5보다 큰 값은 \"이 이미지는 9 입니다\"를 나타내게 됩니다.\n\n뉴런 네트워크의 입력과 출력층들의 구조가 일반적으로 일방통행적 이지만, 은닉층의 디자인에 꽤나 예술적인 면이 있을 수 있습니다. 이러한 상황에서는, 단지 몇개의 간단한 규칙만으로 은칙층의 계산과정을 줄일 수 없습니다. 대신, 뉴런 네트워크 연구자들은 네트워크에서 이끌어 내고자 하는 행동을 얻게 도와주는 은닉층을 위한 많은 간편한(heuristic, 어림짐작의) 구조를 개발해 냈습니다. 예를 들면, 어떤 간편한 방법은 어떻게 네트워크를 학습시키기 위해 필요한 시간에 대해 은닉층의 수를 결정할 것인지 도와줍니다. 우리는 나중에 이 책에서 몇개의 경험적 방법들을 배워볼 겁니다.\n\n지금까지 우리는 한 층의 출력이 다음 레이어의 입력으로써 쓰이는, 일방통행적 뉴런 네트워크에 대해서 이야기 해 왔습니다. 이런 네트워크들은 feedforward 뉴런 네트워크라고 불리는데, 이는 네트워크에 어떠한 재귀도 존재하지 않음을 의미합니다. 정보는 항상 앞으로 이동합니다. 절대로 뒤로 영향을 주지 않습니다. 만약 우리가 재귀를 가지게 된다면, 우리는 시그모이드 함수로 들어가는 입력값에 따라 출력값이 달라지는 상황과는 다른 상황을 맞이하게 될 것입니다. 이에 대한 개념을 배우기는 어려우니, 우리는 그러한 재귀를 만들지 않을 것 입니다.\n\n그러나, 뒤로 영향을 주는 재귀가 가능한 가상 뉴런 네트워크의 다른 모델들 또한 존재합니다. 이런 모델들은 \u003ca href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network\" target=\"_blank\" class=\"tx-link\"\u003e회귀적 뉴런 네트워크\u003c/a\u003e라고 불립니다. 이러한 모델의 개념은 활성화 된 상태가 끝나기 전에 일정시간 동안 발화하는 뉴런이 있다는 것 입니다. 이러한 발화는 다른 뉴런들에 영향을 주어서 일정시간 간격을 두고 일정시간 동안 발화하게 할 수 있습니다. 이는 또한 더 많은 뉴런들을 발화하게 할 수 있고, 시간이 지남에 따라 계속 진행되는 뉴런의 발화를 볼 수 있을 것 입니다. 루프는 이러한 모델에서 뉴런의 출력은 즉시 이루어 지지 않고 일정 시간 간격을 두고 자신의 입력에만 영향을 미치기 때문에 어떠한 문제도 일으키지 않습니다.\n\n회귀적 뉴런 네트워크는 학습 알고리즘이 다른 네트워크 모델보다 강력하지 않기 때문에 feedforward 네트워크 보다는 적은 영향력을 행사하고 있습니다. 하지만 이런 회귀적 네트워크는 여전히 흥미로운 모델입니다. 이는 우리의 뇌가 작동하는 방법과 feedforward 네트워크보다 비슷합니다. 또한 회귀적 네트워크는 feedforward 네트워크로는 굉장히 어렵게 풀어야 하는 문제들을 풀 수 있습니다. 그러나, 우리의 능력의 한계로 인해, 이 책에서는 더 자주 사용되는 feedforward 네트워크에만 집중 하려고 합니다.\n\n","slug":["2017-04-09-the-architecture-of-neural-networks"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"기울기 하강 알고리즘으로 학습\",\"date\":\"2017-04-11 00:20:10 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n이제 우리는 우리의 뉴런 네트워크를 위한 설계도를 가지고 있습니다. 어떻게 하면 이 네트워크가 숫자를 인식하도록 학습을 할 수 있을까요? 우리에게 필요한 첫번째는 학습 데이터 셋이라고 불리는 데이터 입니다. 우리는 \u003ca href=\"https://yann.lecun.com/exdb/mnist/\" target=\"_blank\" class=\"tx-link\"\u003eMNIST 데이터 셋\u003c/a\u003e을 사용할 것 입니다. 이는 정확한 분석결과와 함께 손으로 쓰인 수만개의 숫자들을 스캔한 이미지를 가지고 있습니다. MNIST의 이름은 \u003ca href=\"https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology\" target=\"_blank\" class=\"tx-link\"\u003eNIST\u003c/a\u003e에 의해 수집된 두개의 데이터 셋을 수정한 별도의 셋이라는 사실로 부터 지어졌습니다. NIST는 United States' National Institute of Standards and Technology의 약자 입니다. 아래 사진은 MNIST로 부터 가져온 몇장의 사진 입니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/digits_separate.png\" style=\"max-width:100%;height:auto\"  height=\"99\" width=\"630\"/\u003e\u003c/center\u003e\n\n위에 보이는 것 처럼, 이 숫자들은 사실 \u003ca href=\"https://neuralnetworksanddeeplearning.com/chap1.html#complete_zero\" target=\"_blank\" class=\"tx-link\"\u003e이 챕터의 시작\u003c/a\u003e에서 보여드린 것과 같은 이미지입니다. 당연히, 우리의 네트워크를 시험할때에는 이 학습 셋에 있지 않은 이미지들을 사용할것입니다!\n\n\u003c!-- more --\u003e\n\nMNIST 데이터 셋은 두개의 부분으로 나뉩니다. 첫번째 부분은 학습 셋으로 사용될 60,000개의 이미지로 이루어져 있습니다. 이 이미지들의 반은 US Census Beureau 직원들과 반은 고등학생으로 이루어진 250명의 사람들로 부터 스캔한 이미지 입니다. 이 이미지들은 $28\\times 28$크기의 흑백 사진입니다. 우리는 이것을 우리의 네트워크가 숫자를 인식하는것에 얼마나 잘 학습되었는지 평가하기 위해 사용할 것입니다. 좋은 성능 테스트를 하기 위해 테스트 셋은 원본 학습 데이터에 있던 사람과는 다른 250명의 사람들로 부터 가져왔습니다.(비록 모집단은 여전히 Census Bereau 직원들과 고등학생이지만요.) 이는 우리의 시스템이 학습하는 동안 보지 못한 사람들이 쓴 숫자들을 인식할 수 있는지 우리에게 확신을 줄 수 있도록 도와줄 것입니다. 우리는 학습 입력 데이터를 표시하기 위해 $x$라는 기호를 사용할 것입니다. 각각의 입력 $x$를 $28\\times 28=784$차원의 백터로 생각하는것이 편할겁니다. 백터의 각 성분은 이미지의 각 픽셀의 명도를 나타냅니다. 우리는 $y=y(x)$로써 우리가 각 입력마다의 우리가 원하는 출력값을 나타낼겁니다. $y$는 10차원 백터입니다. 예를 들어, 6을 나타내는 특정한 학습 이미지 $x$에 대해 $y(x)=(0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$가 네트워크로 부터 우리가 원하는 출력이 됩니다. $T$는 여기서 열 백터를 일반적인 행 백터로 바꿔주는 $transpose$ 연산이라는 것을 알아두세요.\n\n우리가 원하는 것은 가중치와 $bias$를 찾아서 네트워크로 부터 나온 출력값이 모든 학습 데이터 $x$에 대해 $y(x)$의 값과 거의 같도록 하는 알고리즘을 만드는 것 입니다. 얼마나 우리가 이 목표를 잘 달성하였는지 수치로 나타내기 위해 우린 비용함수 라는 것을 하나 정의할것 입니다.\n\n$$\\begin{eqnarray}  C(w,b) \\equiv\\frac{1}{2n} \\sum_x \\| y(x) - a\\|^2.\\tag{6}\\end{eqnarray}$$\n\n여기 $w$는 네트워크의 모든 가중치($weight$)를 의미하고 $b$는 모든 $bias$, $n$은 학습 이미지의 총 갯수, $a$는 $x$가 입력으로 주어졌을때의 네트워크에서의 출력, 그리고 시그마는 모든 학습 이미지 $x$에 대한 값 입니다. 당연히 출력 $a$는 $x$, $w$ 그리고 $b$에 종속되어 있습니다. 하지만 이 공식을 간단하게 하기 위해서 아직 이 종속관계를 명확하게 밝히지 않았습니다. $\\|v\\|$라는 기호는 백터 $v$에 대한 길이만을 의미합니다. 우리는 이 $C$라는 함수를 이차 비용 함수라고 부릅니다. 이 함수는 mean squared error 또는 MSE라고 불리기도 합니다. 이차 비용 함수의 형태를 보니, $C(w, b)$는 시그마가 음수가 될 수 없기에 양수의 값만을 가진다는 것을 알 수 있습니다. 또한, $C(w, b)$는 $y(x)$가 모든 학습 데이터 $x$에 대한 출력 $a$와 비슷해 질 때 $C(w, b)\\approx 0$ 이 됨을 알 수 있습니다. 그러므로 우리의 학습 알고리즘은 가중치와 $bias$를 잘 찾아서 $C(w, b)\\approx 0$가 될 때 잘 학습되었다고 말할 수 있습니다. 반대로, $C(w, b)$의 값이 크다면 잘 학습되지 않은 것 입니다. 이는 많은 수의 입력 데이터에 대한 출력 $a$와 $y(x)$가 비슷한 값을 가지지 않음을 의미합니다. 그러므로 우리의 학습 알고리즘의 초점은 가중치와 $bias$에 대한 함수로써 $C(w, b)$의 값을 최소화 하는것 입니다. 다른말로, 우리는 비용함수의 값을 가능한 작게 만드는 가중치와 $bias$를 찾고싶은 것 입니다. 우리는 이를 기울기 하강 알고리즘이라고 불리는 알고리즘을 통해 구현할 것 입니다.\n\n왜 비용 함수를 소개했을까요? 다른걸 다 떠나서, 우리는 첫째로 네트워크에 의해 정확히 판별되는 이미지에 관심있던것 아니었나요? 왜 비용함수와 같은 간접적인 수치를 최소화 하는것이 아닌 그 갯수 자체를 높이는것에 초점을 맞추지 않는것일까요? 문제는 정확히 판별된 이미지의 갯수는 네트워크의 가중치와 $bias$에 대한 부드러운 함수로 표현되지 않는다는 것 입니다. 대부분 가중치와 $bias$의 작은 변화를 만드는 것이 정확히 판별되는 학습 이미지의 갯수의 변화를 만들어 내지 못합니다. 이는 어떻게 향상된 성능을 얻기 위해 가중치와 $bias$를 바꾸어야 하는지 알아내는것을 어렵게 합니다. 만약 우리가 이차 비용 함수와 같은 부드러운 함수를 사용하게 된다면, 어떻게 비용적 측면에서 향상을 이끌어 내기 위해 가중치와 $bias$에서 작은 변화를 만들어야 할지 알아내기 쉬울것입니다. 이것이 우리가 비용함수의 최소화에 초점을 맞추는 이유입니다. 그리고 나중에 우리는 판변의 정확도에 대해서 검토하게 될겁니다.\n\n우리가 부드러운 비용 함수를 사용하고 싶다고 이야기 하였는데, 여러분은 아마 왜 우리가 (6)번 공식과 같은 이차 함수를 선택했는지 궁금해 하실지도 모르겠습니다. 과연 우리가 원하는 목적에 맞는 선택일까요? 우리가 다른 비용함수를 선택하면 전혀 다른 가중치와 $bias$를 가지게 되지 않을까요? 이는 충분히 걱정할만한 부분입니다. 나중에 우리는 이 비용함수로 다시 돌아와서 몇개를 수정할겁니다. 그러나, 6번 식의 이차 비용 함수는 뉴런 네트워크에서 학습의 기초를 다지는데 큰 도움을 줍니다. 그러니 일단은 우리는 이 함수를 사용하도록 합시다.\n\n요약하자면, 뉴런 네트워크에서의 우리의 목표는 이차 비용 함수 $C(w, b)$의 값을 최소화 할 수 있는 가중치와 $bias$를 찾는것 입니다. 이는 우량 조건 문제(역주: 문제의 답이 존재하고 그 해가 유일하게 결정될 수 있는 조건의 문제)입니다. 하지만 현재 우리에게는 이 목표를 이루는것을 흐리게 하는 여러가지 요소들이 있습니다. 가중치와 $bias$에 대한 이해, 시그모이드 함수, 네트워크 구조의 선택, MNIST, 기타 등등... 우리가 대부분의 저 요소들을 잠시 무시하고 함수 최소화 문제에만 집중함으로써 더 많은것을 이해할 수 있을것입니다. 일단 지금은 비용함수의 정확한 식, 뉴런 네트워크의 연결 기타 등등에 대한 모든것을 잊읍시다. 대신, 우리가 많은 변수를 가진 함수를 우리가 가지고 있고 우리가 그 함수의 값을 최소화 하고 싶다고 상상해 보려고 합니다. 우리는 최소화 문제와 같은 것을 풀기위해 사용될 수 있는 기울기 하강 알고리즘이라고 불리는 기술을 배울것 입니다. 그런뒤에 우리는 뉴런 네트워크에서 최소화 하고자 하는 특정한 함수로 돌아갈 것 입니다.\n\n좋습니다, 우리가 $C(v)$라는 어떤 함수를 최소화 하려고 한다고 가정해 봅시다. 이 함수는 $v=v_{1}, v_{2}...$ 처럼 많은 변수에 대한 그 어떤 함수도 될 수 있습니다. 제가 이 함수가 그 어떤 함수도 될 수 있음을 강조하기 위해 $w$와 $b$를 $v$로 치환하였습니다. 우리는 더 이상 뉴런 네트워크의 맥락에서 생각하지 않을것입니다. $C(v)$를 최소화 하려면 $C$함수를 단지 두개의 변수를 가진 함수로 생각해 보는것이 도움이 되겠군요. 그 두개의 변수를 $v_{1}$와 $v_{2}$라고 부르도록 합시다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/valley.png\" style=\"max-width:100%;height:auto\"  height=\"612\" width=\"812\"/\u003e\u003c/center\u003e\n\n우리가 하고싶은 것은 $C$가 최소인 곳을 찾는 것 입니다. 지금 위 함수에서는 당연히 눈을 돌려 $C$가 최소인곳을 어렵지 않게 찾을 수 있습니다. 제가 너무 간단한 예를 들어드린것 같군요! 일반적인 경우의 함수 $C$는 아마 많은 변수를 가지고 있을겁니다. 그리고 보통은 눈으로 그래프의 최소인곳을 찾기는 아마 불가능할겁니다.\n\n이 문제를 해결하는 한가지 방법은 분석적으로 최소를 찾기위해 미적분을 사용하는 것 입니다. 우리는 미분을 통해 $C$가 극값을 가지는 곳을 찾을 수 있을 것 입니다. $C$가 한개 또는 두세개 정도의 변수만을 가지고 있다면 이 방법은 아마 잘 통할겁니다. 하지만 우리가 더 많은 변수를 가지고 있다면 이는 악몽같은 방법이 될겁니다. 그리고 뉴런 네트워크에서는 보통 더 많은 변수를 가지고 있습니다. 가장 큰 뉴런 네트워크는 엄청나게 복잡한 형태의 가중치와 $bias$에 대한 비용함수를 가지고 있습니다. 최소화를 하는 방법으로 단지 미적분을 사용하는것은 그냥은 먹히지 않을것 입니다!\n\n()\n\n그렇습니다, 미적분은 먹히지 않습니다. 하지만 운좋게도, 꽤 잘 먹히는 알고리즘을 이끌어 낼 수 있는 아름다운 유추 방법이 하나 있습니다. 우리의 함수를 하나의 계곡으로 생각하면서 시작해 봅시다. 여러분이 위의 그래프에서 눈을 찌푸리지 않았다면 그리 어렵지 않을겁니다. 그리고 계곡의 비탈면으로 구르는 공을 한번 상상해 봅시다. 우리의 일상에서의 경험은 공이 결국에는 계곡의 바닥으로 굴러갈것이라고 말해줍니다. 우리가 이 아이디어를 함수의 최소를 찾는데 사용할 수 있을까요? 우리는 상상속의 공의 시작점을 아무데나 고르고, 계속 바닥으로 공이 구르도록 움직임을 시물레이션 할겁니다. 우리는 $C$의 미분 계산을 통해 (또는 이계도함수) 이 시물레이션을 간단히 해낼 수 있습니다. 이 미분은 계곡의 모양에 대해 알기위해 필요한 모든것을 알려줍니다. 그러므로 어떻게 우리의 공이 구르게 될지도 알려줍니다.\n\n제가 설명한것만 보면, 마찰 또는 중력 등을 고려해서 공의 움직임에 대한 뉴턴 방정식을 쓰는것은 아닐까 생각하실수도 있지만, 그렇게 까지 심각하게 공의 움직임을 유츄하지는 않을것입니다. 우리는 $C$를 최소화 하기 위한 알고리즘을 고안하고 있는것이지, 물리 법칙의 정확한 시물레이션을 하고자 하는것이 아닙니다! 공이라는 시각은 우리의 상상을 시물레이션 하기 위함이지, 우리의 생각을 구속하기 위함이 아닙니다. 그러므로 물리의 방대한 세부사항 전체를 파고들기 보단 우리 스스로에게 한번 물어봅시다. 만약, 우리가 하루동안 신이 될 수 있다면, 그리고 물리의 법칙을 우리가 스스로 만들 수 있다면, 공이 어떻게 굴러야 하는지 규칙을 정할 수 있다면, 어떤 움직임의 법칙을 골라야 공이 항상 계속의 바닥면으로 구르게 할 수 있을까요?\n\n이 질문을 좀 더 명확히 하자면, 우리가 공을 $v_{1}$방향으로 작은 $\\Delta v_{1}$만큼 움직이고 $v_{2}$ 방향으로 작은 $\\Delta v_{1}$ 만큼 움직였을 때 무엇이 일어나는지에 대해 생각해 봅시다. 미분식은 $C$가 다음과 같이 변함을 보여줍니다.\n\n$$\\begin{eqnarray}   \\Delta C \\approx \\frac{\\partial C}{\\partial v_1} \\Delta v_1 +  \\frac{\\partial C}{\\partial v_2} \\Delta v_2.\\tag{7}\\end{eqnarray}$$\n\n우리는 $\\Delta C$가 음수가 되도록 하는 $\\Delta v_{1}$과 $\\Delta v_{2}$를 고르는 방법을 찾을겁니다. 즉, 계곡 아래로 공이 구를 수 있도록 하는 값을 찾을겁니다. 어떻게 그렇게 선택을 할 수 있는지 알아내려면 $\\Delta v$를 $\\Delta v\\equiv (\\Delta v_{1}, \\Delta v_{2})^{T}$처럼 $v$에서의 변화량에 대한 백터로 정의하는것이 도움이 됩니다. 여기서 $T$는 $transpose$ 연산자로써, 열 백터를 행 백터로 바꿔줍니다. 또한 우리는 C의 기울기를 $\\left(\\frac{\\partial    C}{\\partial v_1}, \\frac{\\partial C}{\\partial v_2}\\right)^T$ 와 같이 편미분의 백터로 정의할 것 입니다. 그리고 우리는 이 기울기 백터를 $\\nabla C$으로 표현할 것 입니다.\n\n$\\begin{eqnarray}   \\nabla C \\equiv \\left( \\frac{\\partial C}{\\partial v_1},   \\frac{\\partial C}{\\partial v_2} \\right)^T.\\tag{8}\\end{eqnarray}$\n\n후에 우리는 $\\Delta C$의 변화를 $\\Delta v$와 기울기 $\\nabla C$에 대해서 다시 정의할겁니다. 이것에 대해 알아보기 전에, 가끔 몇몇 사람들이 이 기울기에서 막힌다는 것을 알려드리고 싶군요. $\\nabla C$라는 기호를 처음 만나게 되면, 사람들은 가끔 $\\nabla$라는 기호에 대해 어떻게 생각해야 하는지 궁금해 하곤 합니다. 정확하게 $\\nabla$이 의미하는 바는 뭘까요? 사실, $\\nabla C$자체를 하나의 수학 기호로 봐도 무방합니다. $\\nabla$는 단지 \"이봐, $\\nabla C$는 기울기 백터야\"라고 말할때 쓰이는 기호의 일부분에 불과합니다. $\\nabla C$가 예를들면 미분 연산자처럼 그것 자체로 하나의 의미를 가지는 어려운 경우도 있지만 우리는 여기서 이런 경우를 생각할 필요는 없습니다.\n\n이 정의들과 함께, $\\Delta C$에 대한 7번 식은 다음과 같이 다시 쓰여질 수 있습니다.\n\n$$\\begin{eqnarray}   \\Delta C \\approx \\nabla C \\cdot \\Delta v.\\tag{9}\\end{eqnarray}$$\n\n이 공식은 왜 $\\nabla C$가 기울기 백터라고 불리는지에 대한 이유를 설명하는데 도움을 줍니다. $\\nabla C$는 우리가 기울기값이라는것이 하는 일에 대해서 예상할 수 있다시피 $C$에서의 변화량들과 $v$에서의 변화량을 관련짓습니다. 하지만 이 방정식에 대한 정말로 흥미로운 점은 이 방정식이 $\\Delta C$를 음수로 만들기 위해 $\\Delta v$를 어떻게 골라야 하는지 우리에게 보여준다는 것 입니다. 특히, 우리가 다음과 같은 $\\Delta v$를 선택했다고 해봅시다.\n\n$$\\begin{eqnarray} \\Delta v = -\\eta \\nabla C,\\tag{10}\\end{eqnarray}$$\n\n여기서 $\\eta$는 작은 양수입니다.(학습율, learning rate라고도 불립니다.) 9번 방정식은 우리에게 $\\Delta C \\approx -\\eta\\nabla C \\cdot \\nabla C = -\\eta \\|\\nabla C\\|^2$임을 보여줍니다. $\\| \\nabla C\\|^2 \\geq 0$이므로 $\\Delta C \\leq 0$이고 10번식을 따라 $v$를 변화시킨다면 이는 $C$는 증가하지 않고 항상 감소함을 보여줍니다. (물론, 9번 공식에서의 근사치의 한계 내에서만) 이런 특징이 바로 우리가 원하던 것입니다! 그리고 우리는 우리의 기울기 하강 알고리즘에서 우리의 공을 위한 \"운동 법칙\"을 정의하기 위해 공식10번을 취할것입니다. 이 말은 즉슨, 우리는 $\\Delta v$의 값을 계산하기 위해 10번 공식을 사용하여 $\\Delta v$만큼 공의 위치 $v$를 움직일 것입니다.\n\n$$\\begin{eqnarray} v \\rightarrow v' = v -\\eta \\nabla C\\end{eqnarray}$$\n\n그리고 나서 우리는 또 다른 움직임을 만들기 위해 이 개정된 규칙을 다시 사용할 것입니다. 만약 우리가 이것을 반복하면, $C$가 최소가 될때까지 감소하는 상태를 유지할 수 있습니다.\n\n요약하자면, 기울기 하강 알고리즘이 작동하는 방법은 기울기 $\\nabla C$를 반복적으로 계산하기 위함이며, 계곡의 바닥면으로 \"떨어지는\" 방향으로 움직이기 위함입니다. 우리는 이것을 이렇게 시각화 할 수 있습니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/valley_with_ball.png\" style=\"max-width:100%;height:auto\"  height=\"612\" width=\"812\"/\u003e\u003c/center\u003e\n\n이런 기울기 하강 규칙은 실제 물리 움직임을 재생산 하지는 않음을 알아두세요. 실제 세계에서는 공이 운동량을 가지고 있어서 계곡의 바닥면을 가로질러 가게 합니다. 혹은 계곡의 꼭대기로 올라가게 할 수도 있습니다. 반대로, 우리가 $\\Delta v$를 선택하기위한 규칙은 단지 \"지금이야, 굴러가!\"라고 말할 뿐입니다. 이는 여전히 최소를 찾기위한 좋은 규칙입니다.\n\n기울기 하강을 정확하게 작동하도록 만들기 위해서는, 9번 공식이 꽤 좋은 근사치를 가지기 위해서는 중분히 작은 학습율 $\\eta$을 선택할 필요가 있습니다. 그렇지 않다면, $\\Delta C \u0026gt; 0$이라는 영 좋지 않은 결과를 맞이할 수 도 있습니다. 거기에다, 우리는 $\\Delta v$를 매우 작게 변화시키기 때문에 $\\eta$가 너무 작아지길 원하진 않습니다. 그렇게 되면 기울기 하강 알고리즘은 매우 느리게 작동할 것입니다. 실용적인 구현에서는, $\\eta$는 보통 9번 식이 좋은 근사치를 보이기 위해서 다양한 값을 가집니다. 그러나 알고리즘이 너무 느리지는 않습니다. 우리는 나중에 이것이 어떻게 작동하는지 볼것입니다.\n\n저는 $C$함수를 단지 두개의 변수를 가진 함수로써 이야기 하였을때 기울기 하강을 설명하였습니다. 하지만, 사실, $C$가 더 많은 변수를 가지고 있을때에도 이 알고리즘은 제대로 작동합니다. 함수 $C$가 $m$개의 변수 $v_{1}$, ..., $v_{m}$를 가지고 있는 함수라고 가정하여 봅시다. 그러면 $C$의 변화량 $\\Delta C$는 $\\Delta v=(\\Delta v_1, ..., \\Delta v_m)^T$라는 작은 변화에 의해 생산됩니다.\n\n$$\\begin{eqnarray}   \\Delta C \\approx \\nabla C \\cdot \\Delta v,\\tag{12}\\end{eqnarray}$$\n\n여기서 기울기 $\\nabla C$는 다음과 같은 백터입니다.\n\n$$\\begin{eqnarray}  \\nabla C \\equiv \\left(\\frac{\\partial C}{\\partial v_1}, \\ldots,   \\frac{\\partial C}{\\partial v_m}\\right)^T.\\tag{13}\\end{eqnarray}$$\n\n두개의 변수를 가진 경우에 대해서, 우리는 다음과 같이 $\\Delta v$를 고를 수 있습니다.\n\n$$\\begin{eqnarray}  \\Delta v = -\\eta \\nabla C,\\tag{14}\\end{eqnarray}$$\n\n그리고 우리는 우리의 $\\Delta C$에 대한 12번 식이 음수가 될것이라는 것을 증명하였습니다. 이는 함수 $C$가 많은 변수를 가진 함수일때에도 다음과 같은 규칙을 계속해서 적용시키므로써 최소를 향한 기울기를 따라가는 방법을 제시하여 줍니다.\n\n$$\\begin{eqnarray}  v \\rightarrow v' = v-\\eta \\nabla C.\\tag{15}\\end{eqnarray}$$\n\n여러분은 이 규칙을 기울기 하강 알고리즘의 정의로써 생각할 수 있습니다. 이 규칙은 함수 $C$의 최소를 찾기위해 $v$를 반복적으로 바꾸는 방법을 알려줍니다. 그러나 이 규칙이 항상 옳게 작동하지는 않습니다. 몇몇의 부분들이 C의 최소를 찾는것으로 부터 기울기 하강 알고리즘을 작동하지 않게 합니다. 그 부분에 대해서는 후의 장에서 다루려고 합니다. 그러나, 실제로는 대부분의 상황에서 기울기 하강 알고리즘은 굉장히 잘 작동합니다. 그리고 뉴런 네트워크에서 이러한 비용함수를 최소화 하는 방법이 굉장히 강력하고 네트워크가 학습하는데 큰 도움을 줌을 알게될것입니다.\n\n사실, 기울기 하강 알고리즘은 최소를 찾는데 있어 잘 최적화 된 방법입니다. $C$를 가능한 작게 만들기 위하여 $\\Delta v$를 움직이려고 한다고 해봅시다. 이는 $\\Delta C \\approx \\nabla C \\cdot \\Delta v$를 최소화 하는것과 같습니다. 우리는 움직임의 범위를 제한하여 $\\epsilon \u0026gt; 0$인 작은 값에 대해 $\\|\\Delta v \\| = \\epsilon$가 되도록 하려고 합니다. 다른말로 하면, 고정된 값 만큼씩만 움직여서 $C$를 가능한 작게 하는 움직임의 방향을 찾으려고 하는것입니다. $\\nabla C \\cdot \\Delta v$를 최소화 하는 $\\Delta v$의 값은 $\\Delta v = -\\eta \\nabla C$이고, $\\eta = \\epsilon / \\|\\nabla C\\|$은 $\\|\\Delta v\\|=\\epsilon$라는 고정된 값에 의해 결정됩니다. 그래서 기울기 하강 알고리즘은 $C$를 즉시 감소시키기는 방향으로는 작은 움직임을 취하는 방법이라는 관점으로 생각할 수 있습니다.\n\n### 연습\n* 마지막 단락의 주장을 증명하여 보세요. 힌트: 만약 여러분이 코시-슈바르츠 부등식에 대해 익숙치 않다면, 이것에 익숙해 지는것이 큰 도움이 될 것 입니다.\n* 저는 $C$함수가 두개의 변수를 가질때 혹은 더 많은 변수를 가질때의 경우에서 기울기 하강을 설명하였습니다. 만약 $C$가 한개의 변수를 가진다면 어떻게 될까요? 1차원의 경우에서 기울기 하강이 어떻게 되는지 기하학적으로 표현해볼 수 있나요?\n\n사람들은 기울기 하강 알고리즘의 많은 방법들을 조사하였고, 실제 물리적인 공과 비슷한 방법들도 있습니다. 이러한 공을 모티브로 한 방법들은 몇가지 장점들을 가지고 있습니다. 하지만 또한 중대한 단점또한 가지고 있습니다. 바로 $C$의 이계도함수를 반드시 계산해야 한다는 것과 이 작업은 굉장히 많은 비용이 든다는것 입니다. 왜 이것이 많은 비용이 드는지 이해하기 위해선, 모든 이계도함수 $\\partial ^2C/\\partial v_j \\partial v_k$를 계산해야 한다고 가정해 봅시다. 만약 백만개의 $v_j$가 있다면, 우리가 계산해야 할것은 1조개(백만의 제곱)이 될것입니다! 이는 계산하는데 엄청난 비용이 들어갑니다. 물론, 이러한 문제를 피하기 위한 꼼수가 있고 기울기 하강을 대체하기 위한 방법을 찾는것은 여전히 활발히 조사되고 있습니다. 하지만 이 책에서는 기울기 하강을 뉴런 네트워크를 학습하기 위한 주 접근방법으로 사용할 것 입니다.\n\n어떻게 우리가 뉴런 네트워크를 학습하기 위해 기울기 하강을 적용할 수 있나요? 방법은, 6번 공식에서 비용을 최소화 하는 가중치와 $bias$들을 찾기위해 기울기 하강을 사용하는 것 입니다. 어떻게 이것이 작동하는지 이해하기 위해서, 변수 $v_j$를 가중치와 $bias$로 바꾸어 기울기 하강 업데이트 규칙을 관련지어 봅시다. 다른말로 하면, 이제 함수 $C$는 가중치와 $bias$를 변수로 가지며 기울기 백터 $\\nabla C$는 이제 $\\partial C/\\partial w_k$와 $\\partial C/\\partial b_l$을 성분으로 가집니다. 이제 다시 기울기 하강 업데이트 규칙을 쓰면 다음과 같습니다.\n\n$$\\begin{eqnarray}  w_k   \\rightarrow   w_k' = w_k-\\eta \\frac{\\partial C}{\\partial w_k} \\tag{16}\\\\  b_l   \\rightarrow   b_l' = b_l-\\eta \\frac{\\partial C}{\\partial b_l}.\\tag{17}\\end{eqnarray}$$\n\n이 규칙들을 반복적으로 적용시킴으로써 우리는 \"계곡의 아래로 구르기\"를 할 수 있고 비용함수의 최소를 찾을 수 있습니다. 다른말로, 이는 뉴런 네트워크를 학습하기 위해 사용할 수 있는 규칙입니다.\n\n기울기 하강 알고리즘을 적용시키기 위한 많은 과제들이 있습니다. 우리는 후의 장에서 이에 대해 깊게 다룰것입니다. 하지만 지금 저는 단 하나의 문제에 대해서만 언급하고 싶군요. 문제가 무엇인지 이해하기 위해, 6번 공식의 이차 비용 함수로 돌아가 봅시다. $C = \\frac{1}{n} \\sum_x C_x$의 형태를 가진 비용 함수는 각 학습 데이터 마다의 비용 $C_x \\equiv \\frac{\\|y(x)-a\\|^2}{2}$의 평균입니다. 실제로 기울기 $\\nabla C$를 계산하기 위해서 각 입력 데이터 $x$마다의 기울기 $\\nabla C_x$를 계산할 필요가 있습니다. 그리고 이를 평균을 내면 $\\nabla C = \\frac{1}{n}\\sum_x \\nabla C_x$가 됩니다. 불행히도, 입력 데이터들의 양이 많아지면 이를 계산하는데 굉장히 오랜 시간이 걸립니다. 그리고 학습은 매우 느리게 진행됩니다.\n\n확률적 기울기 하강 알고리즘이라고 불리는 아이디어는 학습을 빠르게 하는데 이용될 수 있습니다. 이 아이디어는 무작위로 선택된 입력 데이터들의 작은 집합로 부터 $\\nabla C_x$을 계산함으로써 $\\nabla C$를 추정하는것 입니다. 이 작은 집합들의 평균을 냄으로써 실제 기울기 $\\nabla C$의 값을 정확하고 빠르게 추정할 수 있고 기울기 하강과 학습을 빠르게 하는데 도움이 됩니다.\n\n이 아이디어를 명확히 하자면, 확률적 기울기 하강 알고리즘은 무작위로 $m$개의 학습 데이터를 고르므로써 작동합니다. 무작위로 선택된 학습 데이터들을 소집단(mini-batch)라고 부르고 각 데이터를 $X_1, X_2, ..., X_m$라고 이름붙입니다. 소집단의 크기 $m$은 $\\nabla C_{X_j}$의 평균이 $\\nabla C_x$의 평균값에 근사치가 되기에 충분히 커야합니다. 이 말은 다음과 같습니다.\n\n$$\\begin{eqnarray}  \\frac{\\sum_{j=1}^m \\nabla C_{X_{j}}}{m} \\approx \\frac{\\sum_x \\nabla C_x}{n} = \\nabla C,\\tag{18}\\end{eqnarray}$$\n\n두번째 시그마 합은 모든 학습 데이터에 대한 것 입니다. 좌변을 교체하면 다음과 같습니다.\n\n$$\\begin{eqnarray}  \\nabla C \\approx \\frac{1}{m} \\sum_{j=1}^m \\nabla C_{X_{j}},\\tag{19}\\end{eqnarray}$$\n\n이 식은 우리가 무작위로 선택한 소집단의 기울기를 계산함으로써 전체 기울기의 값을 계산할 수 있음을 보여줍니다.\n\n이를 뉴런 네트워크에서의 학습으로 연결시키기 위해서, $w_k$와 $b_l$이 네트워크에서의 가중치와 $bias$를 의미한다고 가정합시다. 확률적 기울기 하강 알고리즘은 학습 데이터의 무작위로 선택된 소집단을 고르고, 그것들을 가지고 학습함으로써 작동합니다.\n\n$$\\begin{eqnarray}   w_k   \\rightarrow   w_k' = w_k-\\frac{\\eta}{m}  \\sum_j \\frac{\\partial C_{X_j}}{\\partial w_k} \\tag{20}\\\\    b_l   \\rightarrow   b_l' = b_l-\\frac{\\eta}{m}  \\sum_j \\frac{\\partial C_{X_j}}{\\partial b_l},\\tag{21}\\end{eqnarray}$$\n\n시그마 합은 현재 소집단에 있는 학습 데이터에 대한 것 입니다. 우리는 또 다른 소집단을 선택한 다음 그것을 가지고 또 학습을 합니다. 그리고 이것을 학습데이터가 바닥날때 까지 반복합니다. 우리는 이 한번의 반복을 세대(epoch)라고 부릅니다. 한 세대가 끝나면 또 한 세대를 반복합니다.\n\n부수적으로, 가중치와 바이어스를 업데이트하는 소집단의 그리고 비용함수의 스케일링은 다양할 수 있습니다. (6)번 식에서 $\\frac{1}{n}$로 전체 비용을 축소시켰습니다. 어떤 사람들은 $\\frac{1}{n}$항을 빼서 평균을 내는 대신에 전체 비용을 그냥 모두 더합니다. 이런 방법은 전체 학습 데이터의 갯수가 몇개인지 사전에 알지 못할때 유용합니다. 이는 예를 들면 학습 데이터가 실시간으로 계속 생성되어 갯수가 늘어나는 경우가 있겠습니다. 그리고 비슷한 방법으로, 소집단 업데이트 규칙인 (20)번 식과 (21)번식에서도 $\\frac{1}{m}$항을 뺄 수 있습니다. 이는 작은 변화를 만드는데, 학습률 $\\eta$를 변화시키는 것과 같은 효과를 보입니다. 하지만 서로 다른 작업들 자세히 비교해야 할때면, 이 변화에 대해 자세히 보는것도 나쁘지 않겠군요.\n\n우리는 확률적 기울기 하강 알고리즘을 여론 조사와 같다고 생각 할 수 있습니다. 전체 집단의 기울기를 구하는것 보다는 작은 소집단의 기울기를 구하는것이 훨씬 쉽습니다. 전체 투표율을 조사하는것 보다는 여론을 조사하는것이 훨씬 쉬운것과 같은 이치죠. 예를 들면 MNIST 처럼 $n=60,000$의 크기를 가지는 학습데이터를 가지고 있고 $m=10$의 크기를 가지는 소집단 을 고르면, 이는 $6,000$배가 빨리 기울기를 구할 수 있다는것을 의미합니다! 물론, 구한 값이 매우 정확치는 않겠죠. 통계적 편차가 존재할 것입니다. 하지만 완벽한 값을 구할 필요가 없습니다. 우리가 하고자 하는것은 전체 $C$의 값을 감소시키는 일반적인 방향을 구하고자 하는것이지, 기울기에 대한 정확한 계산을 할 필요는 없다는 겁니다. 실제로, 확률적 기울기 하강 알고리즘은 뉴런 네트워크를 학습시키는데 있어서 매우 강력하고 자주 쓰이는 기술입니다. 그리고 이는 우리가 이 책에서 개발할 여러 학습 기술들의 바탕이 됩니다.\n\n### 연습\n\u003cul style=\"list-style-type: square;\"\u003e\u003cli\u003e확률적 기울기 하강 알고리즘의 극단적인 버젼은 우리가 소집단의 크기를 1로 사용할 때 입니다. 이 말은, 주어진 학습데이터 $x$에 대해, $w_{k} \\rightarrow w_{k}\\prime = w_{k} - \\eta \\partial C_{x}/\\partial w_{k}$ 와 $b_{l} \\rightarrow b_{l}\\prime = b_{l} - \\eta \\partial C_{x} /\\partial b_{l}$라는 식으로 가중치와 바이어스를 업데이트 하는것을 의미합니다. 그리고 나서 다른 학습데이터를 고르고 다시 규칙을 적용합니다. 이를 계속 반복합니다. 이 과정은 online, on-line, 또는 incremental 학습 이라고 알려져 있습니다. online 학습에서, 뉴런 네트워크는 한번에 하나의 학습데이터만을 가지고 학습합니다(사람이 그러한 것 처럼). 소집단의 크기가 20인(가정) 확률적 기울기 하강 알고리즘과 비교해서 이 방법의 장점과 단점이 무엇인지 이야기 해 보세요.\u003c/li\u003e\u003c/ul\u003e마지막으로, 기울기 하강 알고리즘이 처음인 사람들을 가끔 괴롭히는 부분에 대해서 이야기하면서 이 섹션을 마치도록 하겠습니다. 뉴런 네트워크에서 비용 $C$는 가중치와 바이어스들과 같은 많은 변수들에 대한 함수입니다. 이는 매우 고차원의 공간상의 표면을 그린다고 생각할 수 있습니다. 몇몇 사람들은 이런 생각을 합니다: \"이봐, 나는 모든 이 추가적인 차원들을 시각적으로 봐야할 필요가 있어!\". 그리고 이들은 걱정하기 시작합니다: \"나는 5차원은 커녕 4차원도 생각할 수 없어!(또는 5백만...)\". 이들이 놓친 실제 뛰어난 수학자들이 가지고 있는 어떤 특별한 능력이 있을까요? 물론, 답은 '아니오'입니다. 대부분의 전문적인 수학자들 또한 4차원을 시각화 하지 못합니다. 대신 그들이 사용하는 꼼수는 무엇이 일어나고 있는지를 표현하는 다른 방법을 개발하는 것 입니다. 이것이 바로 우리가 앞서 했던 것과 정확히 일치합니다: 우리는 $C$를 감소시키기 위해 어떻게 움직여야 하는지 알아내기 위해 $\\Delta C$에 대한 수학적 표현을 사용하였습니다. 고차원에서의 상상을 잘 하는 사람들은 서로 다른 많은 기술들을 가지고 있는 그들만의 머릿속 도서관을 가지고 있습니다. 우리의 수학적 꼼수는 단지 하나의 예시입니다. 이러한 기술들은 아마 3차원을 시각화 할때 처럼 우리에게 익숙한 간단함을 가지고 있진 않을겁니다. 하지만 여러분이 이런 기술들을 가지고 있는 여러분만의 도서관을 짓고 나면, 아마 고차원에서의 상상도 손쉽게 할 수 있을겁니다. 저는 여기서 더 자세히 들어가진 않겠지만, 관심이 좀 생겼다면 뛰어난 수학자들이 고차원에서의 상상을 하기 위해 사용하는 몇몇 기술들을 \u003ca href=\"https://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking\" target=\"_blank\" class=\"tx-link\"\u003e여기서\u003c/a\u003e 확인해 볼 수 있습니다. 몇몇 기술들은 꽤 복잡하지만, 대부분은 직관적이고 접근하기 쉽습니다. 그리고 아마 누구라도 마스터 할 수 있을겁니다.\n\n","slug":["2017-04-11-learning-with-gradient-descent"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"숫자들을 판별하기 위한 네트워크 구현하기(작성중)\",\"date\":\"2017-04-15 23:59:36 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n좋습니다, 이제 확률적 기울기 하강 알고리즘과 MNIST 학습 데이터를 이용하여 손글씨를 인식하는 프로그램을 작성하여 봅시다. 우리는 파이썬 2.7로 작성된 단지 74줄의 프로그램을 작성하게 될것입니다! 첫번째로 필요한것은 MNIST 데이터를 가져오는것입니다. 여러분이 git 사용자라면 이 책의 코드 레포지토리를 복사함으로써 데이터를 얻을 수 있습니다.\n\n```\ngit clone https://github.com/mnielsen/neural-networks-and-deep-learning.git\n```\n\n여러분이 git 사용자가 아니라면, \u003ca href=\"https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip\" target=\"_blank\" class=\"tx-link\"\u003e이곳\u003c/a\u003e에서 데이터와 코드를 다운로드할 수 있습니다.\n\n그런데 제가 MNIST 데이터를 앞에서 설명할 때, 제가 이 데이터가 60,000개의 학습 이미지들과 10,000개의 테스트 이미지로 나누어져 있다고 말했습니다. 그것이 MNIST의 공식적인 설명입니다. 사실 저희는 이를 좀 다르게 나누어 보려고 합니다. 테스트 이미지는 그대로 두고, 60,000개의 MNIST 학습 이미지를 두 부분으로 나눌것입니다: 50,000개의 이미지는 우리의 뉴런 네트워크를 학습시키는데 사용하고, 나머지 10,000개의 이미지는 validation set으로 나눕니다. 이 장에서 validation 데이터를 사용하지는 않을것이지만 나중에 이 책에서 뉴런 네트워크의 특정한 hyper-parameters(예를들면 학습률과 같은 직접 선택되지 않은 것들)을 어떻게 정하는지를 알아내는데 있어서 이것이 유용하다는것을 알게될겁니다. validation set이 공식적인 MNIST의 부분이 아니지만, 많은 사람을이 MNIST 자료를 이런식으로 사용하고, 뉴런 네트워크에 있어서 validation set은 굉장히 많이 사용됩니다. 제가 지금부터 \"MNIST 학습 데이터\"를 언급할때는, 저는 50,000개의 이미지 데이터를 이야기 하는겁니다. 60,000개의 원래 이미지가 아닙니다.\n\n\u003c!-- more --\u003e\n\n저희는 또한 \u003ca href=\"https://numpy.org/\" target=\"_blank\" class=\"tx-link\"\u003eNumpy\u003c/a\u003e 라고 불리는 빠른 선형 수학을 하기위한 파이썬 라이브러리가 필요합니다. 여러분이 아직 Numpy를 설치하지 않았다면, \u003ca href=\"https://www.scipy.org/install.html\" target=\"_blank\" class=\"tx-link\"\u003e여기서\u003c/a\u003e 다운로드 받으세요.\n\n아래에 있는 전체 코드를 보여드리기 전에, 뉴런 네트워크 코드의 핵심적인 특징에 대해서 설명하고자 합니다. 가장 핵심이 되는것은 Network 클래스 입니다. 이는 우리가 뉴런 네트워크를 나타내기 위해 사용합니다. 여기 Network 객체를 초기화 하기 위해 사용할 코드가 있습니다.\n\n```python\nclass Network(object):\n\n\tdef __init__(self, sizes):\n\t\tself.num_layers = len(sizes)\n\t\tself.sizes = sizes\n\t\tself.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n\t\tself.weights = [np.random.randn(y, x) \n\t\t\t\tfor x, y in zip(sizes[:-1], sizes[1:])]\n```\n\n이 코드에서, sizes 라는 리스트는 각 층의 뉴런 갯수를 가지고 있습니다. 예를들면, 첫번째 층에는 두개의 뉴런, 둘째 층에는 세개의 뉴런, 마지막 층에는 한개의 뉴런이 있는 Network 객체를 만들고자 한다면, 우리는 다음과 같이 코드를 작성할 수 있습니다.\n\n```python\nnet = Network([2, 3, 1])\n```\n\n네트워크의 bias와 가중치들은 Numpy의 np.random.randn 함수로 무작위로 설정됩니다. 이 초기화는 확률적 기울기 하강 알고리즘을 시작하게 될 값을 제공합니다. 후의 장에서는 가중치와 bias를 초기화 하는 더 좋은 방법을 찾게 되겠지만, 지금은 일단 이렇게 하도록 합시다. 이 Network 의 초기화 작업은 첫번째 층이 입력층이라는 가정 하에 이루어집니다. 입력층에서는 가중치와 바이어스가 필요 없기 때문에 입력층을 제외한 나머지 층의 가중치와 바이어스 행렬만을 만듭니다.\n\n또한 바이어스와 가중치는 Numpy 행렬의 배열로 저장됩니다. 예를들면, net.weight[1]는 두번째 층와 세번째 층을 잇는 가중치를 저장하고 있는 Numpy 행렬입니다.(파이썬은 0부터 인덱싱을 하기 때문에 이는 첫번째 층과 두번째 층에 대한 가중치가 아닙니다.) net.weight[1]이라는 표현은 너무 난잡하기 때문에 여기서는 그냥 행렬 $w$이라고 이야기 합니다. $w_{jk}$는 두번째 층의 $k$번째 뉴런과 세번째 층의 $j$번째 뉴런에 대한 가중치를 이야기 합니다. 이런 $j$와 $k$라는 번호매김 방법은 이상하게 보일 수 있습니다. $j$ 와 $k$의 자리를 바꿔놔야 좀더 직관적인 표현방법이 아닐까요? 이러한 번호매김 방법의 장점은 이것이 세번째 층의 활성화값들에 대한 벡터가 다음과 같기 때문입니다.\n\n$$\\begin{eqnarray}   a' = \\sigma(w a + b).\\tag{22}\\end{eqnarray}$$\n\n이 수식을 이해하려면 시간이 좀 필요합니다. 이를 조각조각 내어 한번 살펴봅시다. $a$는 두번째 층의 뉴런들의 활성화 값에 대한 벡터입니다. $a'$를 얻기 위해선 $a$를 $w$라는 가중치 행렬과 곱해야 합니다. 그리고 나서 바이어스 벡터 $b$를 더해야합니다. 그리고 나서 $\\sigma$ 함수를 벡터 $wa+b$의 성분마다 적용해야 합니다. (이를 함수 $\\sigma$를 벡터화 한다고 합니다.) 우리는 (22)번 식이 앞서 본 (4)번 식과 같은 결과를 가져옴을 쉽게 알 수 있습니다.\n\n### 연습\n\n* (22)번 식의 계산을 성분별로 나타내어 보세요. 그리고 시그모이드 뉴런의 출력을 계산하는데 (4)번 식과 똑같은 결과를 가져옴을 보이세요.\n\nNetwork 객체로 부터 출력값을 계산하는 코드를 짜는것은 매우 쉽습니다. 시그모이드 함수를 정의하는것 부터 시작합시다.\n\n```python\ndef sigmoid(z):\n    return 1.0/(1.0+np.exp(-z))\n```\n\n입력변수 z가 Numpy 배열 또는 벡터라면, Numpy는 자동으로 sigmoid 함수를 성분마다 적용할겁니다.\n\n그리고 나서 Network 객체에 주어진 입력 a에 대해서 출력을 계산하는 feedforward 함수를 만들어 넣도록 합시다. 이 함수가 하는 모든 일은 각 층마다 (22)번 식을 적용하는 것 입니다.\n\n```python\ndef feedforward(self, a):\n        \"\"\"Return the output of the network if \"a\" is input.\"\"\"\n        for b, w in zip(self.biases, self.weights):\n            a = sigmoid(np.dot(w, a)+b)\n        return a\n```\n\n물론, Network 객체가 해야 하는 가장 중요한 것은 '학습'입니다. 그러니 확률적 기울기 하강 알고리즘을 구현하는 SGD 함수를 만들어 넣도록 합시다. 여기 아래 코드가 있습니다. 몇몇 부분에서는 좀 당황스러울 수 있으나, 제가 아래에 각 부분마다 설명을 하도록 하겠습니다.\n\n```python\ndef SGD(self, training_data, epochs, mini_batch_size, eta,\n            test_data=None):\n        \"\"\"Train the neural network using mini-batch stochastic\n        gradient descent.  The \"training_data\" is a list of tuples\n        \"(x, y)\" representing the training inputs and the desired\n        outputs.  The other non-optional parameters are\n        self-explanatory.  If \"test_data\" is provided then the\n        network will be evaluated against the test data after each\n        epoch, and partial progress printed out.  This is useful for\n        tracking progress, but slows things down substantially.\"\"\"\n        if test_data: n_test = len(test_data)\n        n = len(training_data)\n        for j in xrange(epochs):\n            random.shuffle(training_data)\n            mini_batches = [\n                training_data[k:k+mini_batch_size]\n                for k in xrange(0, n, mini_batch_size)]\n            for mini_batch in mini_batches:\n                self.update_mini_batch(mini_batch, eta)\n            if test_data:\n                print \"Epoch {0}: {1} / {2}\".format(\n                    j, self.evaluate(test_data), n_test)\n            else:\n                print \"Epoch {0} complete\".format(j)\n```\n\ntraining_data는 학습을 위한 입력과 그에 해당하는 원하는 출력값을 가지고 있는 튜플 (x, y)의 리스트입니다. epoch 과 mini_batch_size는 이름에서 알 수 있듯이 학습할 세대의 수와 소집단의 크기입니다. eta는 학습률 $\\eta$입니다. 만약 test_data 라는 선택적 매개변수가 주어지게 되면, 프로그램은 각 세대의 학습이 끝난뒤 네트워크를 평가하게 됩니다. 그리고 부분적인 진행률을 보여줍니다. 이는 과정을 따라가는데 유용하지만 몇몇부분에서 상당한 속도 저하를 일으킬 수 있습니다.\n\n각 세대마다 학습데이터를 무작위로 섞으면서 시작합니다. 그리고 이를 적절한 크기로 소집단으로 나눕니다. 이는 학습데이터로 부터 무작위로 샘플링을 하는 쉬운 방법입니다. 그리고 각 mini_batch(소집단)마다 기울기 하강의 각 과정을 거칩니다. 이 과정은 self.update_mini_batch(mini_batch, size)라는 코드를 통해 이루어집니다. 이 함수는 기울기 하강 알고리즘에 따라 네트워크의 가중치와 바이어스를 업데이트 합니다. 여기 update_mini_batch 함수의 코드가 있습니다.\n\n```python\ndef update_mini_batch(self, mini_batch, eta):\n        \"\"\"Update the network's weights and biases by applying\n        gradient descent using backpropagation to a single mini batch.\n        The \"mini_batch\" is a list of tuples \"(x, y)\", and \"eta\"\n        is the learning rate.\"\"\"\n        nabla_b = [np.zeros(b.shape) for b in self.biases]\n        nabla_w = [np.zeros(w.shape) for w in self.weights]\n        for x, y in mini_batch:\n            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n        self.weights = [w-(eta/len(mini_batch))*nw \n                        for w, nw in zip(self.weights, nabla_w)]\n        self.biases = [b-(eta/len(mini_batch))*nb \n                       for b, nb in zip(self.biases, nabla_b)]\n```\n\n대부분의 작업은 다음 줄에서 마무리 됩니다.\n\n```python\ndelta_nabla_b, delta_nabla_w = self.backprop(x, y)\n```\n\n이는 역전파 알고리즘이라고 불리는 것을 실행합니다. 이는 비용함수의 기울기를 계산하는 빠른 방법입니다. update_mini_batch는 간단히 mini_batch의 학습데이터들 마다 이 기울기를 계산함에 따라 작동합니다. 그리고 적절히 self.weights 와 self.biases를 업데이트 합니다.\n\n저는 여기서 self.backprop 함수에 대한 코드를 여기서 보여드리진 않을것입니다. 우리는 다음 장에서 어떻게 역전파 알고리즘이 작동하는지 코드를 포함해서 배우게 됩니다. 하지만 지금 당장은 학습데이터 $x$에 대한 비용함수의 기울기를 반환하는 이 함수가 정의되어 있다고 가정하고 진행합시다.\n\n제가 위에서는 생략했던 주석들과 함께 전체 프로그램을 한번 봅시다. self.backprop을 제외하고서 전체 프로그램은 모두 설명이 되어 있습니다. 대부분의 작업들은 우리가 앞서 미리 알아보았던 self.SGD와 self.update_mini_batch에서 이루어 집니다. self.backprop 함수는 sigmoid_prime 이라는 시그모이드 함수의 도함수와 self.cost_derivative 라는 여기서 아직 설명하지 않은 추가적인 함수들을 기울기를 계산하기 위해 만들어 사용합니다. 여러분은 단지 코드와 주석들을 읽고 대강 요지를 (어쩌면 자세한 사항을) 파악할 수 있을것입니다. 다음 장에서 자세한 사항들을 살펴보도록 하죠. 코드가 매우 길어보이지만, 이해를 돕기위해 대부분의 줄은 주석으로 구성되어 있습니다. 사실, 프로그램은 공백과 주석없이 단지 74줄로 이루어져 있습니다. 모든 코드들은 깃허브의 \u003ca href=\"https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py\" target=\"_blank\" class=\"tx-link\"\u003e여기서\u003c/a\u003e 찾을 수 있습니다.\n\n```python\n\"\"\"\nnetwork.py\n~~~~~~~~~~\n\nA module to implement the stochastic gradient descent learning\nalgorithm for a feedforward neural network.  Gradients are calculated\nusing backpropagation.  Note that I have focused on making the code\nsimple, easily readable, and easily modifiable.  It is not optimized,\nand omits many desirable features.\n\"\"\"\n\n#### Libraries\n# Standard library\nimport random\n\n# Third-party libraries\nimport numpy as np\n\nclass Network(object):\n\n    def __init__(self, sizes):\n        \"\"\"The list ``sizes`` contains the number of neurons in the\n        respective layers of the network.  For example, if the list\n        was [2, 3, 1] then it would be a three-layer network, with the\n        first layer containing 2 neurons, the second layer 3 neurons,\n        and the third layer 1 neuron.  The biases and weights for the\n        network are initialized randomly, using a Gaussian\n        distribution with mean 0, and variance 1.  Note that the first\n        layer is assumed to be an input layer, and by convention we\n        won't set any biases for those neurons, since biases are only\n        ever used in computing the outputs from later layers.\"\"\"\n        self.num_layers = len(sizes)\n        self.sizes = sizes\n        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n        self.weights = [np.random.randn(y, x)\n                        for x, y in zip(sizes[:-1], sizes[1:])]\n\n    def feedforward(self, a):\n        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n        for b, w in zip(self.biases, self.weights):\n            a = sigmoid(np.dot(w, a)+b)\n        return a\n\n    def SGD(self, training_data, epochs, mini_batch_size, eta,\n            test_data=None):\n        \"\"\"Train the neural network using mini-batch stochastic\n        gradient descent.  The ``training_data`` is a list of tuples\n        ``(x, y)`` representing the training inputs and the desired\n        outputs.  The other non-optional parameters are\n        self-explanatory.  If ``test_data`` is provided then the\n        network will be evaluated against the test data after each\n        epoch, and partial progress printed out.  This is useful for\n        tracking progress, but slows things down substantially.\"\"\"\n        if test_data: n_test = len(test_data)\n        n = len(training_data)\n        for j in xrange(epochs):\n            random.shuffle(training_data)\n            mini_batches = [\n                training_data[k:k+mini_batch_size]\n                for k in xrange(0, n, mini_batch_size)]\n            for mini_batch in mini_batches:\n                self.update_mini_batch(mini_batch, eta)\n            if test_data:\n                print \"Epoch {0}: {1} / {2}\".format(\n                    j, self.evaluate(test_data), n_test)\n            else:\n                print \"Epoch {0} complete\".format(j)\n\n    def update_mini_batch(self, mini_batch, eta):\n        \"\"\"Update the network's weights and biases by applying\n        gradient descent using backpropagation to a single mini batch.\n        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n        is the learning rate.\"\"\"\n        nabla_b = [np.zeros(b.shape) for b in self.biases]\n        nabla_w = [np.zeros(w.shape) for w in self.weights]\n        for x, y in mini_batch:\n            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n        self.weights = [w-(eta/len(mini_batch))*nw\n                        for w, nw in zip(self.weights, nabla_w)]\n        self.biases = [b-(eta/len(mini_batch))*nb\n                       for b, nb in zip(self.biases, nabla_b)]\n\n    def backprop(self, x, y):\n        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n        gradient for the cost function C_x.  ``nabla_b`` and\n        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n        to ``self.biases`` and ``self.weights``.\"\"\"\n        nabla_b = [np.zeros(b.shape) for b in self.biases]\n        nabla_w = [np.zeros(w.shape) for w in self.weights]\n        # feedforward\n        activation = x\n        activations = [x] # list to store all the activations, layer by layer\n        zs = [] # list to store all the z vectors, layer by layer\n        for b, w in zip(self.biases, self.weights):\n            z = np.dot(w, activation)+b\n            zs.append(z)\n            activation = sigmoid(z)\n            activations.append(activation)\n        # backward pass\n        delta = self.cost_derivative(activations[-1], y) * \\\n            sigmoid_prime(zs[-1])\n        nabla_b[-1] = delta\n        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n        # Note that the variable l in the loop below is used a little\n        # differently to the notation in Chapter 2 of the book.  Here,\n        # l = 1 means the last layer of neurons, l = 2 is the\n        # second-last layer, and so on.  It's a renumbering of the\n        # scheme in the book, used here to take advantage of the fact\n        # that Python can use negative indices in lists.\n        for l in xrange(2, self.num_layers):\n            z = zs[-l]\n            sp = sigmoid_prime(z)\n            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n            nabla_b[-l] = delta\n            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n        return (nabla_b, nabla_w)\n\n    def evaluate(self, test_data):\n        \"\"\"Return the number of test inputs for which the neural\n        network outputs the correct result. Note that the neural\n        network's output is assumed to be the index of whichever\n        neuron in the final layer has the highest activation.\"\"\"\n        test_results = [(np.argmax(self.feedforward(x)), y)\n                        for (x, y) in test_data]\n        return sum(int(x == y) for (x, y) in test_results)\n\n    def cost_derivative(self, output_activations, y):\n        \"\"\"Return the vector of partial derivatives \\partial C_x /\n        \\partial a for the output activations.\"\"\"\n        return (output_activations-y)\n\n#### Miscellaneous functions\ndef sigmoid(z):\n    \"\"\"The sigmoid function.\"\"\"\n    return 1.0/(1.0+np.exp(-z))\n\ndef sigmoid_prime(z):\n    \"\"\"Derivative of the sigmoid function.\"\"\"\n    return sigmoid(z)*(1-sigmoid(z))\n```\n\n이 프로그램은 얼마나 손글씨들을 잘 알아볼까요? 그러면, MNIST 데이터들을 가지고 시작해 봅시다. 저는 mnist_loader.py라는 작은 도우미 프로그램을 이용하여 데이터들을 불러오도록 하겠습니다. 이 프로그램은 아래에 설명해 두었습니다. 파이썬 쉘에서 다음과 같은 명령어를 입력하여 실행합니다.\n\n```\n\u003e\u003e\u003e import mnist_loader\n\u003e\u003e\u003e training_data, validation_data, test_data = \\\n... mnist_loader.load_data_wrapper()\n```\n\n물론, 이 명령은 또 다른 파이썬 프로그램을 만들어서 작업할 수도 있습니다. 그렇지만 여러분이 저를 따라오고 있는 중이라면, 파이썬 쉘로 하는것이 아마 제일 쉬울것입니다.\n\nMNIST 데이터를 불러오고 나서, 30개의 은닉 뉴런을 가진 네트워크를 준비해 보도록 합시다. 먼저 위에 나와있는 network 라는 이름의 프로그램을 먼저 import 해야합니다.\n\n```\n\u003e\u003e\u003e import network\n\u003e\u003e\u003e net = network.Network([784, 30, 10])\n```\n\n마지막으로, 30세대 동안 소집단의 크기는 10, 학습률은 $\\eta = 3.0$로 하여 MNIST의 training_data를 확률적 기울기 하강 알고리즘을 통해 학습시킵니다.\n\n```\n\u003e\u003e\u003e net.SGD(training_data, 30, 10, 3.0, test_data=test_data)\n```\n\n여러분이 이 글을 읽으면서 코드를 실행하고 계신다면, 코드가 실행되는데 시간이 좀 걸린다는것을 알아두셨으면 합니다. 일반적인 컴퓨터 장치에서는 (2015년 기준으로) 실행하는데 수분이 걸립니다. 저는 여러분이 실행을 한 뒤에, 글을 계속 읽으면서, 주기적으로 프로그램의 출력을 확인해 주셨으면 합니다. 바쁘시다면 세대의 수를 줄이거나, 은닉층의 뉴런수를 줄이거나, 학습데이터의 일부만을 사용하셔도 됩니다. 이렇게 하면 결과를 훨씬 빨리 얻으실 수 있습니다. 이 파이썬 코드는 어떻게 뉴런 네트워크가 작동하는지 여러분의 이해를 돕기 위해 작성되었지, 빠른 수행을 위해 작성된 것이 아닙니다. 그리고 물론 한번 네트워크를 학습시키고 나면 매우 빠르게 네트워크를 사용할 수 있습니다. 거의 모든 연산 가능한 장치에서 말이죠. 예를들어, 네트워크의 가중치와 바이어스를 잘 학습시키고 나면 저희는 이것을 웹 브라우저의 자바스크립트로도 사용할 수 있고 혹은 모바일 장치에서도 사용 가능합니다. 어쨌거나, 제가 아래에 네트워크 학습의 결과 출력의 일부분을 가져왔습니다. 아래 결과는 각 세대의 학습 뒤에 네트워크게 의해 정확히 판별된 테스트 이미지들의 갯수를 보여줍니다. 보이다시피, 단지 한번의 세대 학습만으로도 10000개 중에 9129개의 이미지들을 판별해 내었고, 그 수가 계속 증가하는것을 볼 수 있습니다.\n\n\tEpoch 0: 9129 / 10000\n\tEpoch 1: 9295 / 10000\n\tEpoch 2: 9348 / 10000\n\t...\n\tEpoch 27: 9528 / 10000\n\tEpoch 28: 9542 / 10000\n\tEpoch 29: 9534 / 10000\n\n이 말은, 학습된 네트워크는 95%정도의 판별률을 가진다는 것입니다. 28번째 세대에서 95.42라는 최고치를 기록했습니다! 첫 시도 치고는 꽤 좋은 결과로군요. 그러나, 현재는 가중치와 바이어스를 무작위 하게 고르기 때문에 여러분의 코드 실행결과가 항상 저와 같다고 할 수 없다는 걸 알려드립니다. 전 이 결과를 내기 위해 세번의 학습 중에 가장 좋은 결과를 가져왔습니다.\n\n이번에 은닉 뉴런의 수를 100으로 늘려 다시 한번 학습을 진행하여 봅시다. 앞에서의 경우와 마찬가지로, 여러분이 이 글을 읽으면서 코드를 실행한다면, 실행하는데 꽤 많은 시간이 걸립니다. (저의 컴퓨터에서는 각 세대마다 10초 가량이 걸렸습니다.) 그러므로, 코드가 실행되는 동안 계속해서 글을 읽을것을 추천합니다.\n\n```\n\u003e\u003e\u003e net = network.Network([784, 100, 10])\n\u003e\u003e\u003e net.SGD(training_data, 30, 10, 3.0, test_data=test_data)\n```\n\n이번에는 정확도가 96.59%로 올랐습니다. 최소한 이런 경우에서는, 더 많은 은닉 뉴런들은 더 좋은 결과를 가져옵니다. 물론, 이 정확도를 얻기 위해 저는 특정한 세대수, 소집단 크기, 학습률을 선택해야 했습니다. 위에서 언급했듯이, 이러한 변수들은 네트워크에서 가중치와 바이어스와 분리해서 이야기 하기 위해 hyper-parameter라고 부릅니다. 우리가 매우 않좋은 hyper-parameter를 선택한다면, 우리는 나쁜 결과를 얻습니다. 가령, 예를 들어, 학습률로 $\\eta = 0.001$을 골랐다고 합시다.\n\n```\n\u003e\u003e\u003e net = network.Network([784, 100, 10])\n\u003e\u003e\u003e net.SGD(training_data, 30, 10, 0.001, test_data=test_data)\n```\n\n이는 훨씬 별로인 결과를 보여줍니다.\n\n\tEpoch 0: 1139 / 10000\n\tEpoch 1: 1136 / 10000\n\tEpoch 2: 1135 / 10000\n\t...\n\tEpoch 27: 2101 / 10000\n\tEpoch 28: 2123 / 10000\n\tEpoch 29: 2142 / 10000\n\n그러나, 네트워크의 성능이 느리지만 계속해서 올라가고 있음을 알 수 있습니다. 학습률을 $\\eta = 0.01$로 올려보면 어떨까요? 만약 그렇게 한다면, 더 좋은 결과를 얻을 수 있을것입니다. 그렇다면 다시한번 학습률을 올려보면 어떨까요? (약간의 변화가 향상을 만들어 냈다면, 변화를 더 만들어 보세요!) 우리가 이렇게 몇 번을 반복해서 학습률을 $\\eta = 1.0$까지 올렸다고 해봅시다. (어쩌면 3.0까지 올려도 괜찮을겁니다) 이는 앞선 실험에서 사용한 값과 굉장히 비슷합니다. 그래서 초기에 hyper-parameter로 안좋은 값을 골랐을지라도, 결국에는 좋은 값을 고르기 위한 충분한 정보를 얻을 수 있었습니다.\n\n일반적으로, 뉴런 네트워크를 디버깅 하는것은 꽤 힘듭니다. 초기에 선택한 hyper-parameter로 인해 무작위로 값을 내놓는것만 못한 값들을 뉴런 네트워크가 낼때 특히 그렇습니다. 저희가 앞서 성공적으로 사용했던 30개의 은닉 뉴런을 가진 네트워크를 사용하되, 학습률을 $\\eta = 100.0$으로 바꾸어서 학습시킨다고 해봅시다.\n\n```\n\u003e\u003e\u003e net = network.Network([784, 30, 10])\n\u003e\u003e\u003e net.SGD(training_data, 30, 10, 100.0, test_data=test_data)\n```\n\n좀 오바한것 같군요. 학습률이 너무 높습니다.\n\n\tEpoch 0: 1009 / 10000\n\tEpoch 1: 1009 / 10000\n\tEpoch 2: 1009 / 10000\n\tEpoch 3: 1009 / 10000\n\t...\n\tEpoch 27: 982 / 10000\n\tEpoch 28: 982 / 10000\n\tEpoch 29: 982 / 10000\n\n이제 저희가 첫번째로 마주한 상황이 바로 이 상황이라고 가정해 봅시다. 물론, 앞선 실험을 바탕으로 저희는 적절한 해결책은 학습률을 낮추는 것이라고 알고 있습니다. 하지만, 이 상황이 처음 마주한 상황이라면, 현재 얻은 결과로는 저희가 할 수 있는 것이 없습니다. 저희는 학습률 뿐만 아니라 뉴런 네트워크의 다방면에서 이 상황을 바라보아야 합니다. 저희는 저희가 가중치와 바이어스를 초기화 하는 방법이 네트워크가 학습을 더디게 하는 것일까? 라고 걱정해 볼 수 있습니다. 또는 어쩌면 의미있는 학습을 위한 충분한 학습 데이터를 가지고 있지 않을 수 도 있습니다. 어쩌면 충분한 세대 동안 학습을 진행하지 않은 것일까요? 또는 어쩌면 이 네트워크 구조로는 손글씨를 인식하도록 학습하는 것이 불가능 한걸까요? 어쩌면 학습률이 너무 낮은걸까요? 또는 어쩌면 학습률이 너무 높은걸까요? 여러분이 이런 상황을 처음 마주한다면, 그 무엇도 확신할 수 없습니다.\n\n이것으로 부터 얻을 수 있는 것은 일반적인 프로그래밍 처럼 네트워크를 디버깅하는것이 사소하게 볼 문제가 아니라는 것 입니다. 네트워크를 디버깅 하기 위한 기술이 있습니다. 그리고 여러분은 네트워크로 부터 좋은 결과를 얻어내기 위한 그 기술을 배울 필요가 있습니다. 더 일반적으로는, 좋은 hyper-parameter들과 좋은 구조를 선택하기 위해 시행착오를 반복할 필요가 있습니다. 저희는 이 책을 통해 제가 어떻게 위같은 좋은 hyper-parameter들을 얻었는가를 포함해서 이것들에 대해 이야기 해 볼것입니다.\n\n### 연습\n\n입력층, 출력층 단 두개의 층만을 가지고 있는 네트워크를 만들어 보세요. 입력층은 784개의 뉴런, 출력층은 10개의 뉴런을 가지고 있습니다. 그리고 그 네트워크를 확률적 기울기 하강 알고리즘으로 학습시켜 보세요. 얼마나 정확한 판별률을 얻을 수 있나요?\n\n앞서, 저는 어떻게 MNIST 데이터를 로딩했는지에 대한 세부사항을 그냥 지나갔습니다. 꽤 간단합니다. 완성을 위해, 코드를 보여드리겠습니다. MNIST 데이터를 저장하기 위해 사용된 데이터 구조는 아래 주석으로 설명되어 있습니다. 굉장히 간단하게 구성되어 있습니다. 튜플과 Numpy의 ndarray 객체 리스트로 이루어져 있습니다. (ndarrays라는것에 익숙치 않다면 그냥 백터들로 생각하셔도 됩니다.)\n\n```python\n\"\"\"\nmnist_loader\n~~~~~~~~~~~~\n\nA library to load the MNIST image data.  For details of the data\nstructures that are returned, see the doc strings for ``load_data``\nand ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the\nfunction usually called by our neural network code.\n\"\"\"\n\n#### Libraries\n# Standard library\nimport cPickle\nimport gzip\n\n# Third-party libraries\nimport numpy as np\n\ndef load_data():\n    \"\"\"Return the MNIST data as a tuple containing the training data,\n    the validation data, and the test data.\n\n    The ``training_data`` is returned as a tuple with two entries.\n    The first entry contains the actual training images.  This is a\n    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n    numpy ndarray with 784 values, representing the 28 * 28 = 784\n    pixels in a single MNIST image.\n\n    The second entry in the ``training_data`` tuple is a numpy ndarray\n    containing 50,000 entries.  Those entries are just the digit\n    values (0...9) for the corresponding images contained in the first\n    entry of the tuple.\n\n    The ``validation_data`` and ``test_data`` are similar, except\n    each contains only 10,000 images.\n\n    This is a nice data format, but for use in neural networks it's\n    helpful to modify the format of the ``training_data`` a little.\n    That's done in the wrapper function ``load_data_wrapper()``, see\n    below.\n    \"\"\"\n    f = gzip.open('../data/mnist.pkl.gz', 'rb')\n    training_data, validation_data, test_data = cPickle.load(f)\n    f.close()\n    return (training_data, validation_data, test_data)\n\ndef load_data_wrapper():\n    \"\"\"Return a tuple containing ``(training_data, validation_data,\n    test_data)``. Based on ``load_data``, but the format is more\n    convenient for use in our implementation of neural networks.\n\n    In particular, ``training_data`` is a list containing 50,000\n    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray\n    containing the input image.  ``y`` is a 10-dimensional\n    numpy.ndarray representing the unit vector corresponding to the\n    correct digit for ``x``.\n\n    ``validation_data`` and ``test_data`` are lists containing 10,000\n    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional\n    numpy.ndarry containing the input image, and ``y`` is the\n    corresponding classification, i.e., the digit values (integers)\n    corresponding to ``x``.\n\n    Obviously, this means we're using slightly different formats for\n    the training data and the validation / test data.  These formats\n    turn out to be the most convenient for use in our neural network\n    code.\"\"\"\n    tr_d, va_d, te_d = load_data()\n    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n    training_results = [vectorized_result(y) for y in tr_d[1]]\n    training_data = zip(training_inputs, training_results)\n    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n    validation_data = zip(validation_inputs, va_d[1])\n    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n    test_data = zip(test_inputs, te_d[1])\n    return (training_data, validation_data, test_data)\n\ndef vectorized_result(j):\n    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n    position and zeroes elsewhere.  This is used to convert a digit\n    (0...9) into a corresponding desired output from the neural\n    network.\"\"\"\n    e = np.zeros((10, 1))\n    e[j] = 1.0\n    return e\n```\n\n전 위에서 저희의 프로그램이 꽤 좋은 결과를 얻었다고 말씀드렸습니다. 그것이 무엇을 의미할까요? 무엇에 비교해서 좋은걸까요? 잘 작동한다는 것이 무엇을 의미하는이 이해하기 위해 비교할 간단한 기준선을 만들어 보는것이 좋겠습니다. 가장 간단한 기준선은 역시 숫자들을 무작위로 추측하는것 입니다. 아마 각 횟수마다 정확히 10% 확률로 맞출 수 있을겁니다. 저희는 그것보다 훨씬 낫습니다!\n\n좀 덜 이상한 기준선을 세워볼까요? 이 극단적인 예시를 한번 들어봅시다: 저희는 이미지가 얼마나 어두운지 볼 것입니다. 예를들어, 2라는 숫자의 이미지는 일반적으로 1이라는 숫자의 이미지 보다는 더 어두울 것입니다. 왜냐하면 더 많은 픽셀들이 검정으로 이루어져 있기 때문입니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/mnist_2_and_1.png\" style=\"cursor: pointer;max-width:100%;height:auto\" onclick=\"open_img('https://cfile4.uf.tistory.com/original/275F34495961E4CE0F49F1')\"  height=\"150\" style=\"width: 308px; height: 150px;\" width=\"308\" /\u003e\u003c/center\u003e\n\n학습 데이터를 사용해서 각 숫자의 어두운 정도의 평균을 계산해 봅시다. 그리고 어떤 이미지가 주어지면, 그 이미지의 어두운 정도를 계산해서, 어떤 평균값에 근접한지 추측하는겁니다. 이는 매우 간단한 과정이며 코드로 짜기 쉽습니다. 그래서 자세한 코드를 보여드리진 않을겁니다. 관심 있으시다면 \u003ca href=\"https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py\" target=\"_blank\" class=\"tx-link\"\u003e깃허브 레포지토리\u003c/a\u003e를 확인해 주세요. 이는 무작위 추측에 비해 엄청난 향상을 가져옵니다. 10,000개 중에 2,225개를 맞출 수 있었으며, 이는 22.25%의 판별률을 가집니다.\n\n20%에서 50%의 정확도를 가질 수 있도록 하는 다른 아이디어를 찾는것은 어렵지 않습니다. 좀더 열심히 찾아본다면 50% 이상도 가능합니다. 하지만 더 높은 정확도를 얻기 위해서는 확립된 머신 러닝 알고리즘을 사용하는것이 도움이 될겁니다. 가장 잘 알려진 알고리즘중에 하나인 support vector machine 또는 SVM을 사용해 봅시다. SVM에 익숙치 않으시다면, 걱정하지 마세요. \n\n","slug":["2017-04-15-implementing-our-network-to-classify-digits"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"제 2장 - 역전파 알고리즘이 어떻게 작동하는가\",\"date\":\"2017-04-18 18:55:08 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n전 장에서 우리는 어떻게 뉴런 네트워크가 기울기 하강 알고리즘을 사용해서 가중치와 $bias$를 학습하는지에 대해 보았습니다. 그러나 여기에서 우리의 설명에는 큰 구멍이 하나 있었습니다: 우리는 어떻게 비용함수의 기울기를 계산하는지 이야기 하지 않았습니다. 정말 큰 구멍입니다! 이 장에서 저는 역전파 라고 알려진 그런 기울기를 계산하는 빠른 알고리즘에 대해서 설명할 것 입니다.\n\n역전파 알고리즘은 1970년대에 처음 소개되었지만, [데이비드 루멜하트][david_rumelhart], [제프리 힌튼][hinton], 그리고 [로널드 윌리엄스][ronald_williams]의 [유명한 1986년도의 논문][1986_paper]이 나오기 전 까지는 그 중요성이 인정되지 않았습니다. 이 논문은 이전에는 풀리지 않았던 문제들을 풀 수 있는 뉴런 네트워크의 사용을 가능케 하면서 이전의 학습에 대한 접근방법보다 역전파 알고리즘이 더 빨리 작동하는 몇개의 뉴런 네트워크에 대해 설명하였습니다. 오늘날, 역전파 알고리즘은 뉴런 네트워크에서의 학습의 대표주자가 되었습니다.\n\n\u003c!-- more --\u003e\n\n이 장은 이 책의 나머지 부분보다 수학적인 부분이 많이 연관되어 있습니다. 여러분이 수학에 미치지 않았다면 이 장을 넘겨버리고 역전파를 무시해버리고 싶은 내용들을 담은 판도라 상자처럼 여기고 싶을겁니다. 이런 내용들을 공부하는데 왜 시간을 투자해야 할까요?\n\n그 이유는, 당연히, 이해를 위한겁니다. 역전파의 핵심은 네트워크에서의 그 어떤 가중치 $w$(또는 bias $b$)에 대한 비용 함수 $C$의 편미분 $\\partial C/\\partial w$의 식입니다. 이 식은 우리에게 우리가 가중치와 $bias$를 바꿀때 비용함수가 얼마나 빠르게 바뀌는지에 대해 말해줍니다. 그리고 이 식이 좀 복잡한 반면, 각 항들은 자연적이고 직관적이 해석이 가능한 아름다움을 가지고 있습니다. 그리고 또한 역전파는 학습을 위한 단지 빠른 알고리즘이 아닙니다. 이는 가중치와 $bias$의 변화가 네트워크의 전체 행동을 변화시키는지에 대한 자세한 식견을 알려줍니다. 자세한 사항을 공부하는것은 정말 가치가 있습니다.\n\n앞서 말했듯이, 이 장을 넘기고 슥 지나가고 싶거나 그냥 바로 다음장으로 넘어가고 싶다면, 괜찮습니다. 저는 여러분이 역전파를 알수없는 판도라의 상자와 같이 다루더라도 책의 나머지 부분은 접근하기 쉽도록 작성하였으니까요. 물론 이 장으로 부터의 결론을 다시 언급하게될\u0026nbsp;책의 후반부에는 중요한 요점들이 있습니다. 그러나 그 중요한 요점들에서는 여러분이 모든 이유를 따라가지 못하더라도 주 결론에 대한 이해를 할 수 있어야 합니다.\n\n[david_rumelhart]: https://en.wikipedia.org/wiki/David_Rumelhart\n[hinton]: https://www.cs.toronto.edu/~hinton/\n[ronald_williams]: https://en.wikipedia.org/wiki/Ronald_J._Williams\n[1986_paper]: https://www.nature.com/nature/journal/v323/n6088/pdf/323533a0.pdf\n","slug":["2017-04-18-neuralnet-chap2-how-the-backpropagation-algorithm-works"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"역전파에 대한 네가지 중요한 공식(작성중)\",\"date\":\"2017-04-18 19:57:43 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"역전파는 어떻게 네트워크에서의 가중치와 $bias$의 변화가 비용함수를 바꾸는지에 대한 이해에 관한 것 입니다. 궁극적으로, 이는 $\\partial C/\\partial w^l_{jk}$ 그리고 $\\partial C/\\partial b^l_j$에 대한 편미분을 계산하는 것을 의미합니다. 그러나 이것을 계산하기 위해서 우리는 먼저 $l^{th}$ 층에 있는 $j^{th}$뉴런에서 error 라고 부르는 $\\delta^l_j$라는 중간값을 소개하려고 합니다. 역전파는 error $\\delta^l_j$를 계산하기 위한 과정을 말해주며 $\\delta^l_j$를 $\\partial C/\\partial w^l_{jk}$와 $\\partial C/\\partial b^l_j$와 관련지어줍니다.\n\n어떻게 error 가 정의되는지 이해하기 위해서, 우래의 네트워크에 악마가 하나 있다고 상상해 봅시다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz19.png\" style=\"max-width:100%;height:auto\"  height=\"240\" width=\"583\"/\u003e\u003c/center\u003e\n\n\u003c!-- more --\u003e\n\n$l$층에 있는 $j^{th}$ 뉴런에 악마가 있군요. 뉴런에 입력이 들어옴에 따라, 악마는 뉴런의 작동에 장난을 칠겁니다. 이 장난은 뉴런의 가중치 계산이 된 입력값에 작은 변화 $\\Delta z^l_j$ 를 가할것이고, 뉴런은 $\\sigma (z^l_j)$를 출력으로 내보내는 대신에 $\\sigma (z^l_j + \\Delta z^l_j)$를 내보낼 것 입니다. 이러한 변화는 네트워크의 나머지 층을 통해 전파되어, 결국에는 전체적인 비용에 대해 $\\frac{\\partial C}{\\partial z^l_j} \\Delta z^l_j$만큼의 변화를 만들어 낼 것입니다.\n\n이제, 이 악마는 좋은 악마입니다. 그리고 비용을 향상시키기 위해 여러분에게 도움을 줄 것입니다. 악마는 비용을 작게 만들 수 있는 $\\Delta z^l_j$를 찾으려고 노력할 것 입니다. $\\frac{\\partial C}{\\partial z^l_j}$가 굉장히 큰 값을 가지고 있다고 가정해 봅시다(양수든 음수든). 그러면 악마는 $\\frac{\\partial C}{\\partial z^l_j}$와는 반대의 부호를 가지는 $\\Delta z^l_j$를 선택함으로써 비용함수의 값을 좀 낮출 수 있습니다. 반대로, $\\frac{\\partial C}{\\partial z^l_j}$가 0에 가깝다면, 악마는 가중치가 계산된 $z^l_j$의 값을 통해 비용함수의 값을 개선할 수 없을 것 입니다. 그렇게 된다면 악마는 뉴런이 이미 꽤 잘 학습하였다고 말할 수 있습니다. 그리고 $\\frac{\\partial C}{\\partial z^l_j}$가 뉴런의 error의 값의 척도라는 경험적인 것을 알 수 있군요.\n\n이 이야기로부터 영감을 받아, 우리는 $l$ 층의 $j$ 뉴런의 error $\\delta^l_j$를 다음과 같이 정의할 수 있습니다.\n\n$$\\begin{eqnarray}   \\delta^l_j \\equiv \\frac{\\partial C}{\\partial z^l_j}.\\tag{29}\\end{eqnarray}$$\n","slug":["2017-04-18-the-four-fundamental-equations-behind-backpropagation"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"하다마드 곱\",\"date\":\"2017-04-18 19:48:16 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n역전파 알고리즘은 일반적인 선형 대수학 연산자를 기반으로 합니다. 백터의 덧셈, 행렬으로 백터를 곱하는 등등... 하지만 한 연산자는 보통 잘 사용되지 않습니다. 특히, 같은 차원의 두 백터 $s$, $t$가 있다고 가정해 봅시다. 그러면 우리는 $s\\odot t$를 두 백터의 각 성분마다의 곱으로 사용할 수 있습니다. 따라서 $s\\odot t$의 연산은 단지 $(s\\odot t)_j=s_j t_j$으로 이루어 집니다. 예를 들면,\n\n$$\\begin{eqnarray}\\left[\\begin{array}{c} 1 \\\\ 2 \\end{array}\\right]   \\odot \\left[\\begin{array}{c} 3 \\\\ 4\\end{array} \\right]= \\left[ \\begin{array}{c} 1 * 3 \\\\ 2 * 4 \\end{array} \\right]= \\left[ \\begin{array}{c} 3 \\\\ 8 \\end{array} \\right].\\tag{28}\\end{eqnarray}$$\n\n이런 종류의 성분마다의 곱은 가끔 하다마드 곱 또는 Schur product 라고 불립니다. 우리는 이것을 하다마드 곱으로 부를겁니다. 좋은 행렬 라이브러리는 보통 하다마드 곱의 빠른 구현을 제공하고 역전파를 구현할때 굉장히 편리합니다.\n\n","slug":["2017-04-18-the-hadamard-product"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"비용함수에 대해 필요한 두가지 추정(작성중)\",\"date\":\"2017-04-18 19:43:01 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n역전파의 목적은 네트워크의 어떠한 가중치 $w$ 또는 bias $b$에 대한 비용함수 $C$의 편미분 $\\partial C/\\partial w$ 그리고 $\\partial C/\\partial b$를 계산해내는 것 입니다. 역전파가 작동하기 위해서 우리는 비용함수의 형태에 대한 두가지 주된 추측을 만들어 볼 필요가 있습니다. 두 추측을 이야기 하기 전에, 머릿속에 비용함수의 예를 생각하는것이 도움이 되겠군요. 우리는 저번 장에서의 사용했던 이차 비용함수를 사용할 것입니다. 마지막 섹션에서의 표기에서, 이차 비용함수는 다음과 같은 형태를 갖습니다.\n\n$$\\begin{eqnarray}  C = \\frac{1}{2n} \\sum_x \\|y(x)-a^L(x)\\|^2,\\tag{26}\\end{eqnarray}$$\n\n$n$은 학습 데이터의 총 갯수이고, 시그마는 각각의 학습 데이터 $x$ 에 대한 것이고, $y=y(x)$는 $x$ 해당하는 원하는 출력을 나타냅니다. $L$은 네트워크의 층의 갯수를 나타냅니다. 그리고 $a^L=a^L(x)$는 $x$가 입력으로 주어졌을때 네트워크로부터의 활성화된 출력의 백터입니다.\n\n\u003c!-- more --\u003e\n\n좋습니다, 그러면 역전파가 적용되기 위해서 우리의 비용함수 $C$에 대해 우리가 만들어야 하는 추측은 무엇인가요? 첫번째 추측은 비용함수는 각각의 학습 데이터 $x$에 대한 비용함수 $C_x$에 대한 평균 $C=\\frac{1}{n}\\sum_x C_x$으로 쓰여질 수 있다는것 입니다.\n\n","slug":["2017-04-18-the-two-assumptions-we-need-about-the-cost-function"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"딥러닝을 향해\",\"date\":\"2017-04-18 01:01:22 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"\n우리의 뉴런 네트워크가 인상적인 성과를 보여주었지만, 이러한 성과는 약간 미스테리 합니다. 가중치들과 $bias$들은 자동적으로 조정되었습니다. 그리고 이는 네트워크가 이뤄낸 일을 도데체 어떻게 이루어 낸건지에 대한 설명을 즉시 할 수 없음을 의미합니다. 우리의 네트워크가 손글씨를 판별하고 있음에 대한 원리를 이해하기 위한 방법을 찾을 수 있을까요? 그리고, 그 원리들을 통해, 더 좋은 결과를 만들어 낼 수 있을까요?\n\n이 질문들을 더 완벽히 하자면, 수십년 후에 뉴런 네트워크가 인공지능(Artificial Inteligence)을 이끌어 간다고 가정해 봅시다. 우리가 어떻게 지능적인 네트워크가 작동하는지 이해할 수 있을까요? 어쩌면 네트워크는 스스로 학습하였기 때문에 우리가 이해하지 못하는 가중치들과 $bias$들도 마찬가지로 우리에게는 불투명해 보일겁니다. 인공지능 연구의 초기에 사람들은 지능에 대한 원리, 어쩌면 인간의 뇌의 작동방식에 대한 원리를 이해하는데 AI를 만드려는 노력이 도움이 될것이라고 기대하였습니다. 하지만 어쩌면 결과는 우리가 뇌의 작동방식과 어떻게 인공지능이 작동하는지에 대해 모두 이해하지 못한채로 끝날 수 도 있습니다.\n\n\u003c!-- more --\u003e\n\n이 질문의 목적을 명확히 하기 위해서, 제가 이 장의 초반에 의사결정 모델로써 이야기 하였던 인공 뉴런의 해석으로 돌아가 봅시다. 우리가 아래 보여지는 이미지들이 사람의 얼굴인지 아닌지 구분하고 싶다고 가정해 봅시다.\n\n\u003cdiv\u003e\n\u003cimg src=\"https://cfile3.uf.tistory.com/image/252EA84758F4DC7B051F2A\" height=\"240\" width=\"180\"/\u003e\n\u003cimg src=\"https://cfile9.uf.tistory.com/image/224EDF4758F4DC7C0A6C54\" height=\"233\" width=\"273\"/\u003e\n\u003cimg src=\"https://cfile2.uf.tistory.com/image/2441D84758F4DC7C043F55\" height=\"240\" width=\"275\"/\u003e\n\u003c/div\u003e\n\n우리는 우리가 손글씨 인식문제를 해결하던 방법대로 이 문제를 해결할 수 있습니다. 이미지의 각 픽셀을 네트워크의 입력으로 넣고, \"네, 이것은 얼굴입니다\" 또는 \"아니요, 이것은 얼굴이 아닙니다\" 를 나타내는 하나의 출력 뉴런을 넣으면 됩니다.\n\n우리가 이것을 한다고 가정해 봅시다, 하지만 학습 알고리즘을 사용하지 않는다고 합시다. 대신, 우리는 우리는 직접 적절한 가중치와 $bias$를 골라 네트워크를 디자인 할것입니다. 이것을 어떻게 접근해야 할까요? 잠시 뉴런 네트워크에 대해 모조리 잊고, 경험적으로 우리가 사용할 수 있는것은 문제를 작은 단위로 쪼개는 것 입니다: 사진이 왼쪽 위에 눈을 가지고 있나요? 사진이 오른쪽 위에 눈을 가지고 있나요? 가운데에 코가 있나요? 가운데 아래에 입을 가지고 있나요? 위에는 머리카락을 가지고 있나요? 이런식으로요.\n\n이러한 질문들의 답변들이 \"예\" 또는 \"아마 맞습니다\" 이라면, 우리는 이 사진은 얼굴이라고 결론내릴 수 있습니다. 반대로, 대부분의 질문에 대한 답변이 \"아니오\" 라면, 이 사진은 얼굴이 아마 아닐겁니다.\n\n당연히, 이는 힘든 방법이고 많은 정보의 부족으로 인해 판단하기 힘들 수 도 있습니다. 사람이 대머리라면 머리카락이 없을것 입니다. 혹은 얼굴의 부분만을 또는 특정한 각도의 얼굴만을 볼 수도 있습니다. 그렇게 되면 얼굴의 특징들을 집어내기 어렵겠죠. 하지만, 이러한 경험적인 것들은 만약 우리가 뉴런 네트워크로 이런 부분적인 문제를 풀 수 있다면, 작은 문제들에 대한 네트워크를 합침으로써 얼굴 감지를 위한 뉴런 네트워크를 만들 수 있을것이라고 이야기 해 줍니다. 여기 부분적인 네트워크를 의미하는 사각형들이 그려진 가능할만한 구조가 하나 있습니다. 물론 얼굴 감지 문제를 풀기위한 현실적인 접근 방법은 아닙니다. 그보다, 네트워크가 어떻게 움직일지에 대한 직관을 쌓는데 도움을 줄겁니다. 여기 그 구조를 나타낸 그림이 있습니다.\n\n\u003ccenter\u003e\u003cimg src=\"https://cfile6.uf.tistory.com/image/27398A4758F4DF7B013B42\" style=\"max-width:100%;height:auto\"  height=\"409\" style=\"\" width=\"611\"/\u003e\u003c/center\u003e\n\n부분적인 네트워크들이 분리될 수 있음이 당연해 보이는군요. 다음과 같은 질문을 생각해 봅시다. \"왼쪽 위에 눈이 있나요?\" 이는 또 여러가지의 질문들로 쪼개질 수 있습니다. \"눈썹이 있나요?\", \"속눈썹이 있나요?\", \"홍채가 있나요?\", 이런식으로요. 당연히 이러한 질문들은 위치에 대한 정보들도 담고 있어야 합니다. \"눈썹이 왼쪽 위에 있고 홍채 위에 있나요?\" 이런 질문이죠. \"왼쪽 위에 눈이 있나요?\"라는 질문에 답하는 네트워크는 이제 다음과 같이 분리될 수 있습니다.\n\n\u003ccenter\u003e\u003cimg src=\"https://cfile23.uf.tistory.com/image/2461F24E58F4E15414474B\" style=\"max-width:100%;height:auto\"  height=\"239\" style=\"\" width=\"597\"/\u003e\u003c/center\u003e\n\n이러한 질문들은 더 많고 많은 여러 층들을 통해 더욱 더 많이 분리 될 수 있습니다. 궁극적으로, 하나의 픽셀 단위 수준에서 쉽게 답을 할 수 있는 질문들을 답하는 네트워크들을 가지게 될 것입니다. 이러한 질문들은 아마, 예를들면, 이미지에서의 특정한 위치에서의 매우 간단한 모양의 존재 유무에 대한 것이 될겁니다. 이런 질문들은 이미지의 원본 픽셀에 연결된 하나의 뉴런으로 해결될 수 있습니다.\n\n최종적인 결과는 매우 복잡한 질문을 잘게 쪼개 나가는, 이미지가 얼굴이 있는지 아닌지와 같은 질문을 하나의 픽셀 단위 수준에서 답변 가능한 질문들로 쪼개나가는 네트워크가 될것 입니다. 입력 이미지에 대한 매우 간단하고 특정한 질문들을 앞쪽 층들과 더 복잡하고 추상적인 개념들의 층을 쌓아나가는 뒤쪽 층들로 이루어진 많은 층들로 이러한 문제를 해결합니다. 이러한 두개 이상의 은닉층을 가지는 다층 구조의 네트워크는 딥 뉴런 네트워크 라고 불립니다.\n\n물론, 저는 아직 작은 네트워크으로 반복적인 분해를 하는지에 대해 이야기 하지 않았습니다. 이는 네트워크에서 가중치와 $bias$를 손으로 디자인 하기에는 현실적이지 않습니다. 대신, 학습 알고리즘을 사용함으로써 네트워크가 스스로 학습 데이터로 부터 가중치와 $bias$를 찾도록, 궁극적으로는 개념들의 층들을 쌓도록 할 수 있습니다. 1980년과 1990년대 연구자들은 이런 딥 뉴런 네트워크를 학습시키려고 노력해 왔습니다. 불행히도, 몇개의 특별한 경우를 제외하고서는 성과를 올리기 힘들었습니다. 네트워크는 느리게 배우기는 했지만, 유용히 쓰이기에는 실제로는 너무 느렸습니다.\n\n2006년부터, 여러 기술들이 개발되어 딥 뉴런 네트워크에서의 학습을 가능케 했습니다. 이런 딥 뉴런 네트워크 학습 기술들은 확률적 기울기 하강 알고리즘과 역전파 그리고 새로운 아이디어들로 부터 개발되었습니다. 이런 기술들은 더욱 깊고 큰 네트워크의 학습을 가능케 합니다. 사람들은 이제 일반적으로 5개에서 10개 까지의 은닉층을 가진 네트워크를 학습시킵니다. 그래서 이젠 단 하나의 은닉층을 가진 네트워크와 같은 얕은 뉴런 네트워크보다 더 많은 문제들에 있어서 더 좋은 성능을 보여줍니다. 이유는 당연히 개념들의 복잡한 계층을 쌓을 수 있는 딥 네트워크의 능력 때문입니다. 일반적인 프로그래밍 언어가 복잡한 컴퓨터 프로그램을 만들어냄을 가능케 하기 위해 추상적인 것에 대한 부분적인 디자인과 아이디어들을 사용하는것과 같은 방법과 비슷합니다. 얕은 네트워크와 깊은 네트워크의 비교는 함수 호출을 만들어 낼 수 있는 능력을 가진 프로그래밍 언어와 그러한 호출을 만들어낼 수 없는 절차지향적인 언어의 비교와 비슷합니다. 추상화는 일반적인 프로그래밍에서 하는것보다 뉴런 네트워크에서 다른 형태를 취하나, 여전히 중요합니다.\n\n","slug":["2017-04-18-toward-deep-learning"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"준비운동 뉴런 네트워크로 부터의 결과를 계산하기 위한 빠른 행렬 기반 접근방법\",\"date\":\"2017-04-18 19:09:34 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"역전파를 언급하기 이전에, 뉴런 네트워크로 부터의 결과를 계산하기위한 빠른 행렬기반 알고리즘부터 시작해 봅시다. 사실 우리는 이미 전 장의 마지막 부분에서 이 알고리즘에 대해 요약적으로 보았습니다. 하지만 저는 이를 매우 빠르게 설명하였고 우리는 이 세부사항에 대해 다시 살펴볼 가치가 있습니다. 특히, 이는 비슷한 상황에서 역전파에 사용된 여러 기호들에 익숙해 지는 좋은 방법입니다.\n\n모호한 방법으로 뉴런 네트워크의 가중치들을 언급하는 한 기호로 부터 시작해 봅시다. 우리는 $w^l_{jk}$라는 기호를 $l^{th}$ 층에 있는 $j^{th}$ 뉴런을 가리키는 $(l-1)^{th}$ 층에 있는 $k^{th}$ 뉴런의 연결을 나타내는데 사용할겁니다. 그래서, 예를 들면, 아래 다이어그램은 네트워크의 세번째 층에 있는 두번째 뉴런을 가리키는 두번째 층의 네번째 뉴런의 연결을 나타냅니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz16.png\" style=\"max-width:100%;height:auto\"  height=\"243\" width=\"617\"/\u003e\u003c/center\u003e\n\n\u003c!-- more --\u003e\n\n이 기호는 처음에는 이해하기 어렵습니다. 그리고 이를 숙달하려면 좀 시간이 걸립니다. 하지만 조금만 노력하면 이 기호가 자연스럽고 쉽다고 느껴질 겁니다. 이 기호에서 별난점은 $j$와 $k$의 번호매김방법입니다. 여러분은 아마 $j$를 입력 뉴런으로, $k$를 출력 뉴런으로 생각하는것이 더 직관적이라고 생각할지도 모르겠습니다. 저는 이 별난점에 대한 이유를 아래 설명해 놓았습니다.\n\n우리는 네트워크의 bias와 활성화에 대해 비슷한 기호를 사용합니다. 분명히, 우리는 $l^{th}$ 층에 있는 $j^{th}$ 뉴런의 bias 에 대해 $b^l_j$라고 표기합니다. 그리고 $l^{th}$ 층에 있는 $j^{th}$ 뉴런에의 활성화에 대해 $a^l_j$라는 기호를 사용합니다. 다음 그림은 이 기호들의 사용에 대한 예를 보여줍니다.\n\n\u003ccenter\u003e\u003cimg src=\"/assets/neuralnet/tikz17.png\" style=\"max-width:100%;height:auto\"  height=\"243\" width=\"298\"/\u003e\u003c/center\u003e\n\n이 기호들과 함께, $l^{th}$ 층의 $j^{th}$ 뉴런의 활성화 값은 다음 공식에 의해 $a^l_j$는 $(l-1)^{th}$층에 있는 활성화 값들과 관련이 있습니다. (이전 장에서의 4번 공식과 그에 대해 논한 것들과 함께 비교해 보세요)\n\n$$\\begin{eqnarray}   a^{l}_j = \\sigma\\left( \\sum_k w^{l}_{jk} a^{l-1}_k + b^l_j \\right),\\tag{23}\\end{eqnarray}$$\n\n시그마는 $(l-1)^{th}$층에 있는 모든 뉴런들에 대한 것 입니다. 이 식을 행렬의 형태로 다시 쓰기위해 우리는 각 층 $l$에 대해 가중치 행렬 $w^l$를 정의할겁니다. 가중치 행렬 $w^l$의 성분들은 단지 뉴런의 $l^{th}$층으로 연결된 가중치들을 의미합니다. 다시말하면, $j$번째 행과 $k$번째 열에 있는 성분은 $w^l_{jk}$입니다. 비슷하게, 각 $l$층에 대해 우리는 $bias$ 백터 $b^l$을 정의할 수 있습니다. 여러분은 아마 어떻게 이것이 작동할지 추측할 수 있습니다. bias 백터의 성분들은 단지 $b^l_j$ 의 값들입니다. 하나의 성분은 $l$번째 층의 각 뉴런에 대응됩니다. 그리고 마지막으로, 우리는 활성화 값 $a^l_j$들을 성분으로 가지는 활성화값 백터 $a^l$을 정의할 수 있습니다.\n\n23번 공식을 행렬의 형태로 다시 쓰기 위해 우리에게 필요한 마지막 재료는 시그모이드 함수와 같은 함수를 백터화 하는것 입니다. 우리는 전 장에서 잠시 백터화에 대해 이미 만났지만 다시 요약하자면, 이 개념은 백터 $v$의 모든 성분에 시그모이드 함수와 같은 함수를 적용하는 것 입니다. 우리는 이러한 함수의 성분마다의 작업을 나타내기 위해 $\\sigma (v)$라는 분명한 기호를 사용할 것 입니다. 다시 말하면, $\\sigma (v)$의 각 성분은 단지 $\\sigma (v)_j=\\sigma (v_j)$입니다. 예를들면, 만약 우리가 $f(x)=x^2$라는 함수를 가지고 있다면 백터화된 형태의 함수 $f$는 다음과 같은 일을 할 것 입니다.\n\n$$\\begin{eqnarray}  f\\left(\\left[ \\begin{array}{c} 2 \\\\ 3 \\end{array} \\right] \\right)  = \\left[ \\begin{array}{c} f(2) \\\\ f(3) \\end{array} \\right]  = \\left[ \\begin{array}{c} 4 \\\\ 9 \\end{array} \\right],\\tag{24}\\end{eqnarray}$$\n\n다시 말하면, 백터화된 함수 $f$는 백터의 모든 성분마다 제곱을 취하는 것 입니다.\n\n이 기호들을 머릿속에 담아두면서, 23번 공식은 다음과 같이 아름답고 최소화된 백터화된 형태로 다시 쓰여질 수 있습니다.\n\n$$\\begin{eqnarray}   a^{l} = \\sigma(w^l a^{l-1}+b^l).\\tag{25}\\end{eqnarray}$$\n\n이 식은 우리에게 어떻게 한 층에서의 활성화가 이전의 층에서의 활성화값들과 관계가 있는지에 대해 생각할 수 있는 좀 더 전체적인 방법을 말해줍니다: 우리는 단지 활성화 값들에 가중치 행렬을 곱하고, bias 백터를 더하고, 그리고 최종적으로 시그모이드 함수를 적용하였습니다. 이런 전체적인 시각은 우리가 지금까지 취해왔던 뉴런단위의 시각보다 쉽고 더 간단명로 합니다.(그리고 더 적은 번호들을 사용합니다!) 무엇이 일어나고 있는지에 대해 명확히 하면서 이를 번호매김의 지옥에서 벗어나는 한 방법으로 생각해 보세요. 이 식은 대부분의 행렬 라이브러리가 행렬곱과 백터 덧셈의 빠른 구현을 제공하고 있기 떄문에 현실적으로도 굉장히 유용합니다. 실제로, 전 장에서의 코드는 네트워크의 행동을 계산하기 위해 이러한 식의 사용을 내포하고 있었습니다.\n\n$a^l$을 계산하기 위해 25번 식을 사용할때, 우리는 이 방법을 따라 $z^l \\equiv w^la^{l-1}+b^l$ 라는 중간 값을 계산합니다. 이 값은 이름을 지어주기에 충분히 쓸모있습니다: 우리는 이 $z^l$라는 값을 $l$번째 레이어의 뉴런들에 대한 weighted input(입력 가중치)이라고 부릅니다. 우리는 이 장의 후반부에서 입력 가중치 $z^l$의 많은 사용을 하게 될 겁니다. 25번 식은 입력 가중치에 대해서 $a^l=\\sigma (z^l)$와 같이 쓰여지곤 합니다. $z^l$는 $z^l_j=\\sum_k w^l_{jk}a^{l-1}_k+b^l_j$라는 항들을 가지고 있다고 알려드리는것이 좋겠군요. 다시 말하면, $z^l_j$는 단지 $l$번째 층의 $j$번째 뉴런에 대한 활성화 함수로의 입력 가중치 입니다.\n\n","slug":["2017-04-18-warm-up-a-fast-matrix-based-approach-to-computing-the-output-from-a-neural-network"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"제 3장 - 뉴런 네트워크가 학습하는 방법 향상하기(작성중)\",\"date\":\"2017-05-14 20:07:26 +0900\",\"categories\":null,\"tags\":\"NeuralNetworksAndDeepLearning\"}","markdownbody":"한 골프 선수가 처음으로 골프를 배울 때, 선수는 기본적인 스윙을 연습하는데에 대부분의 시간을 소비합니다. 기본적인 스윙을 쌓고 수정하면서 칩샷, 드로샷, 페이드샷과 같은 다른 샷들을 점차 배워갑니다. 비슷하게, 지금까지 우리는 역전파 알고리즘을 이해하는데에 초점을 맞춰왔습니다. 이것이 우리의 \"기본적인 스윙\"입니다. 뉴런 네트워크에서의 다른 일들을 하기위한 학습의 기초를 다듬은 것이지요. 이 장에서는 역전파의 기본적인 구현을 향상 시킬수 있는 기술들을 소개하고 우리의 네트워크의 학습을 개선하고자 합니다\n\n\u003c!-- more --\u003e\n\n이 장에서 개발해낼 기술들은 다음과 같습니다: 크로스 엔트로피 비용함수 라고 알려진 더 좋은 비용함수의 선택, 우리의 네트워크를 학습데이터를 넘어서 보편화하기 위한 네개의 \"조직화\" 함수(L1 그리고 L2 규칙화, 드롭아웃, 그리고 학습 데이터의 인공적 확장), 네트워크의 가중치를 초기설정하기위한 더 좋은 함수, 그리고 마지막으로 네트워크를 위한 좋은 하이퍼-변수를 선택하기 위한 여러 경험적 사실들이 있습니다. 저는 또한 낮은 수준에서 몇개의 다른 기술들을 미리 보여드릴겁니다.\n","slug":["2017-05-14-neuralnet-chap3-improving-the-way-neural-networks-learn"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"구글 웹 폰트 목록\",\"categories\":\"etc\",\"tags\":\"html\",\"date\":\"2017-08-27 17:27:00 +0900\"}","markdownbody":"\n## 나눔 손글씨\n```css\n@import url(//fonts.googleapis.com/earlyaccess/nanumpenscript.css);\nfont-family: 'Nanum Pen Script', cursive;\n```\n\n## 제주 고딕\n```css\n@import url(//fonts.googleapis.com/earlyaccess/jejugothic.css);\nfont-family: 'Jeju Gothic', sans-serif;\n```\n\n## 제주 명조\n```css\n@import url(//fonts.googleapis.com/earlyaccess/jejumyeongjo.css);\nfont-family: 'Jeju Myeongjo', serif;\n```\n\n\u003c!-- more --\u003e\n\n## 나눔 붓글씨\n```css\n@import url(//fonts.googleapis.com/earlyaccess/nanumbrushscript.css);\nfont-family: 'Nanum Brush Script', cursive;\n```\n\n## Nato Sans KR\n```css\n@import url(//fonts.googleapis.com/earlyaccess/notosanskr.css);\nfont-family: 'Noto Sans KR', sans-serif;\n```\n\n## 한나체\n```css\n@import url(//fonts.googleapis.com/earlyaccess/hanna.css);\nfont-family: 'Hanna', sans-serif;\n```\n\n## 나눔 고딕\n```css\n@import url(//fonts.googleapis.com/earlyaccess/nanumgothic.css);\nfont-family: 'Nanum Gothic', sans-serif;\n```\n\n## 나눔 명조\n```css\n@import url(//fonts.googleapis.com/earlyaccess/nanummyeongjo.css);\nfont-family: 'Nanum Myeongjo', serif;\n```\n\n## 제주 한라산\n```css\n@import url(//fonts.googleapis.com/earlyaccess/jejuhallasan.css);\nfont-family: 'Jeju Hallasan', cursive;\n```\n\n## 나눔 고딕 코딩\n```css\n@import url(//fonts.googleapis.com/earlyaccess/nanumgothiccoding.css);\nfont-family: 'Nanum Gothic Coding', monospace;\n```\n\n## Nato Sans KR 예시\n\u003cdiv style=\"font-family: 'Noto Sans KR', sans-serif;font-size:36px;text-align: center;\"\u003e\n\u003c!--\n\t\u003cp style=\"font-weight: 100;\"\u003e\n\t\t새〮로〮스〮믈〮여듧〮ᄍᆞᆼ〮ᄅᆞᆯ〮ᄆᆡᇰᄀᆞ〮노니〮\n\t\u003c/p\u003e\n\t\u003cp style=\"font-weight: 300;\"\u003e\n\t\t새〮로〮스〮믈〮여듧〮ᄍᆞᆼ〮ᄅᆞᆯ〮ᄆᆡᇰᄀᆞ〮노니〮\n\t\u003c/p\u003e\n\t--\u003e\n\t\u003cp style=\"font-weight: 400;\"\u003e\n\t\t새〮로〮스〮믈〮여듧〮ᄍᆞᆼ〮ᄅᆞᆯ〮ᄆᆡᇰᄀᆞ〮노니〮\n\t\u003c/p\u003e\n\t\u003cp style=\"font-weight: 500;\"\u003e\n\t\t새〮로〮스〮믈〮여듧〮ᄍᆞᆼ〮ᄅᆞᆯ〮ᄆᆡᇰᄀᆞ〮노니〮\n\t\u003c/p\u003e\n\t\u003cp style=\"font-weight: 700;\"\u003e\n\t\t새〮로〮스〮믈〮여듧〮ᄍᆞᆼ〮ᄅᆞᆯ〮ᄆᆡᇰᄀᆞ〮노니〮\n\t\u003c/p\u003e\n\t\u003cp style=\"font-weight: 900;\"\u003e\n\t\t새〮로〮스〮믈〮여듧〮ᄍᆞᆼ〮ᄅᆞᆯ〮ᄆᆡᇰᄀᆞ〮노니〮\n\t\u003c/p\u003e\n\u003c/div\u003e\n","slug":["2017-08-27-google-web-fonts"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"A-FA 퀵 시프터 제작\",\"categories\":null,\"tags\":\"a-fa\",\"date\":\"2019-08-07 23:59:32 +0900\"}","markdownbody":"\n\n\u003c!--more--\u003e\n","slug":["2019-08-07-afa-quick-shifter"]},{"frontmatter":"{\"layout\":\"post\",\"title\":\"마인크래프트 한글 입력 모드 1.0.0 릴리즈 - 자바 에디션 1.14.4\",\"categories\":null,\"tags\":[\"minecraft\",\"forge\",\"mod\",\"hangulinput\",\"programming\"],\"date\":\"2019-08-07 23:59:32 +0900\"}","markdownbody":"\n# 모드 소개\n\n한영키 대신 왼쪽 컨트롤 키를 이용하여 한글 입력을 전환하여, 한글을 입력하기 위한 모드입니다.\n\n## 역사\n\n마인크래프트의 옛날 버전에서는 한글이 입력되지 않아, 이를 해결하기 위해 고안되었습니다.\n후에 신규 버전에서는 한글 입력이 가능하게 되었으나, 입력이 바로 바로 보이지 않고 한 키씩 밀려서 입력 되기 때문에 불편을 해소하고자 계속해서 개발되어 왔습니다.\n\n![](/assets/posts/hangulinput-1.0.0/problem.png)\n\n*한글을 입력하려고 하면 구석진 곳에 나온다*\n\n# 설치 방법\n\n설치 요구사항은 아래와 같습니다.\n\n * [Java](https://www.java.com/ko/) - Minecraft Forge 인스톨러 이용을 위해 필요합니다.\n * [Minecraft Forge 1.14.4](https://files.minecraftforge.net/maven/net/minecraftforge/forge/index_1.14.4.html) - 모드 적용을 위해 필요합니다.\n * [HangulInput-1.0.0.jar](https://github.com/rlj1202/HangulInput/releases/tag/1.0.0) 파일 - 적용할 모드 파일입니다.\n\n아래와 같은 페이지에서 Installer를 클릭하시면 포지 인스톨러를 다운로드 할 수 있습니다.\n\n\u003c!-- more --\u003e\n\n![](/assets/posts/hangulinput-1.0.0/forge_page.png)\n\n자바가 설치되었다면, 아래와 같은 아이콘으로 보이며 더블클릭하여 인스톨러를 실행할 수 있습니다.\n\n![](/assets/posts/hangulinput-1.0.0/forge_installer_file.png)\n\nInstall client 에 체크가 되어있는지 확인하고 OK를 눌러 설치하시면 됩니다.\n\n![](/assets/posts/hangulinput-1.0.0/forge_installer.png)\n\n\n요구사항을 모두 만족하셨다면, ``%appdata%/.minecraft/mods`` 폴더에 다음과 같이\n``HangulInput-1.0.0.jar`` 파일을 다운받아 넣어주세요.\n(``%appdata%``의 대략적인 위치는 ``C:\\Users\\\u003cname\u003e\\AppData\\Roaming`` 입니다.)\n\n![](/assets/posts/hangulinput-1.0.0/capture_0.png)\n\n위 캡처에서 보이는 다른 한 파일은 쉐이더를 이용하기 위해 제가 따로 다운받은 것이니, 무시하시면 됩니다.\n\n파일까지 넣으셨다면, 마지막으로 마인크래프트 런처에서 ``forge`` 프로파일이 선택된 것을 확인하고 플레이를 눌러주시면 됩니다.\n\n![](/assets/posts/hangulinput-1.0.0/launcher.png)\n\n# 사용 방법\n\n사용 방법은 기존에 있던 모드들과 동일하게 왼쪽 컨트롤 키를 이용해서 한/영 전환을 하면 됩니다.\n\n![](/assets/posts/hangulinput-1.0.0/screenshot_0.png)\n\n채팅 입력 창에서는 그대로 왼쪽 아래에 현재 입력 모드가 나타납니다.\n\n![](/assets/posts/hangulinput-1.0.0/screenshot_1.png)\n\n표지판에서는 가운데 위에 있습니다.\n\n![](/assets/posts/hangulinput-1.0.0/screenshot_2.png)\n\n모루는 왼쪽 상단에,\n\n![](/assets/posts/hangulinput-1.0.0/screenshot_3.png)\n\n크리에이티브 모드 인벤토리 창에서는 왼쪽 상단에 있습니다.\n\n![](/assets/posts/hangulinput-1.0.0/screenshot_4.png)\n\n추가로, 월드 선택 창에서 검색 창 왼쪽에도 입력 모드 인디케이터가 있습니다.\n\n텍스트 입력 필드 모두 동작 하나, 입력 모드 인디케이터는 없을 수 있습니다.\n예로, 아래 모드 목록 화면의 검색란은 한글 입력이 가능하나, 입력 모드 인디케이터가 없습니다.\n\n![](/assets/posts/hangulinput-1.0.0/screenshot_5.png)\n\n(펄-럭)\n\n간단 시연 영상\n\n\u003ciframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0heqYohTLfA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen\u003e\u003c/iframe\u003e\n\n# 동작 원리\n\n왼쪽 컨트롤 키로 한글 입력 모드를 토글한 경우, 영문자가 입력 되었을 때 이를 중간에서 가로챕니다.\n그런 뒤, 가로챈 영문자를 한글 자모로 변환하여 한글을 조합한 후, 가로챈 문자 대신 조합한 한글을 내보냅니다.\n\n예를 들어 'd', 'k', 's', 's', 'u', 'd' 을 차례로 입력할 경우, 각각 키보드 키에 대응되는 한글 자모인 'ㅇ', 'ㅏ', 'ㄴ', 'ㄴ', 'ㅕ', 'ㅇ'로 변환되게 됩니다.\n이는 각 입력시 마다 'ㅇ', '아', '안', 'ㄴ', '녀', '녕' 과 같이 조합되게 됩니다.\n\n# 기술적 특징\n\n기존의 한글 채팅 모드들은 입력을 가로채고 다시 내보내기 위해 원본 마인크래프트 소스코드를 뜯어서 가짜를 만들고, 만든 가짜에 하고자 하는 코드를 집어넣고, 다시 가짜를 마인크래프트에 적용하는 등의 많은 대똥꼬쇼(?)를 해야했습니다.\n\n이러한 방법의 장점은 코드를 직접 집어넣기 때문에 그 동작이 확실하다는 것입니다.\n단점은 유지보수가 어렵다는 점입니다. 마인크래프트는 코드가 난독화가 되어있어 매 릴리즈 마다 코드를 새로 해석해야 합니다. 또 매번 릴리즈 마다 포지 버젼도 바뀌기 때문에 가짜를 만들고 가짜를 적용하는 방법 또한 새로이 강구해야 할 수도 있습니다.\n\n새롭게 개발한 모드에서는 최대한 편법을 쓰지 않고 개발하도록 노력했고, 포지에서 제공하는 기능을 최대한 활용하였습니다.\n이로 인한 장점은 유지보수가 상대적으로 간편해 졌다는 것입니다. 코드를 뜯어볼 일이 없기 때문에 난독화를 신경쓰지 않아도 됩니다. 단점은 동작의 무결성을 보장할 수 없단는 것입니다. 물론 지금까지 개발하고 테스트 하였을 경우 대부분의 경우에서는 잘 동작함을 확인 하였으나, 어떤 예외가 있을지 짐작하기 어렵습니다.\n\n# 기타\n\n기타 궁금한 점이나 질문은 댓글로 남겨주세요.\n","slug":["2019-08-30-minecraft-hangulinput-mod-1.0.0-release"]},{"frontmatter":"{\"title\":\"Test post\",\"subtitle\":\"test subtitle\",\"author\":\"Jisu Sim\",\"date\":\"2020-06-07T00:00:00.000Z\",\"tags\":[\"blog\",\"test_tag\"]}","markdownbody":"# Title\nThis is test post.\n\n## Title\nOh yea `inline-code`\n\n*italic*\n_another italic_\n\n**bold**\n__another bold__\n\n~~strike~~\n\n[Google](https://google.com \"link description\")\n\n![image description](https://blog.golang.org/gopher/gopher.png \"link description\")\n\n1. Ordered list\n  1. sublist\n  2. sublist\n2. Unodered list\n  - sub list\n  - sub list\n3. Another unodered list\n  * sublist\n  * sublist\n4. Another unodered list\n  + sublist\n  + sublist\n\n```javascript\nfunction main() {\n    console.log('Hello, world!')\n}\n```\n\n```css\n.html {\n    margin: 0;\n    padding: 0;\n}\n```\n\n| column 1 | column 2       | column 3      |\n| -------- | :------------: | ------------: |\n| row 1    | center aligned | right aligned |\n| row 2    | value          | value         |\n| row 3    | value          | value         |\n\n\u003e Quote\n\u003e\u003e nested quote\n\u003e\u003e\u003e nested nested quote\n\n### horizontal rule\n\n---\n\n***\n\n___","slug":["2020-06-07-test"]},{"frontmatter":"{}","markdownbody":"This is test page under testA.","slug":["testA","2020-06-07-testA"]},{"frontmatter":"{}","markdownbody":"This is test page under testAA under testA.","slug":["testA","testAA","2020-06-07-testA"]}]},"__N_SSG":true},"page":"/","query":{},"buildId":"D0XTK0MEKRJDXLhC_InxX","assetPrefix":"/blog","nextExport":false,"isFallback":false,"gsp":true}</script><script nomodule="" src="/blog/_next/static/runtime/polyfills-b10afcedf826ebd862ad.js"></script><script async="" data-next-page="/_app" src="/blog/_next/static/D0XTK0MEKRJDXLhC_InxX/pages/_app.js"></script><script async="" data-next-page="/" src="/blog/_next/static/D0XTK0MEKRJDXLhC_InxX/pages/index.js"></script><script src="/blog/_next/static/runtime/webpack-c212667a5f965e81e004.js" async=""></script><script src="/blog/_next/static/chunks/framework.619a4f70c1d4d3a29cbc.js" async=""></script><script src="/blog/_next/static/chunks/commons.020a96d8a8e71e9e3362.js" async=""></script><script src="/blog/_next/static/runtime/main-d76a4f4aadf0225115f4.js" async=""></script><script src="/blog/_next/static/chunks/e6dc419047dac61ef10415aaccc4c72c1149af9c.5637e4aab0992574c455.js" async=""></script><script src="/blog/_next/static/D0XTK0MEKRJDXLhC_InxX/_buildManifest.js" async=""></script><script src="/blog/_next/static/D0XTK0MEKRJDXLhC_InxX/_ssgManifest.js" async=""></script></body></html>