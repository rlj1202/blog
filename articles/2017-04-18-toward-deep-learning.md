---
layout:     post
title:      딥러닝을 향해
date:       2017-04-18 01:01:22 +0900
categories: 
tags:       NeuralNetworksAndDeepLearning
---

우리의 뉴런 네트워크가 인상적인 성과를 보여주었지만, 이러한 성과는 약간 미스테리 합니다. 가중치들과 $bias$들은 자동적으로 조정되었습니다. 그리고 이는 네트워크가 이뤄낸 일을 도데체 어떻게 이루어 낸건지에 대한 설명을 즉시 할 수 없음을 의미합니다. 우리의 네트워크가 손글씨를 판별하고 있음에 대한 원리를 이해하기 위한 방법을 찾을 수 있을까요? 그리고, 그 원리들을 통해, 더 좋은 결과를 만들어 낼 수 있을까요?

이 질문들을 더 완벽히 하자면, 수십년 후에 뉴런 네트워크가 인공지능(Artificial Inteligence)을 이끌어 간다고 가정해 봅시다. 우리가 어떻게 지능적인 네트워크가 작동하는지 이해할 수 있을까요? 어쩌면 네트워크는 스스로 학습하였기 때문에 우리가 이해하지 못하는 가중치들과 $bias$들도 마찬가지로 우리에게는 불투명해 보일겁니다. 인공지능 연구의 초기에 사람들은 지능에 대한 원리, 어쩌면 인간의 뇌의 작동방식에 대한 원리를 이해하는데 AI를 만드려는 노력이 도움이 될것이라고 기대하였습니다. 하지만 어쩌면 결과는 우리가 뇌의 작동방식과 어떻게 인공지능이 작동하는지에 대해 모두 이해하지 못한채로 끝날 수 도 있습니다.

<!-- more -->

이 질문의 목적을 명확히 하기 위해서, 제가 이 장의 초반에 의사결정 모델로써 이야기 하였던 인공 뉴런의 해석으로 돌아가 봅시다. 우리가 아래 보여지는 이미지들이 사람의 얼굴인지 아닌지 구분하고 싶다고 가정해 봅시다.

<div>
<img src="https://cfile3.uf.tistory.com/image/252EA84758F4DC7B051F2A" height="240" width="180"/>
<img src="https://cfile9.uf.tistory.com/image/224EDF4758F4DC7C0A6C54" height="233" width="273"/>
<img src="https://cfile2.uf.tistory.com/image/2441D84758F4DC7C043F55" height="240" width="275"/>
</div>

우리는 우리가 손글씨 인식문제를 해결하던 방법대로 이 문제를 해결할 수 있습니다. 이미지의 각 픽셀을 네트워크의 입력으로 넣고, "네, 이것은 얼굴입니다" 또는 "아니요, 이것은 얼굴이 아닙니다" 를 나타내는 하나의 출력 뉴런을 넣으면 됩니다.

우리가 이것을 한다고 가정해 봅시다, 하지만 학습 알고리즘을 사용하지 않는다고 합시다. 대신, 우리는 우리는 직접 적절한 가중치와 $bias$를 골라 네트워크를 디자인 할것입니다. 이것을 어떻게 접근해야 할까요? 잠시 뉴런 네트워크에 대해 모조리 잊고, 경험적으로 우리가 사용할 수 있는것은 문제를 작은 단위로 쪼개는 것 입니다: 사진이 왼쪽 위에 눈을 가지고 있나요? 사진이 오른쪽 위에 눈을 가지고 있나요? 가운데에 코가 있나요? 가운데 아래에 입을 가지고 있나요? 위에는 머리카락을 가지고 있나요? 이런식으로요.

이러한 질문들의 답변들이 "예" 또는 "아마 맞습니다" 이라면, 우리는 이 사진은 얼굴이라고 결론내릴 수 있습니다. 반대로, 대부분의 질문에 대한 답변이 "아니오" 라면, 이 사진은 얼굴이 아마 아닐겁니다.

당연히, 이는 힘든 방법이고 많은 정보의 부족으로 인해 판단하기 힘들 수 도 있습니다. 사람이 대머리라면 머리카락이 없을것 입니다. 혹은 얼굴의 부분만을 또는 특정한 각도의 얼굴만을 볼 수도 있습니다. 그렇게 되면 얼굴의 특징들을 집어내기 어렵겠죠. 하지만, 이러한 경험적인 것들은 만약 우리가 뉴런 네트워크로 이런 부분적인 문제를 풀 수 있다면, 작은 문제들에 대한 네트워크를 합침으로써 얼굴 감지를 위한 뉴런 네트워크를 만들 수 있을것이라고 이야기 해 줍니다. 여기 부분적인 네트워크를 의미하는 사각형들이 그려진 가능할만한 구조가 하나 있습니다. 물론 얼굴 감지 문제를 풀기위한 현실적인 접근 방법은 아닙니다. 그보다, 네트워크가 어떻게 움직일지에 대한 직관을 쌓는데 도움을 줄겁니다. 여기 그 구조를 나타낸 그림이 있습니다.

<center><img src="https://cfile6.uf.tistory.com/image/27398A4758F4DF7B013B42" style="max-width:100%;height:auto"  height="409" style="" width="611"/></center>

부분적인 네트워크들이 분리될 수 있음이 당연해 보이는군요. 다음과 같은 질문을 생각해 봅시다. "왼쪽 위에 눈이 있나요?" 이는 또 여러가지의 질문들로 쪼개질 수 있습니다. "눈썹이 있나요?", "속눈썹이 있나요?", "홍채가 있나요?", 이런식으로요. 당연히 이러한 질문들은 위치에 대한 정보들도 담고 있어야 합니다. "눈썹이 왼쪽 위에 있고 홍채 위에 있나요?" 이런 질문이죠. "왼쪽 위에 눈이 있나요?"라는 질문에 답하는 네트워크는 이제 다음과 같이 분리될 수 있습니다.

<center><img src="https://cfile23.uf.tistory.com/image/2461F24E58F4E15414474B" style="max-width:100%;height:auto"  height="239" style="" width="597"/></center>

이러한 질문들은 더 많고 많은 여러 층들을 통해 더욱 더 많이 분리 될 수 있습니다. 궁극적으로, 하나의 픽셀 단위 수준에서 쉽게 답을 할 수 있는 질문들을 답하는 네트워크들을 가지게 될 것입니다. 이러한 질문들은 아마, 예를들면, 이미지에서의 특정한 위치에서의 매우 간단한 모양의 존재 유무에 대한 것이 될겁니다. 이런 질문들은 이미지의 원본 픽셀에 연결된 하나의 뉴런으로 해결될 수 있습니다.

최종적인 결과는 매우 복잡한 질문을 잘게 쪼개 나가는, 이미지가 얼굴이 있는지 아닌지와 같은 질문을 하나의 픽셀 단위 수준에서 답변 가능한 질문들로 쪼개나가는 네트워크가 될것 입니다. 입력 이미지에 대한 매우 간단하고 특정한 질문들을 앞쪽 층들과 더 복잡하고 추상적인 개념들의 층을 쌓아나가는 뒤쪽 층들로 이루어진 많은 층들로 이러한 문제를 해결합니다. 이러한 두개 이상의 은닉층을 가지는 다층 구조의 네트워크는 딥 뉴런 네트워크 라고 불립니다.

물론, 저는 아직 작은 네트워크으로 반복적인 분해를 하는지에 대해 이야기 하지 않았습니다. 이는 네트워크에서 가중치와 $bias$를 손으로 디자인 하기에는 현실적이지 않습니다. 대신, 학습 알고리즘을 사용함으로써 네트워크가 스스로 학습 데이터로 부터 가중치와 $bias$를 찾도록, 궁극적으로는 개념들의 층들을 쌓도록 할 수 있습니다. 1980년과 1990년대 연구자들은 이런 딥 뉴런 네트워크를 학습시키려고 노력해 왔습니다. 불행히도, 몇개의 특별한 경우를 제외하고서는 성과를 올리기 힘들었습니다. 네트워크는 느리게 배우기는 했지만, 유용히 쓰이기에는 실제로는 너무 느렸습니다.

2006년부터, 여러 기술들이 개발되어 딥 뉴런 네트워크에서의 학습을 가능케 했습니다. 이런 딥 뉴런 네트워크 학습 기술들은 확률적 기울기 하강 알고리즘과 역전파 그리고 새로운 아이디어들로 부터 개발되었습니다. 이런 기술들은 더욱 깊고 큰 네트워크의 학습을 가능케 합니다. 사람들은 이제 일반적으로 5개에서 10개 까지의 은닉층을 가진 네트워크를 학습시킵니다. 그래서 이젠 단 하나의 은닉층을 가진 네트워크와 같은 얕은 뉴런 네트워크보다 더 많은 문제들에 있어서 더 좋은 성능을 보여줍니다. 이유는 당연히 개념들의 복잡한 계층을 쌓을 수 있는 딥 네트워크의 능력 때문입니다. 일반적인 프로그래밍 언어가 복잡한 컴퓨터 프로그램을 만들어냄을 가능케 하기 위해 추상적인 것에 대한 부분적인 디자인과 아이디어들을 사용하는것과 같은 방법과 비슷합니다. 얕은 네트워크와 깊은 네트워크의 비교는 함수 호출을 만들어 낼 수 있는 능력을 가진 프로그래밍 언어와 그러한 호출을 만들어낼 수 없는 절차지향적인 언어의 비교와 비슷합니다. 추상화는 일반적인 프로그래밍에서 하는것보다 뉴런 네트워크에서 다른 형태를 취하나, 여전히 중요합니다.

