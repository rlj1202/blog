---
layout:     post
title:      비용함수에 대해 필요한 두가지 추정(작성중)
date:       2017-04-18 19:43:01 +0900
categories: 
tags:       NeuralNetworksAndDeepLearning
---

역전파의 목적은 네트워크의 어떠한 가중치 $w$ 또는 bias $b$에 대한 비용함수 $C$의 편미분 $\partial C/\partial w$ 그리고 $\partial C/\partial b$를 계산해내는 것 입니다. 역전파가 작동하기 위해서 우리는 비용함수의 형태에 대한 두가지 주된 추측을 만들어 볼 필요가 있습니다. 두 추측을 이야기 하기 전에, 머릿속에 비용함수의 예를 생각하는것이 도움이 되겠군요. 우리는 저번 장에서의 사용했던 이차 비용함수를 사용할 것입니다. 마지막 섹션에서의 표기에서, 이차 비용함수는 다음과 같은 형태를 갖습니다.

$$\begin{eqnarray}  C = \frac{1}{2n} \sum_x \|y(x)-a^L(x)\|^2,\tag{26}\end{eqnarray}$$

$n$은 학습 데이터의 총 갯수이고, 시그마는 각각의 학습 데이터 $x$ 에 대한 것이고, $y=y(x)$는 $x$ 해당하는 원하는 출력을 나타냅니다. $L$은 네트워크의 층의 갯수를 나타냅니다. 그리고 $a^L=a^L(x)$는 $x$가 입력으로 주어졌을때 네트워크로부터의 활성화된 출력의 백터입니다.

<!-- more -->

좋습니다, 그러면 역전파가 적용되기 위해서 우리의 비용함수 $C$에 대해 우리가 만들어야 하는 추측은 무엇인가요? 첫번째 추측은 비용함수는 각각의 학습 데이터 $x$에 대한 비용함수 $C_x$에 대한 평균 $C=\frac{1}{n}\sum_x C_x$으로 쓰여질 수 있다는것 입니다.

